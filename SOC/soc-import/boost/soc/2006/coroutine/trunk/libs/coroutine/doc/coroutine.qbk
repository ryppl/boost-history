[library Boost.Coroutine
	[authors [ Deretta, Giovanni P. ]]
	[copyright 2006 Giovanni P. Deretta]
	[purpose A coroutine class template]
	[category higher-order]
	[id coroutine]
	[license
	 Distributed under the Boost Software License, Version 1.0.
        (See accompanying file LICENSE_1_0.txt or copy at
        <ulink url="http://www.boost.org/LICENSE_1_0.txt">
            http://www.boost.org/LICENSE_1_0.txt
        </ulink>)
	]
]

[/ QuickBook Document verion 1.0]
[/ Aug 10, 2006]

[/ blurb icons]
[def __alert__ [$alert.png]]
[def __note__ [$note.png]]

[/ pics]

[def __MeleyFSM__ [$more.png]]

[/ reference: classes and types]
[def __coroutine__ [link boost::coroutines::coroutine coroutine]]
[def __generator__ [link boost::coroutines::generator generator]]
[def __shared_coroutine__ [link boost::coroutines::shared_coroutine
shared_coroutine]] 
[def __self__ [link boost::coroutines::coroutine::self self]]

[/ reference: functions]
[def __self_exit__  [link boost::coroutines::coroutine::self::exit exit]]
[def __exit__  [link boost::coroutines::coroutine::exit exit]]
[def __yield__     [link boost::coroutines::coroutine::self::yield
yield]]
[def __yield_to__     [link boost::coroutines::coroutine::self::yield_to yield_to]]
[def __exited__     [link boost::coroutines::coroutine::exited
exited]]
[def __empty__     [link boost::coroutines::coroutine::empty empty]]
[def __waiting__     [link boost::coroutines::coroutine::waiting
waiting]]
[def __pending__     [link boost::coroutines::coroutine::pending
pending]]
[def __swap__     [link boost::coroutines::swap
swap]]
[def __mfswap__     [link boost::coroutines::coroutine::swap
swap]]

[/ exception]
[def __exit_exception__ [link boost::coroutines::exit_exception
exit_exception]]
[def __coroutine_exited__ [link boost::coroutines::coroutine_exited
coroutine_exited]]
[def __abnormal_exit__ [link boost::coroutines::abnormal_exit
abnormal_exit]]

[/ concepts]
[def __Generator__ [link to-sgi-doc Generator]]
[def __AdaptableGenerator__ [link to-concepts-doc AdaptableGenerator]]
[def __Assignable__ [link to-concepts-doc Assignable]]
[def __Movable__ [link to-movable-concept Movable]]
[def __Swappable__ [link to-swappable-concept Swappable]]
[def __DefaultConstructible__ [link to-sgi-concept DefaultConstructible]]
 

[/ bibliography links]
[def __marlin80__ [link to-marlin-doctoral-thesis-here \[Marlin80\]]]
[def __moura04a__ [link to-moura-04-04 \[Moura04a\]]]
[def __moura04b__ [link to-moura-04-15 \[Moura04b\]]]
[def __ActorModel__ [link ref-to-actor-model-biblio \[ActorModel\]]]

[/ external links]
[def __OpenMP__ [@ link-to-openmp-webpage OpenMP]]
[def __BoostAsio__ [link to-boost-asio Boost.Asio]]
[def __BoostFunction__ [link to-boost-asio Boost.Function]]
[def __complex_matcher_cpp__ [link to-complex_matcher.cpp complex_matcher.cpp]]

[section:intro Introduction]

The Boost.Coroutine library contains a family of class templates that
transform function objects in coroutines. Coroutines are a
generalization of subroutines that can return and be reentered more
than once without causing the destruction of automatic objects.

Coroutines are useful whenever it is necessary to keep state across a
function call.

[endsect]

[section:background Tutorial]

While all subroutines have state, this is usually lost when the
subroutine returns; on the other hand coroutines keep their state
across calls. Function 
objects familiar to all C++ programmers are similar to coroutines in
the fact as they may have state that is preserved across calls; but
while function objects store their state on class members variables, coroutines
store the state in the stack as automatic objects. 

__marlin80__ provides a widely accepted  definition of coroutines:

* "The value of local data of coroutines persist between successive
calls".
* "The execution of a coroutine is suspended as control leaves it,
only to carry on were it left off when control re-enters the coroutine
at some later stage".

The second point is a fundamental difference between a coroutine and
a generic function objects. While the latter can also store local state
in the form of member variables, it does not automatically preserve
the point of suspension when it is exited; it must be manually saved
in an extra state member variable. Coroutines automatically remember
where they left off.

Coroutines can be used in all places where function objects are used;
this includes: as callback to standard algorithms, as generator
functions, as callback to asynchronous functions and much more.

In this section, we will first present the __generator__ class
template (a simplified form of coroutines). Only [link coroutine.coroutines
later] the full
__coroutine__ class template is described.

[h3 Stylistic Notes]

For brevity all code in this and other sections will assume that
the following using declaration is in effect:

    using namespace coro = boost::coroutines;
	    
And the following include directive is present:
    
    #include<boost/coroutine/generator.hpp>

[section:generators Generators]

One of the most simple uses for coroutines is as generator functions.    
A generator is similar to a function that returns a sequence of
values, but instead of returning all values at once (for example as an
array), the generator returns the values one at time. Every time the
generator is called, it returns the next value.

In standard C++ library, generators are for example used with the
`std::generate` algorithm, that takes as third argument a function
object that model the __Generator__ concept. 

[h3 Function objects as generators]

A generator can be easily implemented in C++ as a function
object. Consider a generator that returns all integer numbers in a
range:

  class range_generator {
  public:
    range_generator(int min, int max) :
      m_current(min),
      m_max(max) {}
  
    int operator()() {
      return m_current++;
    }
  
    operator bool() const {
      return m_current < m_max;
    }
  
  private:
    int m_current;
    int m_max;
  };
	
It can be used like this:

  range_generator generator(100, 200);

  while(generator) 
    std::cout<<generator()<<"\n";

It will print all values in the half-open range [100, 200).
The conversion to `bool` is used to detect when the generator has
terminated. In production code probably the safe-bool idiom would be
used instead. 

[h3 Input iterators as generators]
A generator can also be implemented as an input iterator. 
Recall that an input iterator only support dereferencing and incrementing.
This is the iterator version of the [link generators.function_objects_as_generators previous function object].

  class range_generator {
  public:
    typedef int value_type;

    range_generator(int min, int max) :
      m_current(min),
      m_max(max) {}

    range_generator() :
      m_current(-1),
      m_max(0) {}
  
    int operator*() {
      return m_current;
    }
    
    range_generator& operator++() {	
      m_current ++;
      if(m_current == m_max)
        m_current = -1;
      return *this;
    }    

    range_generator operator++(int) {
      range_generator t(*this);
      ++*this;
      return t;
    }

    friend
    bool operator==(const range_generator& rhs,
		    const range_generator& lhs) {
      return rhs.m_current == lhs.m_current;
    }

    friend
    bool operator!=(const range_generator& rhs,
		    const range_generator& lhs) {
      return !(rhs == lhs);
    }

    private:
    int m_current;
    int m_max;
  };
	
It can be used like this:

  range_generator generator(100, 200);

  while(generator != range_generator()) 
    std::cout<<*generator++<<"\n";

It will print all values in the half-open range [100, 200). Notice that
a default constructed iterator is used to represent the past-the-end iterator.
We will call this kind of iterator a generator iterator.

[h3 The generator class template]

Obviously a generator is a stateful object, and can be easily
implemented using coroutines.

Before introducing full fledged coroutines, we will introduce the
__generator__ class template that wrap a coroutine in an input iterator
interface.
  
We begin declaring its type, the generator is an iterator over 
values of type `int`:

  typedef coro::__generator__<int> generator_type;

The typedef is not really required, but makes the following code more
readable. This is the generator body: 

  int range_generator(generator_type::__self__& self, 
		      int min,
		      int max) 
  {
    while(min < max-1)
      self.__yield__(min++);
    return min;  
  }	
	 
It is a plain C++ function that takes as parameter a non const
reference to a `__generator__::__self__` and two integers by value.
The `self` object of type  `generator_type::__self__` identifies
the current generator. In fact, as coroutines have state, there can be
more than one instance of the same coroutine type. The `self` name is
just a convention used in this documentation. You can give to it
whatever name you want, of course.

The `min` and `max` parameters are the minimum and maximum bounds of
the iteration. 

The generator body iterates between all numbers in the ranges [min,
max-1) and invokes `__self__::__yield__()` for each number. The `yield` member
function is responsible of returning the parameter to the caller of
the generator.

When the `while` loop terminates, a plain `return min` statement is executed.
This both terminates the generator and returns the final value
(i.e. max-1). We will see later how to remove this asimmetry.

Given the generator body, a __generator__ iterator can be constructed:

  generator_type generator
    (boost::bind
     (range_generator, 
      _1, 
      100,
      200));

The `boost::bind` facility is used to bind the `min` and `max` arguments
of the function to the actual iterations ranges. The function object
returned by `boost::bind` is then used to construct a __generator__
object. The signature of the function or function object passed to the
__generator__ constructor must be:

  value_type(coro::__generator__<value_type>::__self__&)

The `generator` iterator can be used exactly like the iterator object of the
previous example.

  while(generator != generator_type()) 
    std::cout<<*generator++<<"\n";

Note that `range_generator` body is entered for the first time when the
generator is constructed (from the main entry point), then at every
iteration `range_iterator` is reentered from `__yield__()`. In
particular `range_iterator` is reentered when
`__generator__::operator++` is invoked.

You can have more than one generator referring to the same body:

  generator_type generator_a
    (boost::bind
     (range_generator, 
      _1, 
      100,
      200));

  generator_type generator_b
    (boost::bind
     (range_generator, 
      _1, 
      100,
      200));

[blurb __alert__ Do not confuse a /generator body/ with the 
/generator itself/. The generator body is only the code that implement the
generator behavior. The generator is composed of the body plus the
current state (that is, the current call stack and the set of live
local variables). Notice that two generators with the same generator
signature and the same body are still two different generators.]

  while(generator_a != generator_type() && 
	generator_b != generator_type()) 
    std::cout<<"generator_a is: "<<*generator_a++<<", "
	     <<"generator_b is: "<<*generator_b++<<"\n";

The `self` parameter in `range_generator` is used to identify the
different instances of a generator. Also `__generator__::__self__`
encodes the type of the generator allowing the compiler to statically
type check the argument type of `__yield__` in the same way it would
statically type check the argument type of a `return` statement. 

In addition to the normal input iterator semantics, a __generator__
iterator is also convertible to `bool`. The conversion returns true
while there are elements in the range:

  range_generator generator(100, 200);

  while(generator) 
    std::cout<<*generator++<<"\n";

__generator__ has a nested
`result_type` typedef and an `value_type operator()` member function (`generator()` is equivalent to `*generator++`). Thus
__generator__ also models the __AdaptableGenerator__ concept:

  range_generator generator(100, 200);

  while(generator) 
    std::cout<<generator()<<"\n";

[h3 Exiting a generator]

The [link generators.the_generator_class_template previous example] had an asimmetry in its
body. The last generated value had to be returned with a 'return'
statement instead of 'yield'. In simple code this is not a problem,
because it is easy to see what the final value will be, but in more
complex generators this asimmetry requires a substantial obfuscation
of the code.

The `__generator__::__self__::__self_exit__()` member function provides a way
to exit a generator without returning a value. The [link
generators.the_generator_class_template previous generator] can thus be written like this:

 int range_generator(generator_type::__self__& self, 
		     int min,
		     int max) 
  {
    while(min < max)
      self.__yield__(min++);
    self.__self_exit__();
  }	
		
Notice that now the `while` loop iterates over the full range.
The __generator__ class can handle both styles of exiting a generator.

`__self_exit__()` works by throwing an exception of type
__exit_exception__. Objects of this type can be normally caught, but 
must be eventually re-thrown: once `__self_exit__()` has been called, the
coroutine can no longer `__yield__()` nor `return`. 
	 
[blurb __alert__ Some compilers might not be able to recognize
`__self_exit__()` as a function that doesn't return, and warn that
'range_generator' returns without a value. For these compilers you may
have to add a dummy return value at the end of the function body like
this: `return int();`
If the return type is not default constructible, boost optional might
be another solution: `return *boost::optional<result_type>();`]

A generator is automatically exited when the last __generator__ iterator
that refers to it goes out of scope. In that case the generator body is resumed
and an __exit_exception__ is thrown from `__yield__`().

[blurb __alert__ Note that the __generator__ class template use the reference
counted body/handle idiom. This is necessary because an input iterator must be
 __Assignable__ while it is in general not possible to copy the generator state (that
is kept in automatic variables in the generator body). This means that
if a generator ever gets a copy of its associated __generator__
iterator, a cycle is formed and it could cause memory not to be
reclaimed.]

[#producer_consumer1]
[h3 Example: producer/consumer]

Generators can be used to straightforwardly model the ['consumer/producer] pattern. In
this scenario one function generates values and another consumes
them. The solution presented here is consumer driven, that is, the
consumer dictates the speed at witch the producer generates
values. In this example the producer generates all permutations of a
given string, while the consumer simply print the output:

  typedef coro::__generator__<int> generator_type;

  const std::string& producer(generator_type::self& self, std::string base) {
    std::sort(base.begin(), base.end());
    do {
      self.__yield__(base);
    } while (std::next_permutation(base.begin(), base.end()));
    self.__exit_self__();
  }
  
  template<typename Producer> 
  void consumer(Producer producer) {
    do {
      std::cout <<*producer << "\n";
    } while(++producer);
  }

  ...
  consumer
   (generator_type
    (boost::bind
     (producer, _1, std::string("hello"))));
  ...

[blurb __alert__ __generator__ correctly handle reference
and const references. You can even return a reference to a local
object, but you must make sure that the object doesn't go out of scope
while it is in use. This is why this example uses `operator*` and
`operator++` instead of the simpler `operator()`. In fact this last member
function correspond to  `*(*this)++`. Consider what would happen at
the last iteration: it would first 
copy the iterator (and thus store a reference to the last generated
value), then increment it, restarting the generator body that would call
`__self_exit__()`, destroying the local string and invalidating the
reference; finally it would 
return the dangling reference. Splitting the calls to the two member
functions gives us a window where the reference is live.]

This pattern is very useful and can be extended to insert another
filter function between the producer and the consumer. This filter is
both a producer and a consumer: it return the result of a call to the
parameter producer with the string `" world"` appended:

  struct filter {
    typedef const std::string& result_type;

    template<typename Producer>
    const std::string& operator()
      (generator_type::self& self, Producer producer) {
      do {
        self.yield(*producer + " world");
      } while(++producer);
      self.exit();
    }
  };

  consumer
    (generator_type
     (boost::bind
      (filter(),
       _1,
       generator_type
       (boost::bind
	(producer, _1, std::string("hello"))))));

[blurb __note__ We have made `filter` a function object instead of a
plain function because it is a template. If it were a template
function, the compiler wouldn't know which function pointer pass to
`bind`. This is just one of the multiple solutions to this recurring
problem.]

You can obviously have as many filters functions as you want.

[endsect]
[section:stackful Stackful generators: Same fringe problem]

[h3 Stackfulness]

While generators are have seen a resurgence in recent times, for
example both *Python* and *C#* support them, most implementations 
require that a generator can only be
yield from the main body: while it can
call other functions (including other generators), they must all
return before the generator can yield to the
caller. That is, the generator's call stack must be empty when it
yields. This type of coroutines is sometime called /semi/-coroutine
(__moura04b__) or simply generators. 

Boost.Coroutine provides stackful coroutines and generators that
can yield from deep inside nested functions. This makes them much more
powerful than more limited form of generators.  

We will prefer the term /semi/-coroutine to refer to these limited
coroutines and generators. 

[blurb __alert__ The term /semi/-coroutine is sometimes used to
describe asymmetric coroutines, while symmetric coroutines are simply
called coroutines. We will explain the difference between symmetric
coroutines and asymmetric coroutines only in the [link
advanced.symmetric_coroutines advanced section]]

[h3 Same Fringe: the problem]

Given two binary trees, they are have the [*same fringe] if all
leafs, read from left to right are equals. This is the classical
coroutine killer application, because it is hard to solve in *O(N)*
(with best case *O(1)*) in the number of leaves, without using stackful coroutines.
The Portland Pattern Repository's [@http://c2.com/cgi/wiki?SameFringeProblem wiki] 
contains more details on the problem and solutions on many languages.

The solution presented here is an almost verbatim port of the version
in the *Lua* language from the [@http://c2.com/cgi/wiki?SameFringeProblem wiki] 

[h3 Solution]

For this example a tree of integers will be represented by this
recursive description:

# a leaf is an integer.
# a node is a pair of nodes or a leaf.
# a tree is a node.

Or, in pseudo-C++:

  typedef int leaf_type;
  typedef boost::variant<std::pair<node_type, node_type>, leaf_type> node_type;
  typedef node_type tree_type;

Note that the above typedefs aren't legal C++ because the syntax for a 
recursive variant is lightly different. For
the sake of exposition we will pretend that the recursive typedef works.
The function:

    bool is_leaf(node_type)

will return true if the node is actually a leaf, false otherwise.
This is the generator signature:

  typedef __generator__<leaf> generator_type;

This is the generator body:

  leaf tree_leaves
   (generator_type::__self__& self,
    const node_type& node) 
  {
    if(is_leaf(node)) {
      self.__yield__(boost::get<leaf_type>(tree));
    } else {
      tree_leaves(self, boost::get<node_type>.first);
      tree_leaves(self, boost::get<node_type>.second);
    }
    self.__exit__();
  }

`tree_leaves` recursively traverses the tree and yields each leave. In
practice it gives a flattened view of the tree. 
Notice how  `__yield__()` can be called from anywhere in the recursion stack. 

  bool same_fringe(const element& tree1, const element& tree2) {
    generator_type tree_leaves_a(boost::bind(tree_leaves, _1, tree1));
    generator_type tree_leaves_b(boost::bind(tree_leaves, _1, tree2));
    while(tree_leaves_a && tree_leaves_b) {
      if(tree_leaves_a() != tree_leaves_b())
        return false;
    }
    return true && (!tree_leaves_b && !tree_leaves_a);
  }

Given two trees `same_fringe` creates two __generator__ instances,
each bound to one of the two trees. Then, as long as there are leaves
in the two trees it check that the current leaf of  first tree is
equal to the one in the second tree.

The return value controls that both generators have reached the end:
to have the same fringe, both trees must have the same number of
leaves.

[blurb __alert__ [#recursive_generators] While a generator body
can be recursive, a generator 
is *never* recursive: a generator cannot call itself directly nor
indirectly: a generator can freely call other functions, even other
generators, but these cannot call the generator. This make sense
because a generator can only be reentered after it has yielded
control, and it is resumed at the exact point where it had yielded. An
hypothetical recursive generator wouldn't know were to resume if it
called itself because it had not yielded.]

[h3 Solutions without coroutines]

To implement `same_fringe` without coroutines you need to follow one
of these strategies:

* Store a flattened view each tree before hand, then compare the views
for equality. You lose the ability to do an early
exit. The best case is *O(N)* instead of *O(1)*.

* Destructively traverse the first tree while traversing the second
tree. The best case is *O(1)*, but it is a destructive algorithm.

* Use an explicit stack to track the traversal of the first tree. This
has the same characteristics of the coroutine solution but requires
explicit stack management and is much more complex.

Generators have the property of lazy evaluation (the
tree is traversed only on request), simplicity (the recursion stack
is implicit) and immutability (the trees are not modified) . All other
solutions have to give up at least one of these properties.

[h3 Conclusions]

The `same_fringe` problem is one of the simplest problems that can be
easily solved with stackful coroutines. The coroutine stack is
essentially used to store the current position in the tree. In general
recursive algorithms are the ones that benefit the most from being able
to `yield` from anywhere in the call stack.

For example, notice how the `same_fringe` function cannot be easily
ported to *Python* generators.

Next section will show a simple non recursive program that benefit from the
stackfulness property of coroutines. It will also show how to use
coroutines for multitasking.

[endsect]
[section:multitasking Multitasking]

Coroutines can be used to implement multitasking in a very simple and
efficient way. Each coroutine represent a *job* and a scheduler is
responsible of executing each job serially. Every job is responsible
of yielding control to the scheduler once in a while.
We use a `__generator__<void>` to represent a job:

  typedef generator<void> job_type;

[blurb __note__ A `__generator__<void>` can be legally instantiated. Of
course the input iterator interface of such an iterator is not very
useful (`operator*` returns void); on the other hand the
__Generator__ interface fits perfectly our goal here.]

[#generator_scheduler]
The scheduler is just a simple wrapper around a `std::queue`:

  #include<queue>

  class scheduler {
  public:
    void add(job_type job) {
      m_queue.push(job);
    }
  
    job_type& current() {
      return m_queue.front();
    }

    void run () {
      while(!m_queue.empty()) {
        if(current()) {
	  current()();
	  add(current());
	}
	m_queue.pop();
      }
    }
  private:
    std::queue<job_type> m_queue;
  };

For simplicity we declare a global scheduler object:

  scheduler global_scheduler;

Here is a generic job body:

  void printer(job_type::__self__& self, std::string name, int iterations) {
    while(iterations --) {
      std::cout<<name <<" is running, "<<iterations<<" iterations left\n";
      self.__yield__();
    }
    self.__self_exit__();
  }

When a job yields, it is rescheduled again. If it had exited instead,
next time it is removed from the queue it will be dropped.
Notice that `__self_exit__()` is in this case superfluous. When void a
function returns it is as it had exited. 
Let's give some job to the scheduler:

  ...
  global_scheduler.add(boost::bind(printer, _1, "first", 10));
  global_scheduler.add(boost::bind(printer, _1, "second", 5));
  global_scheduler.add(boost::bind(printer, _1, "third", 3));
  ...

Calling  `global_scheduler.run();` will print:

[pre
first is running, 9 iterations left
second is running, 4 iterations left
third is running, 2 iterations left
first is running, 8 iterations left
second is running, 3 iterations left
third is running, 1 iterations left
first is running, 7 iterations left
second is running, 2 iterations left
third is running, 0 iterations left
first is running, 6 iterations left
second is running, 1 iterations left
first is running, 5 iterations left
second is running, 0 iterations left
first is running, 4 iterations left
first is running, 3 iterations left
first is running, 2 iterations left
first is running, 1 iterations left
first is running, 0 iterations left
]

[blurb __alert__ This example has a little quirk:
 the generator body is executed for the first time when the __generator__
is constructed (that is, in the call to `scheduler::add()`). An user
might rightfully expect that tasks are executed only on in the call to
`scheduler::run()`. While our solution is not necessarily wrong it
should be prominently documented. This quirk could be solved by using
true coroutines instead of generators.]
	
[h3 Multitasking versus multithreading]

What we have seen so far is a cooperative implementation of
multitasking, that is, each task must explicitly yield control to
the central scheduler to allow the next task to run. This means that a
misbehaving task that never yields control, can starve all other
tasks. 

Multithreading on the other hand, at least on most implementations,
implies preemptive multitasking; each task is allowed to run for a
certain amount of time, called /time-slice/. When the time-slice is
over the task is forcibly interrupted and the scheduler select the next
task. If the interrupted task was manipulating some shared resource,
this can be left in an undefined state. A task cannot control when is
preempted, so it must be pessimistic and lock all shared resources
that it uses. As any programmer that had to work with heavily threaded
applications knows, dealing with complex locking is not a trivial
task. In addition locking imposes some overhead.

Cooperative multitasking has not such problems as long as a
task never yield while manipulating shared state. 

This does not means that multithreading has not its place, there are
at least two scenarios where true concurrency and preemption are
pretty much required:

* *Real time applications*. Preemption is required in practice in real-time
applications. Almost all real-time scheduling algorithms need
preemption to guarantee that tasks always meet their deadline.

* *Multiprocessing*. To take advantage of hardware parallelism tasks
must be run in parallel. With the current trend of multicore
architectures this will be more and more necessary. While shared
memory threads are not the only abstraction that take advantage of
hardware parallelism (multiple processes, message passing and
__OpenMP__ are other examples), they are certainly the most popular.

Unfortunately threads are often abused for general
multitasking, where preemption is a burden instead of a benefit.

Cooperative multitasking implemented with coroutines is often a better
choice.

The simple solution presented [link generator_scheduler above] has a
fundamental problem: if a task blocks waiting for I/O, all tasks are
blocked. This is can be easily solved with asynchronous functions, but
this will be explained in an [link advanced.events advanced
section]. For now we will show a simplified example.

[h3 Waiting for events]

In the first [link generator_scheduler scheduling example], when a
task is suspended, it is always added to the back task queue. We will
now let a task decide whether be automatically rescheduled or
not. This way a task can wait to be rescheduled at a latter time, when
an event arrives.

We slightly modify `scheduler::run()`:

  ...
  void run () {
    while(!m_queue.empty()) {
      if(current()) {
        current()();	
      }	
    m_queue.pop();
  }
  ...
  
`add(current())` has been removed. This method:

  ...
  void reschedule(job_type::__self__& self) {
    add(current());
    self.__yield__();
  }
  ...

is added to `scheduler`. It is used by a task to 
reschedule itself. We will define a message queue class now:

  class message_queue {
  public:
    std::string pop(job_type::__self__& self) {
      while(m_queue.empty()) {
        m_waiters.push(m_scheduler.current());
        self.__yield__();      
      }
      std::string res = m_queue.front();
      m_queue.pop();
      return res;
    }

    void push(const std::string& val) {
      m_queue.push(val);
      if(!m_waiters.empty()) {
        m_scheduler.add(m_waiters.front());
        m_waiters.pop();
      }
    }

    message_queue(scheduler& s) :
      m_scheduler(s) {}

  private:
    std::queue<std::string> m_queue;
    std::queue<job_type> m_waiters;
    scheduler & m_scheduler;
  };

A task can wait for a message to arrive by calling
`message_queue::pop()`. This function returns the first element in the
internal queue; if the queue is empty adds the current task to an internal wait
queue and yields control to the scheduler. When `message_queue::pop()`
is called, if the wait queue is not empty, its top element is removed
and rescheduled.

  message_queue mqueue(global_scheduler);

This is our message queue object. Again a global for simplicity.

Now we will create some jobs: 

  void producer(job_type::__self__& self, int id, int count) {
    while(count--) {
      std::cout << "In producer: "<<id<<"\n";
      mqueue.push("message from " + boost::lexical_cast<std::string>(id));
      std::cout << "\tmessage sent\n";
      global_scheduler.reschedule(self);
    } 
  }

  void consumer(job_type::self& self, int id) {
    while(true) {
      std::string result = mqueue.pop(self);
      std::cout <<"In consumer: "<<id<<"\n";
      std::cout <<"\tReceived: "<<result<<"\n";
      global_scheduler.reschedule(self);
    }
  }

And add some instances of them to the scheduler:

  global_scheduler.add(boost::bind(producer, _1, 0, 3));
  global_scheduler.add(boost::bind(producer, _1, 1, 3));
  global_scheduler.add(boost::bind(producer, _1, 2, 3));
  global_scheduler.add(boost::bind(consumer, _1, 3));
  global_scheduler.add(boost::bind(consumer, _1, 4));

calling `global_scheduler.run()` generates the following output:

[pre
In producer: 0
        message sent
In producer: 1
        message sent
In producer: 2
        message sent
In consumer: 3
        Received: message from 0
In consumer: 4
        Received: message from 1
In producer: 0
        message sent
In producer: 1
        message sent
In producer: 2
        message sent
In consumer: 3
        Received: message from 2
In consumer: 4
        Received: message from 0
In producer: 0
        message sent
In producer: 1
        message sent
In producer: 2
        message sent
In consumer: 3
        Received: message from 1
In consumer: 4
        Received: message from 2
In consumer: 3
        Received: message from 0
In consumer: 4
        Received: message from 1
In consumer: 3
        Received: message from 2
]

[h3 Conclusions]

While this example is very simple and can't be easily extended to
support system-generated events, it shows how a more complex event framework
can be implemented. In the advanced session we will see how
__BoostAsio__ can be used as a scheduler and how coroutines can be
adapted as callbacks to asynchronous functions.

[endsect]

[section:coroutines Full coroutines]

[h3 From generators to coroutines]

So far we have learned to use generators, a special kind of
subroutines. We have seen that generators are function objects with no
parameters and that return a sequence of values. 
We can generalize this concept to function objects that have zero, one or
more parameters and return zero, one or more values.
A generic coroutine is, not surprisingly, implemented with the
__coroutine__ template class.

All examples in this sections will assume that the following using
directive is in effect:

  #include <boost/coroutine/coroutine.hpp>

[h3 The accumulator coroutine]

Let's start with a very simple coroutine that takes as parameter an
integer and returns the sum of that integer and all integers passed
before. In practice it acts as an accumulator.
As usual, we start by declaring its type:

  typedef coro::__coroutine__<int(int)> coroutine_type;

The syntax is deliberately similar to that used in __BoostFunction__.
This is the coroutine body:

  int accumulator_body(coroutine_type::__self__& self, int val) {
    while(true) {
      val += self.__yield__(val);
    }
  }
  
This is code is not very different from our first [link
generators.the_generator_class_template generator example]. Still there
are some differences. For example `__yield__()` now returns a
value. Soon we will see what this value represent. The syntax used to declare
a coroutine is not surprising:

  coroutine_type accumulator(accumulator_body); 

And even its usage is straight forward:

  ...
  for(int i = 0; i < 1000; ++i)
     std::cout << accumulator(i);
  ...

This will print all values in the mathematical series `a[i] = a[i-1]
+ i`.
Let's see how the flow control evolves. 

[blurb __note__ A coroutine, unlike generators, will enter its body only  when the
`__coroutine__::operator()` is invoked for the first time. This is
because, in general, a coroutine requires parameters to be passed. In
our case the parameter is the value to accumulate. 
__generator__ and __coroutine__ are intended for different use cases
(generator functions and iterators the first, generalized control
inversion the second) and their semantics try to be the best for each case.]

* The `for` loop starts, `accumulator(0)` is called.
* The coroutine body is entered for the first time.
  The first statement of `accumulator_body` is executed. At
  this point the parameter `val` is `0`. 
* The `while` loop is entered and `__yield__(val)` is invoked. The coroutine
stops and relinquishes control to the main program, back in the `for`
loop. 
* At the next iteration, `accumulator(1)` is called.
* The coroutine is resumed at the point of the call to
`__coroutine__::__yield__()`, 
that returns the parameter passed to `accumulator`, in this case `1`.
* The value returned by `__yield__()` is
added to `val` and the coroutine continues to the next iteration,
yielding `val` again, now equal to `1`. 
* At the next iteration of the
`for` loop `accumulator(2)` is called and the coroutine will yield `3`,
the new value of `val`. 
* ... and so on, until the end of the `for` loop.

When `accumulator` goes out of scope, the coroutine is destroyed in
the same way generators are destroyed: it is resumed and __yield__()
throws an instance of `__exit_exception__`.

[blurb __alert__ Coroutines have the same limitation that generators
[link recursive_generators have]: a coroutine can
never be recursive.]

[h3 Copyability]
 
While you can freely copy a generator, you can't do the same with
coroutines: during the development of Boost.Coroutine it has been
deemed that giving refference counted shallow copying to coroutines
was too risky. Coroutines usually have a longer lifetime and are more
complex. Different coroutines can interact in dynamic ways, especially
with the ability to yield to another coroutine (`__yield_to__()` will
be introduced in an [link advanced.symmetric_coroutines advanced
section]). 

The possibility of creating a cycle was very high and very
hard to debug, thus the possibility of copying a __coroutine__ object
has been removed. Coroutines instead are __Movable__: you can return a
coroutine from a function, copy construct and assign from a temporary,
and explicitly `__move__()` them, but you can't for example add them
to a standard container, unless your standard library already has
support for movable types (currently in the draft standard). A
coroutine is also __Swappable__ and __DefaultConstructible__.

Unfortunately most libraries expect copyable types and do not support
moving. For interoperability with this libraries you should use
a `shared_ptr` to manage the lifetime of a
`__coroutine__`. 

Boost.Coroutine also provides the
`__shared_coroutine__` that acts as a counted reference to a coroutine
object. You should use this class template with care because
potentially reopens the cycle loophole, and use it only as a temporary
workaround for lack of movability. 

[h3 Exiting a coroutine and the `__coroutine_exited__` exception]

A coroutine can be exited from inside its body exactly like a
generator by invoking `__coroutine__::__self__::__self_exit__()`, but
the semantics from the point of view of the caller are
different. consider this piece of code that represent a call to the
object `my_coroutine` of type `__coroutine__<int()>()`

  int i = my_coroutine();

If `my_coroutine` returns to the caller by invoking `__self_exit__()`,
there is no value can be returned from `operator()` and be assigned to
`i`. Instead a `__coroutine_exited__ exception is thrown from
`operator()`.

[blurb __note__
Generators never throw `__coroutine_exited__` because if a generator
is valid it is always guaranteed that a value can be returned. We will
see [link coroutines.behind_generators later] how this is possible.]

A coroutine can also be exited by throwing any other exception from
inside the body and letting the stack unwind below the coroutine main
body. The coroutine is terminated and `operator()` will throw an
instance of `__abnormal_exit__` exception.

[blurb __note__ Generators too may throw `__abnormal_exit__` from
`operator++` or `operator()`.]
   
Finally a coroutine can be exited from outside its body by calling
`__coroutine__::__exit__()`. It behaves exactly as if the coroutine
had exited out of scope.

[h3 Other member and friend functions]

`__coroutine__` provides a set of member functions to query its state;
these are `__exited__()`, `__empty__()`, `__waiting__()` and
`__pending__()`.
`__exited__()` returns true if a coroutine has been exited (by
throwing an exception, by calling `__self_exit__()` or by a plain
return), `__empty__()` returns true if a coroutine has not been
assigned. `__waiting__()` and `__pending__()` are related to the event
waiting mechanics and will be explained [link advanced.events later].

Both `__coroutine__::__mfswap__()` and a friend `__swap__()` are
provided with the usual semantics.

The `__yield_to__()` member function will be explained in an advanced
section about [link advanced.symmetric_coroutines symmetric coroutines].

[h3 Multiple arguments and return values]

A coroutine can have more than one argument. For example the coroutine
`accumulator2` is similar to [link
coroutines.the_accumulator_coroutine accumulator], but it takes two
parameters and accumulate only the larger of the two values:
[#accumulator_2]

  typedef coro::__coroutine__<int(int, int)> coroutine_type;

  int accumulator2_body(coroutine_type::__self__& self,
                        int arg1,
                        int arg2) {
    int i = 0;
    while(true) {
       i +=  std::max(arg1, arg2);
       boost::tie(arg1, arg2) = self.__yield__(i);
    }
  }

  coroutine_type accumulator2(accumulator2_body);

Note that __yield__ now returns two values in the form of a
`boost::tuple<int, int>`. `accumulator2` can be called like any other
binary function or function object:

  ...
  int i = accumulator2(0, 1);
  ...

Multiple return values are also handled with tuples. The coroutine
`muladd` returns the partial sum and the partial product of the argument
passed so far:
[#muladd]

  typedef coro::__coroutine__<boost::tuple<int, int>(int)> coroutine_type;

  boost::tuple<int, int> muladd_body
    (coroutine_type::__self__& self, 
     int val) {
    int prod = 0;
    int sum = 0;
    while(true) {
      prod += val;
      sum  += val;
      val = self.__yield__(boost::make_tuple(prod, sum));
    }
  }

  coroutine_type muladd(muladd_body);

Again, `muladd` behaves like any other function that return a tuple:

  ...
  int prod;
  int sum;
  boost::tie(prod, sum) = muladd(0);
  ...

Notice that there is a slight asimmetry between [link accumulator_2
the first] and [link muladd the second] example. In the call to
`accumulator2` there is no need to call `boost::make_tuple(...)`,
the arguments to `operator()` are automatically packed in the tuple
that is returned by `__yield__()`. On the other hand, in the call to
`__yield__()` in `muladd_body`, the result types must manually packed
in a tuple. It would be nice if this syntax could be used:

  ...
  self.__yield__(prod, sum);
  ...

Boost.Coroutine in fact allows this user friendlier syntax, but it is
not enabled by default because it could conflict with generic code. To
enable it `coroutine_type` must be redefined like this:

  typedef coro::__coroutine__<coro::tuple_traits<int, int>(int)> coroutine_type;

The `__coroutine__` class template recognizes the special
`coro::tuple_traits` type and enables `__yield__()` to automatically
pack its arguments.

[blurb __note__ __coroutine__ can handle any number of arguments and
return values up to a implementation defined limit. The macro
`BOOST_COROUTINE_ARG_MAX` expands to the current limit. While it is
technically possible to 
increase this number by redefining this macro, it also
requires support for more arguments from other boost components
(at least Boost.Tuple and Boost.MPL), thus this cap
cannot be modified easily.] 
  
[blurb __alert__ Both `__coroutine__::operator()` and
`__coroutine__::__yield__` can be called with a smaller amount of
arguments than required by the `__coroutine__` signature. The
rightmost missing arguments are default constructed. This is an
artifact of the current implementation, and at least in one instance
has caused an hard to find bug. You shouldn't rely on this feature
that will be probably removed from future versions of
Boost.Coroutines. Finally note that non default
constructible arguments cannot be omitted.]

[h3 Behind generators]

To complete the tour of the basic capabilities of Boost.Coroutine we
will return to the __generator__ class template and explain how it is
implemented in term of coroutines. This is its definition:

  template<typename ValueType>
  class generator : public std::iterator<std::input_iterator_tag, ValueType> {
    typedef shared_coroutine<ValueType()> coroutine_type;
  public:
    typedef typename coroutine_type::result_type value_type;
    typedef typename coroutine_type::self self;

    generator() {}

   generator(const generator& rhs) :
      m_coro(rhs.m_coro),
      m_val(rhs.m_val) {}

    template<typename Functor>
    generator(Functor f) :
      m_coro(f), 
      m_val(assing()) {}

    value_type operator*() {
      return *m_val;
    }

    generator& operator++() {
      m_val = assing();
    }

    generator operator++(int) {
       generator t(*this);
       ++(*this);
       return t;
    }

    friend operator==(const generator& lhs, const generator& rhs) {
      lhs.m_val == rhs.m_val;
    }
  private:
    boost::optional<vale_type> assign() {
      try {
        return m_coro? m_coro() :  boost::optional<value_type>();
      } catch (__coroutine_exited__) {
        return boost::optional<value_type>()
      }
    }

    coroutine_type m_coro;
    boost::optional<value_type> m_val;
  };

[blurb __note__ The code above is simplified for the sake of
exposition. The actual __generator__ class template is a bit more
complex: it handles correctly `void` result types and `tuple_traits`,
it has an `operator()`, a `safe-bool` conversion and a friend
`operator !=`]

__generator__ has two members variables: 

* `m_coro` of type `shared_coroutine<value_type()>` is the coroutine
in term of which `__generator__` is implemented.
* `m_val` of type `boost::optional<value_type>` is the next value that
will be returned by `operator*`. An empty optional represent a
past-the-end iterator.

The first two member functions are the default constructor and the
copy constructor. There is nothing peculiar in them. Note how a
default constructed `__generator__` has an empty `m_val` and thus is a
past-the-end iterator.

The third member constructs the generator from a function or function
object parameter. The argument is forwarded to the `m_coro` member
to initialize the internal coroutine. `m_val` is then initialized by a
call to `assing()`.

`operator*` simply returns `*m_val`, that is the current value stored
in the optional. The result of dereferencing a past-the-end iterator
is undefined.

The prefix `operator++` simply reassign the result of `assign()` to `m_val`.

The postfix `operator++` is implemented in terms of the prefix
`operator++` in the usual way.

`operator==` compares two generators for equality by comparing their
`m_val` members. Notice that two past-the-end iterators have both
empty `m_val` and compare equally.

`assign()` is responsible of returning the next value in the sequence
by invoking the underlying coroutine and eventually signaling the end
of iteration. It first checks the coroutine for liveness
(through __coroutine__ `safe-bool` conversion). If the coroutine is
live it returns the result of a call to the coroutine. If the
coroutine is dead (it has exited or has never been initialized) it
returns an empty optional. Notice that the call to the coroutine could
throw a `coroutine_exited` exception if the coroutine exited, without
yielding a value, by invoking `__self_exit__()`. In that case an empty
optional is returned. 

The `try {...} catch(__coroutine_exited__) {...}` idiom is frequent in
code that use coroutines that are expected to terminate via
`__self_exit__()` (that this, the `__self_exit__()` termination path is not "exceptional").
Boost.Coroutine provides a way to simplify this code by completely
eliminating the exception. For example
`assign()` can be rewritten as:

  boost::optional<vale_type> assing() {
    return m_coro? m_coro(std::nothrow) :  boost::optional<value_type>();
  }

Notice the extra `std::nothrow` parameter. If the first parameter to a
`__coroutine__<result_type(...)>::operator()` is an object of type `std::nothrow_t`, the
return type of the operator is modified to
`boost::optional<result_type>`. The optional will contain the normal
result value in the case of a normal `yield()` or `return` statement,
or will be empty if the coroutine has been exited via
`__self_exit__()`. Notice that if `result_type` was `void` it will
remain unchanged (no optional will be returned), but no exception will
be thrown.

If the coroutine terminates because of an uncaught exception not of
type `__exit_exception__`, `operator()(std::nothrow)` will still throw an
`__abnormal_exit__` exception. 

If a coroutine takes one or more parameters, std::nothrow must be the
first parameter. For example a coroutine `my_coro` of type:

  typedef coro::coroutine<int(long, double, char)> coroutine_type;

Will be invoked like this:

  boost::optional<int> res = my_coro(std::nothrow, 10000L, 10.7, 'a');

[#producer_consumer2]
[h3 Example: producer/consumer revisited]

A [link producer_consumer1 previous example] presented a consumer
driven version of the ['producer/consumer] pattern. We will now
implement a producer driven example of the same scenario:

  typedef coroutine<void(const std::string&)> coroutine_type;

  template<typename Consumer>
  void producer(Consumer consumer, std::string base) {
    std::sort(base.begin(), base.end());
    do {
      consumer(base);
    } while (std::next_permutation(base.begin(), base.end()));
  }

  void consumer(coroutine_type::self& self, const std::string& value) {
    std::cout << value << "\n";
    while(true) {
      std::cout << self.yield()<< "\n";
    } 
  }

[blurb __note__ __coroutine__ too correctly handles reference
types. This specific example doesn't have the reference lifetimes
issues the [link producer_consumer1 previous] had, but coroutines
aren't in general immune to them.]

Here we take advantage of the capability to pass arguments in a
coroutine invocation to reverse the leading role of the
pattern. Extending this pattern to support filter functions is left as
an exercise for the reader.

[h3 Conclusions]

We have now terminated our tour on the basic capabilities of
`__coroutine__` and `__generator__`. The next section will
describe more advanced features, including symmetric coroutines and
event handling.

[endsect]
[endsect][/tutorial]

[section:advanced Advanced concepts]

[section:introduction Introduction]

So far we have only seen some arguably simple uses of coroutines,
mostly as generators and iterators. We have only scratched the surface
of more advanced usage when we used generators to implement cooperative
multitasking. In this section will now explore some more advanced
usages, including as [link advanced.actors actors in the actor model]
and as [link advanced.state_machines state machines]. Finally we will
learn to use Boost.Coroutine support for [link advanced.events events] and its integration
with [link advanced.asio __BoostAsio__].

[endsect]

[section:symmetric_coroutines Symmetric coroutines]

[h3 Introduction]

The type of coroutines we have described so far is usually referred as
/asymmetric/. The asymmetry is due to the fact that the caller/callee
relation between a coroutine's context and caller's context is
fixed. The control flow must necessarily go from the caller context to
the coroutine context and back to the caller. In this model a
coroutine [*A] can obviously call coroutine [*B], but [*A] becomes the
caller. [*B] cannot directly yield to the caller of [*A] but must
relinquish control to [*A] by yielding. For example, this control flow is not
possible for example:

[#symmetric_example]

[pre
  [*A] yield to [*B] yield to [*C] yield to [*A] yield to [*B] ... etc
]

[blurb __alert__ This is not completely true. We will [link
symmetric_coroutines.symmetric_and_asymmetric_coroutine_transformation
show] a code transformation that demonstrates how /asymmetric/ coroutines have the same
expressive power of /symmetric/ coroutines.]

Control flow with /symmetric/ coroutines instead is not stack-like. A
coroutine can always yield freely to any other coroutine and is not
restricted to return to its caller. The [link symmetric_example
previous] control flow is possible.

[h3 Syntax]

While /asymmetric/ coroutines are the main abstraction provided by
Boost.Coroutine, a /symmetric/ coroutine facility is also provided.

The __coroutine__ class template has an the `__yield_to__()` member
function that can be used to stop the current coroutine and yield
control to a different __coroutine__. It works exactly like
`__yield__()`, except that the control is not returned to the caller
but to another coroutine, specified as the first argument of
`__yield_to__`. The target coroutine can be any other coroutine for
witch one of these is true:

* Has not been started yet.
* Is stopped in a call to `__yield__`.
* Is stopped in a call to `__yield_to__`.

From the above conditions it follows that a __coroutine__ can yield to
itself (in this case `__yield_to__` act as a null operation).

If  coroutine  [*A]  yields to coroutine [*B], the caller
of *A* becomes the caller of [*B]. If [*B] ever does a normal yield, the
control is given back to the caller of [*A].

[blurb __alert__ Do not confuse /calls/ with /yields to/. The first
verb implies an invocation of `__coroutine__::operator()`, while the
second an invocation of `__coroutine__::__yield_to__`. A coroutine
that yields to a second *does not* call the second one.]

As Boost.Coroutine strives for type safety, it requires that the return type
of the yielded coroutine be the same of the yielder. For example,
given these three coroutines:

  typedef __coroutine__<int(char*, float&)> coroutine1_type;
  typedef __coroutine__<int(int, float)> coroutine2_type;
  typedef __coroutine__<void *(const& char)> coroutine3_type;

  coroutine1_type coroutine1(coroutine1_body);
  coroutine2_type coroutine2(coroutine2_body);
  coroutine3_type coroutine2(coroutine3_body);

This code is legal:

   //in coroutine1_body:
   self.__yield_to__(coroutine2, 10, 0.0);

This is not:

   //in coroutine1_body
   self.__yield_to__(coroutine3, 'a'); // return type mismatch!

There is no restriction on the argument type. 

[blurb __alert__ `__yield_to__()` is like `goto` on steroid. While it
can be extremely expressive and powerful, if it used without care and
discipline can easily lead to spaghetti code.]

[h3 Producer/consumer revisited (again)]

We have explored the [link producer_consumer1 consumer] and
[link producer_consumer2 producer] driven versions of this path
before. In this third installment we will implement the pattern with
the producer and the consumer as peers, implementing them as symmetric
coroutines. The implementation is straight forward. These the our
consumer and the producer bodies: 

  void producer_body(producer_type::self& self, 
	  	     std::string base, 
		     consumer_type& consumer) {
    std::sort(base.begin(), base.end());
    do {
      self.yield_to(consumer, base);
    } while (std::next_permutation(base.begin(), base.end()));
  }

  void consumer_body(consumer_type::self& self, 
	  	     const std::string& value,
		     producer_type& producer) {
    std::cout << value << "\n";
    while(true) {
      std::cout << self.yield_to(producer)<< "\n";
    } 
  }

Creating the coroutines themselves is done as usual:

  producer_type producer;
  consumer_type consumer;
    
  producer = producer_type
    (boost::bind
     (producer_body, 
      _1, 
      "hello", 
      boost::ref(consumer)));

  consumer = consumer_type
    (boost::bind
     (consumer_body, 
      _1,
      _2,
      boost::ref(producer)));
       
Note how we default construct both `producer` and `consumer` before
actually initializing them with the bodies: we need to pass to
each coroutine a reference to the other. Also note the use of
`boost::ref` to prevent `boost::bind` to try to copy our non copyable
coroutines. 

We can start the machinery indifferently from the producer:

  ...
  producer();
  ...

Or from the consumer:

  ...
  consumer (std::string());
  ...

We need to provide an argument to the consumer because it expect to
receive a value the first time it is called. For simplicity we
provided an empty string. A better solution would have had the
consumer accept `boost::optional<const std::string&>`.

[h3 Symmetric and asymmetric coroutine transformation]

To conclude this section we demonstrate that both symmetric and
asymmetric coroutines have the same expressive power, that is each
type can be expressed in term of the other.

An asymmetric coroutine call can be implemented with `__yield_to__` by
yielding to the called coroutine and passing as a parameter a
reference to the caller coroutine. `__yield__` can be implemented 
with a `__yield_to__` the caller. This transformation is extremely
simple and intuitive. In fact the lowest levels of the
library only deal with a special `swap_context`
function. `swap_context` works as an
argument-less `__yield_to__`. Both `__yield__` and `__yield_to__` are
implemented in terms of this function.

Implementing `__yield_to__` with only asymmetric coroutines is a bit
more involved, but still straight forward. In fact we already did
implement a form of it in our [link generator_scheduler scheduler
example]. A dispatch loop invokes the first coroutine. This
coroutine then chooses the next coroutine to run by returning to the
dispatcher the address of the target coroutine. The dispatch loop then
execute that coroutine and so on.

In conclusion Boost.Coroutine could implement only one of the two
models and not loose expressiveness. Given a choice we would implement
asymmetric coroutines because they are simpler to understand, safer
and have a broader application. We decided to provide both models for
convenience. 

[endsect]

[/ section:actors Actor Model]

[/ The actor model (__ActorModel__)]

[/ endsect]

[section:finite_state_machines Finite state machines]

[h3 Introduction]

Finite state machines are a model of computation that consist in a set of
states, the set of input symbols, a function that maps every tuple
`(input, state)` to new state  and the actions performed at each
state. A complete exposition of the concept is beyond the scope of this
documentation. Here we will show how coroutines are a straightforward
implementation of this model.

[h3 Sequence recognizer]

Consider a state machine that implements this behavior:

[:For every input, output '1' if the last three inputs where `110`, `0` otherwise .]

In practice it is a sequence recognizer.
  
The formal description of this state machine is the following:

[variablelist States:
[[A:] [ if input == `1` then { output `0`, state = B} else { output
`0`,  state = A}]]
[[B:] [ if input == `1` then { output `0`, state = C} else { output
`0`, state = A}]]
[[C:] [ if input == `1` then { output `0`, state = C} else { output
`1`, state = A}]]
]

The initial state is `A`. This FSM can be represented by the following
Meley model:

__MeleyFSM__

For example, given the input:

  0110100010010001101001000111110010011001

The output will be:

  0001000000000000010000000000001000000100

This state machine can be implemented in `C++` directly from it
definition, using a `switch` statement inside a stateful function
object:

  struct fsm {
    void operator() (char input_) {
      bool input = input_ != '0';
      switch(m_state) {
      case A:
        std::cout <<"A";
        m_state = input? B : C;
        break;
      case B:
        std::cout <<"B";
        m_state = input? C : D;
        break;
      case C:
        std::cout <<"C";
        m_state = input? B : A;
        break;
      case D:
        std::cout <<"D";
        m_state = input? A : C;
        break;
      };
    }

    fsm() :
      m_state(A) {}

    enum state { A, B, C, D};
    state m_state;
  };

Each `case` block directly implements its corresponding state.
While the transformation is straightforward, it doesn't make the code
very readable. The simplicity of the informal description is
lost. While this code might be acceptable for machine generated and
maintained *FSM*, it is does not scale to large finite state machines
that must be maintained by humans.

With coroutines the straight forward transformation is:

  typedef coro::__coroutine__<void(char)> coroutine_type;

  enum state { A, B, C};	
  void fsm(coroutine_type::self& self, char input_) {
    state m_state = A;
    while(true) {
      bool input = input_ != '0';
      switch(m_state) {
      case A:
        std::cout << (input? '0' : '0');
        m_state = input? B : A;
        break;
      case B:
        std::cout << (input? '0' : '0');
        m_state = input? C : A;
        break;
      case C:
        std::cout << (input? '0' : '1');
        m_state = input? C : A;
        break;
      }
      input_ = self.yield();
    }
  }

We haven't gained much with this transformation. We have simply
done a control inversion and moved the external loop inside the
fsm. 

Let's examine the code more carefully and see if we can do better. The
`m_state` variable and its assignments are just carefully concealed
`goto` statements: 

  void fsm_goto(coroutine_type::self& self, char input) {
    while(true) {
    A:
      if(input != '0') {
        std::cout << '0';
        input = self.yield();
        goto B;
      } else {
        std::cout << '0';
        input = self.yield();
        goto A;
      }
    B:
      if(input != '0') {
        std::cout << '0';
        input = self.yield();
        goto C;
      } else {
        std::cout << '0';
        input = self.yield();
        goto A;
      }
    C:
      if(input != '0') {
        std::cout << '0';
        input = self.yield();
        goto C;
      } else {
        std::cout << '1';
        input = self.yield();
        goto A;
      }
    }
  }

`fsm_goto` has lost the state variable `m_state`. The current state of
the *FSM* is stored in the instruction pointer and need not to be
managed explicitly. On the other hand the control flow of the code has
become explicit and arguably more readable. Then again, calling
readable a code
full of `goto`s might be a stretch. Let's complete the opera
and do the final transformation:

  void fsm_structured(coroutine_type::self& self, char) {
    while(true) {
      if(self.yield() == '1') {
        std::cout << '0';
        if(self.yield() == '1') {
          std::cout << '0';
          if(self.yield() == '0') 
            std::cout << '1';
          else std::cout <<'0';
        } else std::cout <<'0';
      } else std::cout <<'0';
    }
  }

Now the code is much more readable. Also for simplicity we discard the
first input: you should give a dummy char to the coroutine before
feeding it with the input to be matched. The sequence of `if`s represent
exactly the informal requirement of matching the sequence `110`. Note
that this transformation can be easily extended to include regular
expressions. For example a matcher for the regular expression `(01+010)`
can be written as:

  void fsm_regexp(coroutine_type::self& self, char) {
    while(true) {
      if(self.yield() == '0') {
        std::cout << '0';
        if(self.yield() == '1') {
          std::cout << '0';
          while(self.yield() == '1') 
            std::cout << '0';
          std::cout <<'0';
          if(self.yield() == '1') {
            std::cout << '0';
            if(self.yield() == '0') {
              std::cout << '1';
            } else std::cout <<'0';
          } else std::cout <<'0';
        } else std::cout << '0';
      } else std::cout <<'0';
    } 
  }

Notice that the above coroutine will fail to match the last six digits
of this pattern:

  011011010

This because when it sees the fourth `1`, while it was expecting a `0`,
the state machine does not backtrack to match the `1+` pattern, but
returns to the beginning of the pattern and tries to find a `0`.

It is possible to implement backtracking elegantly with coroutines
using a goal driven design, but it is beyond the scope of this
document. See the example [^__complex_matcher_cpp__] for more details.

[endsect]

[section:events Events: introducing futures]
[endsect]

[section:asio Events: Boost.Asio]
[endsect]

[section:threads Coroutines and thread safety]
[endsect]

[endsect][/advanced]

[section:reference Reference]
[endsect]

[section:design Design Rationale]
[h3 Reference counting and movability]
[h3 No `current_coroutine`]
[h3 Main context is not a coroutine]
[h3 Symmetric and asymmetric coroutines]
[endsect]

[section:todo The future]
[h3 Introduction]
[h3 Pipelining]
[h3 Output iterators]
[h3 Generator caching]
[h3 Context caching]
[endsect]

[section:internals Internals]

[section:implementation Implementation]

[h3 A simple trick, the Duff device]
[h3 The stack switching model]
[h3 The myth of a portable coroutine library]
[h3 Extensibility]
[h3 A wild dream: Compiler support for coroutines]

[endsect]

[section:fibers Case study 1: Win32 Fibers]
[endsect]
[section:linuxasm Case study 2: Linux-x86-GCC]
[endsect]

[endsect]

[section:acknowledgments Acknowledgements]
[endsect]

[section:bibliography Bibliography]
[endsect]
  

 

	