[library Unicode
    [quickbook 1.3]
    [version 0.1a2]
    [authors [Gaunard, Mathias]]
    [copyright 2009 Mathias Gaunard]
    [category string-text]
    [purpose Internationalized text handling in C++ with Unicode]
    [license
        Distributed under the Boost Software License, Version 1.0.
        (See accompanying file LICENSE_1_0.txt or copy at
        [@http://www.boost.org/LICENSE_1_0.txt])
    ]
]

[/ Some links]

[def __note__           [$images/note.png]]
[def __alert__          [$images/alert.png]]
[def __tip__            [$images/tip.png]]

[def __unicode_std__    [@http://www.unicode.org/versions/latest/ Unicode Standard]]
[def __tr10__           [@http://unicode.org/reports/tr10/ Technical Standard #10 - Unicode Collation Algorithm]]
[def __tr15__           [@http://unicode.org/reports/tr15/ Annex #15 - Normalization Forms]]
[def __tr29__           [@http://unicode.org/reports/tr29/ Annex #29 - Text Segmentation]]
[def __boost_range__    [@http://boost.org/libs/range/index.html Boost.Range]]

[section Preface]

[:Unicode is the industry standard to consistently represent and manipulate text across most of the world's writing systems.]


[heading Description]

This library aims at providing the foundation tools to accurately represent and deal with natural text in C++ in a portable
and robust manner, so as to allow internationalized applications, by implementing parts of the __unicode_std__.

This library is environment-independent and deliberately chooses not to relate to the standard C++ locale facilities
as well as the standard string facilities, judged ill-suited to Unicode.

The current version is locale-agnostic, but a subsystem for tailored locale behaviour may be added in the future.

[heading How to use this manual]

Some icons are used to mark certain topics indicative of their relevance. These
icons precede some text to indicate:

[table Icons
    [[Icon]         [Name]          [Meaning]]
    [[__note__]     [Note]          [Information provided is auxiliary but will
                                     give the reader a deeper insight into a specific
                                     topic. May be skipped.]]
    [[__alert__]    [Alert]         [Information provided is of utmost importance.]]
    [[__tip__]      [Tip]           [A potentially useful and helpful piece of
                                     information.]]
]

[endsect]

[section Introduction to Unicode]

[section Character set]
The Unicode character set is a mapping that associates *code points*, which are integers, to characters for any writing system or language.

As of version 5.1, there are 100,507 characters, requiring a storage capacity of 17 bits per code point. The unicode standard however
also reserves some code ranges, known as planes, meaning it really requires a storage capacity of 21 bits.

Since microprocessors usually deal with integers whose capacity are multiples of 8 bits, a naive usage would be to use 32 bits per code point,
which is quite a waste, especially since most daily-used characters lie in the Basic Multilingual Plane, which fits on 16 bits.

That is why variable-width encodings were designed, where each code point is represented by a variable number of *code units*, formely also known as code values.
[endsect]

[section Encodings]

The UTF-X family of encodings encode a single *code point* into a variable number of *code units*, each of which does X bits.

[heading UTF-32]

This encoding is fixed-width, each code unit is simply a code point.

This encoding isn't really recommended

[heading UTF-16]

Every code point is encoded by one or two code units. If the code point lies within the BMP, it is represented by exactly that code point.
Otherwise, the code point is represented by two values which both lie in the surrogate category of Unicode code points.

This is the recommended encoding for dealing with Unicode internally for general purposes, since it has fairly low processing overhead
compared to UTF-8 and doesn't waste as much memory as UTF-32.

[heading UTF-8]

This encoding was designed to be compatible with legacy, 8-bit based, text management.

Every code point within ASCII is represented as exactly that ASCII character, others are represented as a variable-sized sequence from
two to four bytes, all of which are non-ASCII.

This encoding is popular for data storage and interchange, but can also be useful for compatibility with byte-oriented string manipulation.

[endsect]

[section Composite characters]

Multiple *code points* may be combined to form a single *grapheme cluster*, which corresponds to what a human would call a character.

Certain graphemes are only available as a combination of multiple code points, while some, the ones that are expected to be the most used,
are also available as a single precomposed code point. The order of the combined code points may also vary, but all code points combinations
leading to the same grapheme are still canonically equivalent.

It is thus important to be able to apply algorithms with graphemes as the unit rather than code points to deal with graphemes not representable
by a single code point.

[endsect]

[section Normalization]

The Unicode standard defines four normalized forms in __tr15__ where *grapheme clusters* are either fully compressed or decompressed,
using either canonical or compatiblity equivalence.

The Normalized Form C is of a great interest, as it compresses every grapheme so that is uses as few code points as possible. It is also
the normalized form assumed by the XML standard.
[endsect]

[section Other operations]
The Unicode standard also specifies various features such as a collation algorithm in __tr10__ for comparison and ordering of strings with
a locale-specific criterion, as well as mechanisms to iterate over words, sentences and lines in __tr29__.

Those features are not implemented by the current version of the library.
[endsect]

[section Character properties]

Unicode also provides a database of character properties called the Unicode Character Database (UCD), which consists of a set of files describing
the following properties:

* Name.
* General category (classification as letters, numbers, symbols, punctuation, etc.).
* Other important general characteristics (white space, dash, ideographic, alphabetic, non character, deprecated, etc.).
* Character shaping (bidi category, shaping, mirroring, width, etc.).
* Case (upper, lower, title, folding; both simple and full).
* Numeric values and types (for digits).
* Script and block.
* Normalization properties (decompositions, decomposition type, canonical combining class, composition exclusions, etc.).
* Age (version of the standard in which the code point was first designated).
* Boundaries (grapheme cluster, word, line and sentence).
* Standardized variants.

The database is useful for Unicode implementation in general, as it is the base for most algorithms, but can also be of interest to the library user that wants to
implement facilities not provided by the library core.

[endsect]
[endsect]

[section Linking the library]

As has been stated in [link unicode.introduction_to_unicode.character_properties Introduction to Unicode], several Unicode algorithms require the usage of a large
database of information which, as of version 0.1a2 of this library, is 2.6 MB big on x86.

For this reason, features that can avoid dependency on that database do so; it is not required for conversions for example. All algorithms that depend on the Unicode
Character Database are documented as such. All other features are header-only.

[heading UCD generation]

The Unicode Character Database can be generated using a parser present in the source distribution of this library to analyze
[@http://www.unicode.org/Public/ the data provided by Unicode.org].

Note however that the parser itself needs to be updated whenever new properties are added, and the layout of the table adapted to accomodate for the storage
required to encode those new properties; otherwise those properties will fallback to the default value.

[heading Binary compatibility]

This library does not provide any kind of binary compatibility of the UCD so that applications compiled with version X of the library may actually
link to version Y of the libray, with Y >= X, partially due to performance considerations.

This may change in the future once proper benchmarking has been done.

[heading Alternate databases]

Future versions of this library may provide alternate implementations of this database as a thin layer over a database provided by another library or environment
to prevent duplication of data.

[endsect]

[section Conversions]

``auto concept Pipe<typename T>
{
    typename output_type = T::output_type;
    static const int T::max_output; // optional

    template<typename In, typename Out>
    std::pair<In, Out> T::ltr(In begin, In end, Out out);
    
    template<typename In, typename Out>
    std::pair<In, Out> T::rtl(In begin, In end, Out out);
};``

models: [classref boost::unicode::u8_decoder],
[classref boost::unicode::u16_decoder].

``auto concept OneManyPipe<typename T>
{
    typename Input;

    typename output_type = T::output_type;
    static const int T::max_output; // optional
    
    template<typename Out>
    Out T::operator()(Input input, Out out);
};``

models: [classref boost::unicode::u8_encoder],
[classref boost::unicode::u16_encoder].

May be converted to a =Pipe= by using [classref boost::one_many_pipe].

A =Pipe= may then be used with [classref boost::pipe_iterator] to generate iterator/range
adapters or [classref boost::pipe_output_iterator] to generate
output iterators with on-the-fly conversion.
Alternatively, the algorithm may be applied eagerly to the whole range using [funcref boost::pipe].

The library provides several helpers for the UTF conversion codecs, which naming convention is as follows:

* [funcref boost::u8_encode] is an eager encoding algorithm.
* [funcref boost::u8_decode] is an eager decoding algorithm.
* [funcref boost::u8_encoded] returns a range adapter that does on-the-fly encoding.
* [funcref boost::u8_decoded] returns a range adapter that does on-the-fly decoding.
* [funcref boost::u8_encoded_out] returns an output iterator adapter that will encode its output.
* [funcref boost::u8_bounded] returns a range adapter that turns the range into a range of subranges,
with each subrange being the consumed input for a decoding step.

[endsect]

[section Boundaries]

``auto concept BoundaryChecker<typename T>
{
    template<typename Iterator>
    bool T::operator()(Iterator begin, Iterator end, Iterator pos);
};``

``auto concept Consumer<typename T>
{
    template<typename Iterator>
    Iterator T::ltr(Iterator begin, Iterator end);
    
    template<typename Iterator>
    Iterator T::rtl(Iterator begin, Iterator end);
}``

Can be obtained by converting a =Pipe= with [classref boost::pipe_consumer] or a =BoundaryChecker= with =boost::boundary_consumer=.

A =Consumer= may then be used with [classref boost::consumer_iterator] to generate iterator/range
adapters with turns the range into a range of subranges, each subrange being one consumed input.

[endsect]

[xinclude autodoc.xml]

[section Acknowledgements]

Eric Niebler for mentoring this project, John Maddock for contributing preliminary on-the-fly UTF conversion, Graham Barnett and Rogier van Dalen for their work
on Unicode character properties.

Beman Dawes and other members of the mailing list for their suggestions and support.

[endsect]
