[section:introduction Introduction]

[warning Dataflow is not a part of the Boost libraries.  It was developed
as a part of the Google Summer of Code program.  The original proposal (for
the Signal Network library, which became the Dataflow library)
as well as some GSoC status updates can be found on the
[@http://svn.boost.org/trac/boost/wiki/soc/2007/SignalNetwork GSoC page].]

[heading Description]

Dataflow is a generic library for [WikiDataflow] programming.  Dataflow
programs can typically be expressed as a graph in which vertices represent
components that process data, and edges represent the flow of data between
the components.  As such, dataflow programs can be easily reconfigured by
changing the components and/or the connections.

[heading Library Layers]
The Dataflow library currently offers three layers:

* A layer providing generic dataflow support centered around [concepts],
  adaptable to various dataflow frameworks and data transport mechanisms.
* The [DataflowSignals] layer, with a number of implemented components using
  [BoostSignals] as a data transport mechanism.
* The [DataflowBlueprint] layer, built on top of the generic layer and providing
  runtime reflection and network modeling using the [BoostGraph].

The relationship of these layers is shown in the following diagram:

[$layers.png]

As indicated by the diagram, classes provided by [DataflowSignals] model
the concepts from the generic dataflow layer.  [DataflowBlueprint] class
templates require these concepts, hence they can be used with [DataflowSignals].
The idea behind providing a generic dataflow library is that
other data transport mechanisms and dataflow frameworks can be easily adapted for
use with the library (through modeling the appropriate concepts), and benefit from
any layers built on top of the generic layer (through requiring the appropriate
concepts).

[/There is also a (currently very experimental) [DataflowPhoenix] layer,
which uses object pointers with support for
[BoostPhoenix] actors specifying how the data is processed.]

[h5 Generic dataflow layer]

The generic dataflow layer provides [concepts] which are applicable to
different dataflow frameworks, and can be used to develop generic dataflow
code.  Currently, the concepts adress things such as [Component]s and [Port]s,
as well as the connection and data extraction functionality
(the [rationale] section discusses why this is the initial focus).

[DataflowSignals] has a (very thin) support layer which makes `boost::signal`
and `boost::function` model the Dataflow [concepts], and there is an
[vtk_example example] showing how to do the same for [VTK].  Support layers
for other dataflow frameworks will be added in the future.

Developing a Dataflow support layer for a dataflow framework allows
anything that is built on top of the generic layer (e.g., [DataflowBlueprint],
a [gui_example GUI dataflow editor], and operators which can be used
to connect components in a clean, readable manner) to be used with the
framework.  See the [link dataflow.future future directions] section
for an idea of about other things in planning.

[h5 Dataflow.Signals layer]

The [DataflowSignals] layer provides Dataflow support and
components which use [BoostSignals] as a mechanism to transfer data
between the components.

[h5 Dataflow.Blueprint layer]

[DataflowBlueprint] provides run-time reflection and modeling of dataflow
networks in a [BoostGraph] graph for any dataflow framework with
implemented Dataflow library support.

[/There is an example on how to do that for [VTK], and there is also an
implementation of an (experimental and currently broken) layer based
connections made through simple object pointers, with support for using
[BoostPhoenix2] actors for data processing ([DataflowPhoenix]).]

[heading What the Dataflow library doesn't offer (yet)]

Since the development of the Dataflow library started with a dataflow
framework built on top of [BoostSignals], its features are heavily biased
towards the characteristics of [BoostSignals] - connectability is detirmined
at compile time, and evaluation of a dataflow network is driven entirely by the
components.  Ideally, the Dataflow library should at some point offer a native
dataflow framework of a different kind - one that allows runtime specification
of port/component characteristics, offers memory management for the data being
exchanged between the components, as well as flexible scheduling and optimized
evaluation.  At this point, however, such a framework is missing.

[heading Where to go from here]

* If you would like some more information about why one would want to connect
  objects into a dataflow network, read about
  [link dataflow.introduction.dataflow Dataflow programming in C++].
* If you'd like to try out the library
    * keep in mind that the interface is subject to change
    * Read [how_to_use how to use this library and the documentation].

[section:dataflow Dataflow programming in C++ - motivation and advantages]

The [WikiDataflow] programming paradigm is based on interconnected
/components/ which process passing /data/.  Basically, data is treated
as something that originates from a source, flows through a number of
processing components that manipulate it (e.g., by changing it,
duplicating, etc.), and arrives at some final destination.  As such,
the dataflow paradigm is most suitable when developing applications that
are themselves focused on the "flow" of data.

Perhaps the most readily available examples of a
dataflow-oriented applications come from the realm of real-time
[@http://en.wikipedia.org/wiki/Signal_processing signal processing],
e.g. a video signal processor which perhaps starts with a video input,
modifies it through a number of processing components (video filters),
and finally outputs it to a video display.  Another example is event
processing.

[heading A motivating example]

Let's take a simple real-time camera-input-displayed-on-the-screen application.
Suppose there are three parts to the application - getting each image frame
from the camera, processing the image in some way,
and displaying it on the screen. To see how we might arrive at
a dataflow-oriented implementation of this application,
let's first begin with an imperative approach.  Such an implementation might
be structured as follows:

[$dataflow1.png]

Basically, the main program loop is a series of instructions which does
this particular job.  To take this a step further in the dataflow direction,
we note that video input libraries often provide callback
functionality which will deliver a video stream as a sequence of
image frames given at the appropriate frame rate.
With this in mind, we do the following:

# implement a function which takes an image as input.
 # the function first invokes the image processing library function that
   modifies the image as appropriate
 # the function then invokes the GUI library function that displays the image
# register the function as a callback with the camera library
# the main program loop can relax and have some coffee.

The situation now looks something like this:

[$dataflow2.png]

So now, the image library is acting as a data/signal producer - it
generates images at a certain frame rate.  And the function we
implemented seems to be a signal consumer which can take an image,
process it, and display it on the screen.  

This now employs the basic elements of the dataflow paradigm, but we could
take it even further.  Instead of just having two components, one image
signal generator and one signal consumer, how about this:

# implement a component which accepts an input image signal,
  modifies the image as appropriate, and then outputs
  a signal with the modified image
# implement a component which receives an imput image signal and displays
  it on the screen
# connect the camera library input stream to the first component
# connect the first component to the second component
# the main program loop can relax and have some tea, or even take a nap.

The big picture now looks like the following:

[$dataflow3.png]

To give you a sense of how you would do something like this using the Dataflow
library, we will present a slightly simplified example using [DataflowSignals].
Instead of processing images, we will just process numbers - but the dataflow
parts of the code are pretty much the same.

We will first define a few components to use for our network:

[simple_example_components]

And then connect them in a dataflow network:

[simple_example]

A sample run produces:

[pre

0.213436
-0.49558
1.57538
-1.0592
1.83927
1.88577
0.604675
...

]

...not quite image processing, but you get the (dataflow) point :-)

[heading Advantages]

There are already many programming paradigms supported by C++ (either directly or through
additional libraries), so let's examine what the advantages of the the dataflow paradigm might be.

First of all, [*dataflow programming is not exclusive of other paradigms], so adopting the dataflow paradigm
does not hinder the use of other techniques.  In fact, in C++ it can't - since the components
themselves need to be implemented somehow, and we can't recursively define them
forever as finer and finer dataflow diagrams, the dataflow paradigm relies on other
programming techniques to do the underlying work.  Also, dataflow does not need
be used for the entire application implementation.  You can always use it
for only those parts of the application it is appropriate for, and 
"extend your fingers" from other parts of the program in order
to insert data into the dataflow, catch it on the other end, probe and adjust the components, etc.
You can think of it as working with electronic components and changing the connections, turning knobs,
flipping switches, or hanging over a circuit board and tinkering with it using, say, a multimeter and a
5V lead (just do it with care).

Second, [*dataflow promotes some good programming practices].  When developing processing components,
we have only the incoming data to deal with - with no requirements on where it is coming from.  Hence,
the developed components tend to be quite versatile and reusable.  In the above example, the image
processing component can be used with any image data generator - there is nothing inside the component
that says "get the image from the camera", or "get the image from this type of data source (where the
type is either a base class or a concept)".  It just does it's thing, no matter where the data is coming
from.

Third, when used in the right context, [*dataflow programming makes development and maintenance
very intuitive].  In the image processing example, say you don't want to process the image any more. You can
just connect the camera signal directly to the screen display and cut out
the image processing component.  Someone gives you a new video signal generator component you'd like to use as input
instead of the camera?  Just plug it in. Literally.

Fourth, [*dataflow-oriented programs can be divided between threads, processors, or computers more easily],
because the data dependencies are much more visible.  In the image processing example, say you have
the display on a different computer. You can just pass the connection to it through a network socket.
With the data flow clearly specified, it is much easier to distribute the work either manually or
even automatically (although the Dataflow library at the moment offers no such automatic functionality).

Finally, [*we are not to far from the advantages of a [@http://en.wikipedia.org/wiki/Visual_programming_language
visual programming language]], since the components and the connections have a natural graphical representation.
With a visaul development environment, programming becomes as easy as connecting components with connections.
In fact, the Dataflow library provides a small [gui_example example]
illustrating this.

[heading Go with the flow?]

If you are interested in exploring dataflow programming further using
the Dataflow library, see

* [how_to_use How to use this library and the documentation].

[endsect][/dataflow]

[section:how_to_use How to use this library and the documentation]

Different layers of the library are covered in different sections of the
documentation.  Here are some good starting points for the different layers:


[heading Generic dataflow layer]

* If you would like to implement Dataflow support for the dataflow framework
you are working with,  see the [vtk_example example] showing
how the [VTK] support layer was developed.
* If you are interested in developing generic code on top of the dataflow
layer, see the [concepts] documentation.

[heading Dataflow.Signals layer]

For examples of how the [DataflowSignals] layer can be used, see:

* The example on developing a
  [link dataflow.signals.introduction.examples.distributed distributed dataflow application].
* The example on developing an
  [link dataflow.signals.introduction.examples.gil image processing network].
* The [DataflowSignals] documentation.

[heading Dataflow.Blueprint layer]

The development of this layer is ongoing.  To find out more about it, see:

* The example on [link dataflow.blueprint.examples.blueprint run-time
  reflection and connectivity modeling].
* The example of [gui_example a GUI dataflow editor] built on top of
  [DataflowBlueprint]
* The [DataflowBlueprint] documentation.


[/[heading When to use]

While the [link dataflow.introduction.dataflow dataflow] section hopefully
convinced you that there are circumstances in which a dataflow approach is 
useful, please keep in mind that there are many circumstances in which this
is not the case.

First, a dataflow approach really only makes sense when the underlying task is
really about the flow of data through the components that process it.
If you can't sketch a concise data flow diagram which truly represents
the application, the dataflow approach might not be the best option.
For example, if you are implementing a complicated algorithm which is really
about the sequence of instructions that need to be executed on the data
(rather than the data going through well-defined and self-contained
processing components), you probably should't use the Dataflow library.
If you are working on an audio or video processing application,
maybe you should.

Second, the data transport mechanism you choose should reflect the needs of
the applications closely.  Most of the functionality that the library supports
at this moment is regarding run-time configurable connections.  If you don't
need that functionality, you might be wasting resources ([DataflowPhoenix]
offers some functionality related to compile-time connectability in its
iterator_relative connections, but that is yet to trickle out into the library
as a whole).

When using signals as the data transport mechanism, remember that every signal
sent results in a function call, and if the processing
components are so minute that the cost of the function
calls overtakes the cost of the processing,
using [DataflowSignals] will cause a significant performance hit.  A similar
situation occurs with [DataflowPhoenix], where each consumer must be invoked.

To sum up, consider using the Dataflow library when:

* The application can be modeled well through the flow of data; and
* The cost of the processing shadows the cost of the function calls, and any
  unnecessary overhead caused by any connections that need to be stored.
]


[/[heading Dataflow library organization]

The design of the Dataflow library looks like this:

[xinclude dataflow_table.xml]

The layers are a bottom-up hierarchy, with dependencies
only on layers underneath.
The /support/ layer provides the necessary generic traits and functions
required for generic code to work with mechanism-specific
components.  Each type of mechanism or component must specialize the elements
of the support layer to work with the mechanism\/component.

Directly based on the support layer, we have functions like /connect/ and
/invoke/, which can be used to manipulate generic and mechanism-specific
components that the library supports.  /Operators/ are based on /connect/.


The library also offers a few generic components, which can be used
to group other components together: [producer_group], [consumer_group],
and [consumer_map].

The rest of the library is in the mechanism-specific modules [DataflowSignals]
and [DataflowPhoenix], each of which provide their own support layer, on
top of which their components are implemented.

As long as the support layer is implemented
for the mechanism/component, the component should
work seamlesly with the rest of the dataflow library.
Essentially, the support layer is a very minimal layer implementing a generic
and extensible intrusive directed graph framework.

[heading Namespace use]

Since the Dataflow library provides both a generic layer, as well as
mechanism-specific implementations, its elements are scattered over multiple
namespaces.

The fundamental user-oriented generic elements, such as `is_producer`,
`producer_category_of` etc., are located in the `boost::dataflow` namespace.
Function objects which must be specialized for different data transport
mechanisms, such as `connect_impl`, are in the `boost::dataflow::extension`
namespace.  The connection operators are in `boost::dataflow::operators`.

On the other hand, individual data transport mechanism implementations
are located in the namespace of the data transport mechanism.  For example,
all of the [DataflowSignals] components are in the `boost::signals` namespace,
and all of the [DataflowPhoenix] components are in the `boost::phoenix`
namespace.  Furthermore, free functions such as `connect` and `invoke` are
imported into the mechanism's namespace, so that they can be used via ADL.

All of the examples shown in this documentation are assuming the use of

    using namespace boost;

[note Since there are multiple namespaces used, the documentation will
explicitly state the namespace of documented elements wherever it is
convenient.]
]

[endsect][/how_to_use]

[section:download Downloading, building and linking]

[heading Downloading]

The latest development version is located in the
[@http://svn.boost.org/trac/boost/browser/sandbox/SOC/2007/signals Boost sandbox].
Released versions are located in the
[@http://www.boost-consulting.com/vault/index.php?&directory=Dataflow Boost Vault].

The Dataflow library uses the trunk version of Boost - it might not work
perfectly with release versions of boost.

Version 0.9.1 (under development)

* Generic Dataflow layer
 * binary operations now propagate the return value

* [DataflowSignals]
 * [connect] now returns the `signals::connection` object
 * added tracking_call_consumer example
 * added a GUI example using GLV
 
* Added new Dataflow.Managed framework
 * added a gui example using GLV
 
Version 0.9.0
 \[[@http://www.boost-consulting.com/vault/index.php?direction=&order=&directory=Dataflow& available in the Boost vault]\]

* Generic Dataflow layer
 * Revamped [concepts] one more time
 * added the port_adapter class to replace old ProxyPort functionality
 * Started adding Doxygen-generated support layer reference.

* [DataflowSignals]
 * Adapted the Dataflow.Signals layer, tests, and examples to new generic layer.
 * [DataflowSignals] components should now all be [Component]s.
 * [filter] base class now offers simpler specification of consumer signatures
 * added a [consumer] base class for input-only components.
 * slot_selector is now useless - replaced with just [boost_function]
 * bind_object replaced with [bind_mem_fn], replaced make_slot_selector with
  [bind_mem_fn_overload].

* [DataflowBlueprint]
 * added a component bank class
 * added [gui_example an example GUI dataflow editor]

Short term to-do list:

* keep working on docs, tests
* default mechanisms for operations should be specified by the framework [Tag]
* propagate return values where they should be propagated
* Key used for [KeyedPort]s should be overridable (not always the [PortTraits])
* binary_operation should take two [Tag] parameters
* add support for cross-framework operations (`tag_adapter`?)
* make dispatching possible on other than just the [PortTraits]
* `port_adapter` should be renamed to `adapter`
* [Invocable] should be a part of [UnaryOperable]

See the [future_work] section for more information on what is planned.

Version 0.8.1
 \[[@http://www.boost-consulting.com/vault/index.php?direction=&order=&directory=Dataflow& available in the Boost vault]\]

* Started the [DataflowBlueprint] layer (runtime reflection and network modeling).
* Expanding the [Component] concept (compile-time reflection of ports).
* VTK example Jamfile now works work with Windows (not just Darwin+X11 VTK).
* Provided an example using [BoostGIL].
* The [Mechanism] concept is now limited to port-related operations.
  In the future, an additional tag template parameter might be added to all
  dataflow templates to allow specifying completely independent dataflow support
  layers over the same types (the original intent of the [Mechanism]
  parameter).

Version 0.8.0 -
 \[[@http://www.boost-consulting.com/vault/index.php?direction=&order=&directory=Dataflow& available in the Boost vault]\]

* post-GSoC version
* generic dataflow support layer with tests and examples
* Dataflow.Signals layer (fusion-based implementation) with tests and examples
* VTK example
* quickbook docs

[/Proposal for Boost / Google SoC version  \[[@signal_network.zip download]\]

* finished the signals::socket_sender and signals::socket_receiver components

Draft proposal for Boost / Google SoC version

* changed the file and namespace structure
* implemented a file-iteration based mechanism for arity-dependent classes
* changed the operators used
* signal_link is now signals::filter and does not need to know it's descendant's type
* implemented signals::junction, signals::selector, signals::storage, signals::timed_generator,
  signals::mutex, signals::chain, signals::function classes

Original request for interest version available as attachment to
[@http://lists.boost.org/Archives/boost/2007/02/116869.php]
]

[heading Building]

The library comes with Boost.Build Jamfiles for all examples, tests, and docs.
As long as your BOOST_ROOT environment variable is set, you should be able
to build each one of those by going to the appropriate directory and
running bjam.

[warning The Jamfile for the VTK examples currently only works for Darwin
with VTK built for X11, and for MSVC.]

The library itself is header only, and requires no linking.  However, parts
of it depend on boost libraries which do need to be built and linked (see
the linking information below).

[heading Linking]

The generic Dataflow support layer is header-only, and relies only on other
Boost header-only libraries.

The [DataflowSignals] layer is dependent on the [BoostSignals] library,
which must be built and linked.  A few of the components ([socket_sender]
and [socket_receiver]) are also dependent on [BoostAsio], which depends on
the System library which must also be built and linked.  A few other components
([mutex] and [condition]) are dependent on [BoostThread], which has to be
linked as well.

The [vtk_example VTK example] requires [VTK], and the [gui_example GUI dataflow
editor example] requires [FLTK].

[endsect][/download]

[endsect][/introduction]
