<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link rel="stylesheet" type="text/css" href="../../../boost.css">
<title>Rank List - Overview</title>
</head>
<body link="#0000ff" vlink="#800080">
<table border="0" cellpadding="7" cellspacing="0" width="100%" summary="header">
  <tr>
    <td valign="top" width="300"> 
      <h3><a href="../../../index.htm"><img height="86" width="277" alt="C++ Boost" src="../../../boost.png" border="0"></a></h3>
    </td>
    <td valign="top"> 
      <h1 align="center">Rank List</h1>
      <h2 align="center">Overview</h2>
    </td>
  </tr>
</table>
<hr>
<dl class="index">
  <dt><a href="#introduction">Introduction</a></dt>
  <dt><a href="#gap">The complexity gap</a></dt>
  <dt><a href="#filling">Filling the complexity gap</a></dt>
</dl>
<h2><a name="introduction">Introduction</a></h2>
<p>
The simplest way to organize a collection of data in memory is storing
the different elements in contiguous memory. If they all have the same
size it's easy to reach the n'th element: just multiply n by the size
of an element, and add this to the memory address where the sequence
begins. The resulting address is where the n'th element resides. This
is called random access. Any desired element can be reached in a short
constant amount of time.
</p><p>
The drawback of this layout is that inserting or removing an element
from any place of the sequence requires moving all elements that lay
after the given position in the sequence. On average, the number of
elements that need to be moved every time will be N/2, where N is the
total number of elements in the sequence. Thus, the time required for
an insert/erase operation will grow in direct proportion with the
size of the sequence. This is called linear time.
</p><p>
What matters here is the growth of time (or memory) required with
respect to the growth of the problem's size. The classification of this
growth is called algorithmic complexity. Note that what matters here
is not some CPU cycles more or less. Let's suppose that moving an
element is 10 times faster than calculating the address of the n'th
element. In this case, insert/erase operations would be faster than
random access in sequences of less than 20 elements. From this size
on, the time required for insert/erase grows and grows while the time
required for random access remains the same.
</p><p>
No matter what constant or proportional advantage has the linear
operation, as the size grows, a moment will come when it will start
to be slower than the constant time operation. And from there on, it
will become slower, and slower... For this reason, linear complexity
is characertized as O(N) and is said to belong to a higher complexity
order than constant complexity (O(1)). For more details, see
<a href="bibliography.html#big_O_wikipedia">Big O notation in the
Wikipedia</a>.
</p><p>
Another usual way to organize data in memory solves the aforementioned
problem: it consists in letting the elements spread, but keeping them
linked by storing, together with each one, the address of the next and
previous elements in the sequence. Inserting and erasing are then O(1),
requiring only to change some links. The drawback here is that, once
lost the contiguous layout, accessing the n'th element requires jumping
n times to the next element, starting with the first one. Thus, random
access is now O(N).
</p>
<h2><a name="gap">The complexity gap</a></h2>
<p>
The C++ Standard Templates Library provides generic sequence containers
for the two exposed ways of storing data:
<ul>
  <li> The<code> vector </code>sequence container provides O(1)
       random access, amortized O(1) insert/erase at the end of the
       sequence, but O(N) insert/erase anywhere else.</dt>
  <li> The<code> deque </code>sequence container provides O(1)
       random access, amortized O(1) insert/erase at both ends of the
       sequence, but O(N) insert/erase anywhere else.</dt>
  <li> The<code> list </code>sequence container provides O(1)
       insert/erase, O(1) access to both ends of the sequence, but
       O(N) random access.</dt>
</ul>
</p><p>
In most real life cases, one of these fits the requirements (either fast
random access or fast insertion/removal). Though, in some rare cases,
both kinds of operation are used intensely. The complexity of an
algorithm depends on the operations in which it will spend more time as
the size of the problem grows. Therefore, an algorithm that performs N
insert/erase operations and N random accesses in a sequence of size N,
will have O(N N) complexity. If<code> vector </code>is chosen, the
insert/erase operations will hold responsible. If<code> list </code>is
chosen, the bottleneck will be in the random access operations.
</p><p>
For those cases, the problem of both<code> vector </code>(or<code>
deque</code>) and<code> list </code>is that they are specialized
for one kind of operation, performing poorly in the other one.
</p>
<h2><a name="filling">Filling the complexity gap</a></h2>
<p>
A non-specialized sequence container that performed better than O(N) in
both kinds of operation would be a great advance, even if it performed
worse than<code> vector </code>on random access, and worse than<code>
list </code>on insert/erase. The sequence container<code>
rank_list</code>, proposed here, has precisely these properties.
It provides O(log N) random access and O(log N) insertion/removal. By
using it, the aforementioned algorithm would have its time complexity
lowered down to O(N log N).
</p><p>
As in<code> list </code>in<code> rank_list </code>every element is
linked to its two sequence neighbors.
<blockquote><pre>
next---&gt; ................. next---&gt;
 <b>A        B</b>     ......      <b>F        G</b>
    &lt;---prev ................. &lt;---prev
</pre></blockquote>
Additionally, every element is linked to three elements more. These
links are employed to build a tree structure:
<blockquote><pre>
      <b>D</b>
    /   \
  <b>B       F</b>
 / \     / \
<b>A   C   E   G</b>
</pre></blockquote>
The topmost element is called the root of the tree. Trees are
self-similar structures. That is, every node is the root of a
subtree that contains the nodes placed under it. In every node,
a variable stores the rank of the node in its subtree (starting
with 0). These kind of trees are called rank trees or
<a href="bibliography.html#order_stat_tree">order statistic
trees</a>.
<blockquote><pre>
         <b>D</b>,3
      /       \
   <b>B</b>,1         <b>F</b>,1
  /   \       /   \
<b>A</b>,0   <b>C</b>,0   <b>E</b>,0   <b>G</b>,0
</pre></blockquote>
This rank variable is employed for reaching the n'th element by
descending from the root and taking every time the left branch (if
n&lt;rank) or the right branch (if n&gt;rank). Before taking a right
branch, n must be adjusted by subtracting the current rank from it.
The time complexity of this random access operation is O(log N),
regarded that the tree is balanced. Maintaining balance and ranks
make insert/erase operations O(log N) too.
</p><p>
That said, it must be clarified that the current implementation
of<code> rank_list </code>doesn't store the rank of every node, but
the count of nodes in its subtree (including both branches and the
node itself):
<blockquote><pre>
         <b>D</b>,7
      /       \
   <b>B</b>,3         <b>F</b>,3
  /   \       /   \
<b>A</b>,1   <b>C</b>,1   <b>E</b>,1   <b>G</b>,1
</pre></blockquote>
The rank of a node is found in the count field of the root of its
left subtree (if there's no left subtree, then the rank is 0). The
total size of the tree is the root's count. On insertion/removal the
count fields in the path to the root must be updated, which requires
adding (unconditionally) left and right counts of every node (only
the nodes in the way up to the root need to be updated).
</p><p>
The underlying tree structure is never exposed to the user. It is
only employed for providing logarithmic time random access, and
it doesn't represent any meaningful hierarchy relationship within
elements.
</p>
<hr>
<p>Revised
  <!--webbot bot="Timestamp" S-Type="EDITED" S-Format="%d %B, %Y" startspan -->
  22 November, 2006
  <!--webbot bot="Timestamp" endspan i-checksum="39359" -->
</p>
<p>
  <i>Copyright &copy; <a href="http://www.uah.es">Universidad de Alcal&aacute;</a>
  2006. All Rights Reserved.</i>
</p>
</body>
</html>
