[/
 / Copyright (c) 2008 Vicente J. Botet Escriba
 /
 / Distributed under the Boost Software License, Version 1.0. (See accompanying
 / file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)
 /]

[section:intro Introduction]


[include introduction_traits_and_concepts.qbk]

[section Mapping the current mutexes (Boost.Thread and Boost/Interprocess) to the common concepts]

The mapping from the current mutexes and scoped guards (Boost.Thread and Boost/Interprocess) to the common concepts has been done adding a indirection level. Instead of requiring a given member function, the lockable concepts reside in fre functions. Neither the Boost.Thread nor Boost/Interprocess mutexes and locks are based on functions, but can see them as models of the common lockable and loker concepts by specializing these generic free functions. In order to make easier the mapping these functions call by default to a member function with the equivalent signature.


For example thread_timed_mutex is viwed as a lockable by specializing the folloxing functions:

    namespace partial_specialization_workaround {
        template <class Clock, class Duration >
        struct lock_until<boost::timed_mutex,Clock, Duration>   {
            static void 
            apply( boost::timed_mutex& lockable, const chrono::time_point<Clock, Duration>& abs_time ) {
                if(!lockable.timed_lock(boost::convert_to<posix_time::ptime>(abs_time))) throw timeout_exception();
            }
        };
        template <class Rep, class Period >
        struct lock_for<boost::timed_mutex,Rep, Period> {
            static void 
            apply( boost::timed_mutex& lockable, const chrono::duration<Rep, Period>& rel_time ) {
                if(!lockable.timed_lock(boost::convert_to<posix_time::time_duration>(rel_time))) throw timeout_exception();
            }
        };
        template <class Clock, class Duration >
        struct try_lock_until<boost::timed_mutex,Clock, Duration> {
            static typename result_of::template try_lock_until<boost::timed_mutex,Clock, Duration>::type 
            apply( boost::timed_mutex& lockable, const chrono::time_point<Clock, Duration>& abs_time ) {
                return lockable.timed_lock(boost::convert_to<posix_time::ptime>(abs_time));
            }
        };
        template <class Rep, class Period >
        struct try_lock_for<boost::timed_mutex,Rep, Period> {
            static typename result_of::template try_lock_for<boost::timed_mutex,Rep, Period>::type 
            apply( boost::timed_mutex& lockable, const chrono::duration<Rep, Period>& rel_time ) {
                return lockable.timed_lock(boost::convert_to<posix_time::time_duration>(rel_time));
            }
        };
    }

Note that only the functions for which the equivalent signature differ are defined. For the others the default works as expected.

[endsect]

[section  Condition lockable]

Based on the idead of Kevlin Henney, the library provides condition lockable, which allows a condition variable to be associated with a Lockable. 

Treating condition locking as a property of Lockable rather than viceversa has the benefit of making clear how something is locked and accessed, as it were emphasising it in the first person.

    class product_queue {
    public:
        ...
        product *pull() {
            mtx.lock();
            while(queue.empty())
                guard.relock_on(not_empty);
            product *pulled = queue.front();
            queue.pop();
            mtx.unlock();
            return pulled;
        }
        ...
    };

Requiring the user of a condition variable to implement a while loop to verify a condition's predicate is potentially error prone. It can be better encapsulated by passing the predicate as a function object to the locking function.

    class product_queue {
    public:
        ...
        product *pull() {
            mtx.lock_when(not_empty, has_products(queue));
            product *pulled = queue.front();
            queue.pop();
            mtx.unlock();
            return pulled;
        }
        ...
    };

[endsect]

[section Exception-based Timed Locks]

Based on the idead of Kevlin Henney, the library supports timeout exception for all the locking functions having a time or duration parameter.

* A lock with a timeout parameter, i.e. a time or a duration, throws a `timeout_exception` on expiry
* A `try_lock` with a timeout simply returns false on expiry
* Any of the conditional locks throw a `timeout_exception` on expiry
* all the locker constructors with the first parameter a timeout.

Use of timeouts can create more robust programs, by not blocking forever, but at the same time one needs to avoid annoyingly arbitrary limits.

[endsect]


[section:lockers Lockers]

Typically, object-oriented programs use object-level locking by associating a synchronization object (mutex) with each object that is susceptible to be shared between threads. Then, code that manipulates the state of the object can synchronize by locking that object. Inside a synchronized section, the mutex associated with the object is locked, and consequently that object's fields can be accessed safely.

In C++, this fundamental idiom is typically implemented with a helper Locker object or lock guard.

A locker is any object or function responsible for coordinating the use of lockable objects.

* Lockers depend on lockable objects - which need not be locking primitives - and not vice-versa. This avoids cycles in the dependency graph.
* Lockers are applications of lockable objects and, as such, form a potentially unbounded family. Most common role of lockers is for exception safety and programming convenience
* Lockers execute-around the lock-unlock pairing.

A locker defines an execution strategy for locking and unlocking that is automated by construction and destruction. It simplifies common use of locking, and does so in an exception-safe fashion. As such, lockers depend on the interface of lockables -e.g. lock and unlock - but lockables do not depend on lockers. The relationship is strictly layered, open and extensible: lockable types may be whole, externally locked objects against which existing lockers can be used; new lockers can be defined that work against existing lockable types.

Substitutability between lockables and lockers does not make sense, so the constructor is always explicit. Implicit copyability is also disabled. 

Boost.Thread and Boost.Interprocess defines already a good starting point with these lockers:

* `boost::lock_guard`,
* `boost::unique_lock`, `boost::interprocess::unique_lock` and `boost::interprocess::scoped_lock`
* `boost::share_lock` and `boost::interprocess::sharable_lock`
* `boost::upgrade_lock` and `boost::interprocess::upgradable_lock`.

The problem is that even if these locker models the same model, there is no a single syntax.

The library defines some locker adapters which take care of naming differences and that can be used like

        bsynchro::unique_locker<boost::mutex> scoped(guard);

or        

        bsynchro::unique_locker<boost::interprocess::interprocess_mutex> scoped(guard);

[*Strict lockers]

Strict lockers were first introduced by Andrei Alexandrescu. A strict locker is a scoped lock guard ensuring the mutex is locked on the scope of the lock, by locking the mutex on construction and unlocking it on destruction.

`boost::lock_guard` could be seen as a strict_locker if the following constructor didn't exists

    lock_guard(Lockable &  m, boost::adopt_lock_t)

We can say that lock_guard is a strict locker "sur parolle".

There is a const function that is very useful when working with strict lockers and external locking which check is the strict locker is locking an instace of a lockable.

    bool is_locking(lockable_type* l) const;

The library provides three strict lockers

* `strict_locker`: is the basic strict locker, special use when doing external locking.
* `neested_strict_locker`: is a strict_locker of another locker as a unique_lock.
* `conditional_unique_locker` and `conditional_shared_locker` : are strict lockers with the condition_lockable interface. These are the synchronizer of the monitor class.

    class product_queue {
    public:
        ...
        product *pull() {
            conditional_unique_locker<> _(mtx, not_empty, has_products(queue));
            product *pulled = queue.front();
            queue.pop();
            mtx.unlock();
            return pulled;
        }
        ...
    };

and a meta function `is_strict_locker` which states if a locker is a strict locker.

So as strict lockers do not provide lock/unlock functions they are not models of Lockable.

[*Try lockers]

A Try Locker is a Locker that initialize it in a such way that instead of locking on the constructor with `lock()` they can try to lock with `try_lock()`. Most of the lockers defined in Boost.Thread and Boost.Interprocess could be cosidered as `TryLockers`, i.e. them initialize in this way when `boost::try_to_lock` is given as parameter.

The following code shows one way to use the TryLocker:

    product *product_queue::try_pull() {
        product *pulled = 0;
        boost::unique_lock<boost::mutex> locker(mtx, boost::try_to_lock);
        if(locker && !queue.empty()) {
            pulled = queue.front();
            queue.pop();
        }
        return pulled;
    }

All of them use a safe strategy for a boolean conversion which use a member pointer rather than a `bool`, which is typically too permissive:

    typedef bool try_locker::*is_locked;
    operator is_locked() const {
        return locked ? &try_locker::locked : 0;
    }

If we use interprocess mutexes we need to replace the following line

        boost::unique_lock<boost::mutex> scoped(guard, boost::try_to_lock);

by

        boost::interprocess::scoped_lock<boost::interprocess::interprocess_mutex> scoped(guard, boost::interprocess::try_to_lock);

There are other `TryLockers` in Boost.Thread defined as a member typedef `scoped_try_lock`. The semantics of each constructor and member function are identical to those of `boost::unique_lock<Lockable>` for the same Lockable, except that the constructor that takes a single reference to a mutex will call `m.try_lock()` rather than `m.lock()`.

        boost::mutex::scoped_try_lock locker(mtx);

The library defines in a generic way a try_unique_locker adapter which takes care of naming differences and that can be used like

        bsynchro::unique_try_locker<Lockable> locker(mtx);

for any model of Lockable.

[*Exception-based Timed Lockers]

In addition to supporting timeout exception for Lock, the library supports them also for ExceptionBaseTimedLockers. The semantics of each constructor and member function are identical to those of boost::unique_locker<Lockable> for the same Lockable, except that the constructor that takes a time or a duration as first parameter in a addition to the reference to a mutex will call `m.lock_until(t)` or `m.lock_for(d)` rather than `m.try_lock_until(t)` or `m.try_lock_for(d)` and so a `timeout_exception` is possible on the constructor.

Let me start with an example of an application needing to lock several locks at the same time. Once all the locks are locked something must be done. Otherwise the application do something else and reiterate the lock requests. The natural and exception safe way to do that is

    while (polling) {
        t=now()+100;
        boost::unique_lock<boost::mutex> l1(m1, t);
        boost::unique_lock<boost::mutex> l2(m2, t);
        boost::unique_lock<boost::mutex> l3(m3, t);
        if (l1.has_lock() && l2.has_lock() && l3.has_lock() {
            foo();
            polling = false;
        } else execute_on_failed(); 
    }

The problem with this code is that it locks `m2` even if `l1` do not owns the lock `m1`. The advertised reader could argument that if the lock m1 has not been locked by a timeout, as all share the same time constraint the failing lock of m2 will not be expensive. Well the problem is that the locking of m1 can fail because m1 is already locked. When we try to optimize this

    while (polling) {
        t=now()+100;
        boost::unique_lock<boost::mutex> l1(m1, t);
        if (l1.has_lock() {
            boost::unique_lock<boost::mutex> l2(m2, t);
            if (l2.has_lock() {
                boost::unique_lock<boost::mutex> l3(m3, t);
                if (l2.has_lock() {
                    foo();
                    polling = false;
                } else execute_on_failed(); 
            } else execute_on_failed(); 
        } else execute_on_failed(); 
    }

we found that this starts to be unmaintenable. What is event wrost is that as the preceding one is subject to deadlock if another thread acquire the locks in a different order. 

[*try_lock_until and try_lock_for free functions]

To avoid this we can request the acquisition of all the locks toghether (letting the function to try several orders), as it does the function try_lock of Boost.Threads, but adding this time a expiration period parameter

    while (polling) {
        if (bsynchro::try_lock_for(100, m1, m2, m3)) {
            foo();
            polling = false;
        } else execute_on_failed(); 
    }

While this solve the deadlock problem, this code is not exception safe. With exception based lockers we can do the following (note that the time is given as first aregument to the locker constructor)

    while (polling)
        try {
            t=now()+100;
            bsynchro::unique_locker<boost::mutex> l1(t, m1);
            bsynchro::unique_locker<boost::mutex> l2(t, m2);
            bsynchro::unique_locker<boost::mutex> l3(t, m3);
            foo();
            polling = false;
        } catch (bsynchro::timeout_exception& ex) {execute_on_failed(); }

[*`locker_tuples` or `locker_array` of Locker containers]

While this code is exception safe and do not locks `m2` if `m1` is not acquired, it is subject to deadlock.
We can go a step ahead and mix the advantage of taking all the locks at once and making the acquisition block scoped. In order to do that we need either a array_locker or a tuple_locker depending on whether the locks are homogeneus or not. The library provides both of them. These locker containers follows the same rules as the element wise lockers. If the time comes after the locks no exception is thrown on timeout and if given as the first parameter a exception will be thown when the time will expire.

So the preceding code becomes without timeout exceptions

    while (polling) {
        bsynchro::array_unique_locker<boost::mutex, 3> lk(m1, m2, m3, 100);
        if (lk.owns_lock()) {
            foo();
            polling = false;
        } else execute_on_failed(); 
    }

which is exception safe or with exception based timed locks (Note that the time is given before the locks)

    while (polling) 
    try { bsynchro::array_locker<boost::mutex, 3> lk(100, m1, m2, m3);
        foo();
        polling = false;
    } catch (bsynchro::timeout_exception& ex) { execute_on_failed(); }

When the Locks locked by an `array_unique_locker` are not homogeneus we need some kind of tuple.

    while (polling) 
    try { bsynchro::tuple_unique_locker<T1, T2, T1> lk(100, m1, m2, m3);
        foo();
        polling = false;
    } catch (bsynchro::timed_exception& ex) { execute_on_failed(); }


[*`lock_until` and `lock_for` free functions]

For completion the exception based timed multi lock functions `unlock`, `lock_until` and `lock_for` are also provided.

    while (polling)
        try {
            bsynchro::lock_for(100, m1, m2, m3);
            foo();
            polling = false;
        } catch (bsynchro::timeout_exception& ex) {execute_on_failed(); }


[*External lockers]

An alternative or complementary approach to internal locking is to support external locking for an object - Multiple calls may be grouped within the same externally defined critical region.

External locking has some associated risks for high-level objects. Incorrect usage can be too easy: a forgotten call to lock or unlock is more likely than with synchronisation primitives because the focus of using the object is on the rest of its non-Lockable interface, so it becomes easy to forget that to use the interface correctly also requires participation in a locking scheme.

To some extent lockers can help, but such a co-operative scheme should only be employed when internal locking is too restricted for a given use, e.g. multiple operations must be performed together. Ideally, if such operations are common they should be defined internally locked and defined in the interface of the object as Combined Methods.

Assuming that locks are re-entrant, external locking can be provided to complement the more encapsulated internal locking, i.e. by default if you want to call a single function you just call it and it automatically locks, but if you want to call multiple functions together you first apply an external lock.

The library provides a `externally_locked` class that allows to access a externally locked class in a thread safe mode through strict lockers.

Where only external locking is used, a safe approach is needed for calling single functions easily. The library provides two classes

* `locking_ptr` and
* `on_dereference_locking_ptr`
* `externally_locked`

[endsect]

[section:poly  Polymorphic lockable]

The locks classes introduced previously are a non-polymorphic classes. Clearly, many of the synchronisation primitives support common operations, and hence interfaces. In some cases a more general interface is useful.

The synchronised interface class may be used explicitly as a base class for a class supporting synchronisation. 

    struct exclusive_lock {
        virtual ~exclusive_lock()=0;
        virtual void lock()=0;
        virtual void unlock()=0;
        virtual bool try_lock()=0;
    };

More usefully for primitives, which are best left as non-polymorphic, an adaptor class is used to provide the interface -- run-time polymorphism -- on behalf of anything supporting the correctly named functions - compile time polymorphism. It easier to take a nonpolymorphic class and adapt it to be polymorphic, than it is do it the other way around: the overhead and semantics of polymorphism can only be introduced to a class, not removed.

    template <typename Lockable>
    class exclusive_lock_adapter : public virtual exclusive_lock
    {
        exclusive_lock_adapter(): lock_() {}
        virtual ~exclusive_lock_adapter() {}

        virtual void lock() {lock_.lock();}
        virtual void unlock() {lock_.unlock();}
        virtual bool try_lock() { return lock_.try_lock();}
    protected:
        Lockable lock_;
    };


[endsect]

[section Language-like Synchronized Block ]

Nest follows an example of mutual exclusion with automatic objects.

    {
        scoped_guard<boost_mutex> lock(l);
        foo();
        return bar(); // lock released
    }

With language-like mutual exclusion this results in:

    synchronize(l) 
    {
        foo();
        return bar(); 
    } // lock released

This is achieved through macros. If the user wants to use synchronized this way he needs to include a specific file which defines

    #define synchronized(MUTEX) BOOST_SYNCHRONIZED(MUTEX)

The library do not provides this directly because this can broke some user code. The library provideds other safer macros, using the BOOST prefix.

    #define BOOST_SYNCHRONIZED_VAR(VARS_DECLARATION) \
        if (bool stop_ = false) {} else \
        for (VARS_DECLARATION; !stop_; stop_ = true)

    #define BOOST_SYNCHRONIZED(MUTEX) \
        BOOST_SYNCHRONIZED_VAR(boost::scoped_guard<boost::mutex> __lock(MUTEX))

[endsect]

[section:monitors Monitors]

Concurrent components may interact in different ways: they may access the same objects by, for example, executing functions of these objects; or they may communicate directly by executing functions of each other.

Concurrent execution of objects requires a mechanism for synchronizing the access to shared objects, just as direct communication between objects may require synchronization. The basic mechanism for synchronization in Boost.Threads and Boost.Interprocess are the well known mutex and condition_variables. Mutexes and condition variables are, however, only useful for very simple synchronization problems. The Synchro Library therefore introduce high-level abstractions for handling more complicated synchronization problems, including monitor for guaranteeing exclusive access to an object.

[endsect]


[endsect]