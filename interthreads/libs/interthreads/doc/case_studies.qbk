[/
  (C) Copyright 2008-2009 Vicente J. Botet Escriba
  Distributed under the Boost Software License, Version 1.0.
  (See accompanying file LICENSE_1_0.txt or copy at
  http://www.boost.org/LICENSE_1_0.txt).
]

[/============================]
[section Examples]
[/============================]

This section do includes complete examples using the library.


[/==================================]
[section Thread safe deferred traces]
[/==================================]

When executing on a multi thread environment, the output lines on
std::cout  could interleave. We can synchronize these outputs with a
global mutex

    {
       boost::lock_guard<boost::mutex> lock(global_cout_mutex);
       std::cout << ... << std::endl ;
    }

This mutex could be the bottleneck of the system. Only one mutex resource for all the user threads.

[pre

        U        U
         \     /
          \   /
    U ----- R ----- U
            |
            |
            U
]


[/$../images/star.png]

Another approach could be using a queue of output stream buffers for each thread.
Each buffer is timestamped with the creation date and there is a concentrator that takes one by one the elements ordered by their timestamp.
Only the current thread can push on this queue because it is specific to the thread.
There is a single thread, the concentrator, that pops from these queue.
In this context we can ensure thread safety without locking as far as
the queue has at least two messages.

[/$../images/fourche.png]

[pre

    U ----- R ------+
                     \
    U ----- R ------\ \
                     \ \
    U ----- R -------- C
                     / /
    U ----- R ------/ /
                     /
    U ----- R ------+
]

This can be encapsulated in an async_ostream class

    class async_ostream : public iostreams::stream<detail::async_ostream_sink> {
    public:
        typedef char                    char_type;
        typedef iostreams::sink_tag     category;

        async_ostream(std::ostream& os);
        void flush();
    };

    extern async_ostream cout_;


With this interface the user can use cout_ as it used std::cout.

    cout_ << "Hello World!" << std::endl ;

All the magic is in the `template class boost::iostreams::stream<>`. The parameter must be a model of a sink (See [@http://www.boost.org/libs/iostreams/doc/index.html [*Boost.Iostreams]]).
Here it is.

    namespace detail {
        struct async_ostream_sink {
            typedef char                            char_type;
            typedef  boost::iostreams::sink_tag     category;
            async_ostream_sink(std::ostream& os);
            std::streamsize write(const char* s, std::streamsize n);
            void flush();
        private:
            friend class async_ostream_concentrator;
            friend class async_ostream;
            struct impl;
            boost::shared_ptr<impl> impl_;
        };
    }

This class declares the just minimum in order to model a sink. In addition, in order to mask the implementation, the Pimpl idiom is used.
The implementation of these functions is straigtforward:

    async_ostream::async_ostream(std::ostream& os)
        : base_type(os) {}

    void async_ostream::flush() {
        this->base_type::flush();
        async_ostream& d = *this;
        d->flush();
    }

    async_ostream_sink::async_ostream_sink(std::ostream& os)
        : impl_(new async_ostream_sink::impl(os)) {}

    std::streamsize detail::async_ostream_sink::write(const char* s, std::streamsize n) {
        return impl_->write(s,n);
    }

    void async_ostream_sink::flush() {
        return impl_->flush();
    }

Let me continue with the handle of the Pimpl pattern:

    struct detail::async_ostream_sink::impl {
        impl(std::ostream& os);
        std::ostream& os_;
        tsss_type tsss_;
        priority_queue_type queue_;
        boost::thread thread_;

        std::streamsize write(const char* s, std::streamsize n);

        static void terminate(shared_ptr<async_ostream_thread_ctx> that);
        static void loop(impl* that);
    };

Of course we need to store a reference to the final ostream.

The `thread_specific_shared_ptr tsss_` is used to encapsulate the logic specific to each thread.

    typedef thread_specific_shared_ptr<async_ostream_thread_ctx> tsss_type;

A priority queue `queue_` will be used by the concentrator thread to order the stringstreams by date.

    template <typename T>
    struct detail::timestamped {
        system_time date_;
        unsigned seq_;
        T value_;
        void reset_date(unsigned seq) {
            date_ = system_time();
            seq_ = seq;
        }
        struct ptr_comparator_gt {
            typedef timestamped* value_type;
            bool operator()(const value_type&lhs, const value_type&rhs) {
                return (lhs->date_ > rhs->date_) ? true :
                        (lhs->date_ == rhs->date_) && (lhs->seq_ > rhs->seq_)? true:false;
            }
        };
    };

    typedef timestamped<std::stringstream> element_type;
    typedef std::priority_queue<queue_type*, std::deque<element_type*>, element_type::ptr_comparator_gt> priority_queue_type;

In addition to the timestamp `date_` we need a sequence number to order the stringstreams pushed without enough time granularity, e.g. on the same microsecond.

To finish the field declaration there is the concentrator thread implemented by the loop function.

        , thread_(boost::bind(loop, this))

Comming back to the sink implementation,

        async_ostream_sink::impl::impl(std::ostream& os)
        : os_(os)
        , tsss_(terminate)
        , thread_(boost::bind(loop, this))
        {}

The terminate cleanup function is used to ensure  that the queue is empty before the thread finishes.
To avoid optimizations a non const call inc is done while waiting the queue empties.

        void async_ostream_sink::impl::terminate(shared_ptr<async_ostream_thread_ctx> that) {
            while (!that->empty()) {
                that->inc();
            }
        }

The central sink function is write. Here instead to lock a mutex the function forwards to
the thread specific shared pointer. We will see below how `async_ostream_thread_ctx` handles this call.

        std::streamsize write(const char* s, std::streamsize n) {
            return tsss_->write(s, n);
        }

It is time to analyze the thread specific context before seeing how the concentrator is implemented.

    struct async_ostream_thread_ctx {
        async_ostream_thread_ctx();
        std::streamsize write(const char* s, std::streamsize n);
        void flush();
        element_type* get();
        bool empty() const {return queue_.empty();}
        void inc() {++inc_;}
    private:
        unsigned seq_;
        element_type *current_;
        queue_type queue_;
        boost::mutex mutex_;
        std::stringstream& buffer() {return current_->value_;}
    };

Each thread has a pointer to the current timestamped stringstream wich is used for the current output flow, i.e. by the write function.

        std::streamsize write(const char* s, std::streamsize n) {
            buffer().write(s, n);
            return n;
        }

Once the user does a flush, the current element is pushed on the queue. The `sec_` integer is used as monotonic sequence in conjuntion with the timestamp.

        void flush() {
            current_->reset_date(seq_);
            ++seq_;
            if (queue_.size()>2) {
                queue_.push(current_);
            } else {
                boost::lock_guard<boost::mutex> lock(mutex_);
                queue_.push(current_);
            }
            current_ = new element_type();
        }

As stated in the introduction, we don't need to lock the mutex if the number of elements in the queue is enough.

These queue elements will be read by the concentrator using the get function.

        element_type* get() {
            if (queue_.size()>1) {
                return get_i();
            } else {
                boost::lock_guard<boost::mutex> lock(mutex_);
                return get_i();
            }
        }

        element_type* get_i() {
            if (queue_.empty()) return 0;
            element_type* e= queue_.front();
            queue_.pop();
            return  e;
        }

The concentrator loop looks like:

    void async_ostream_sink_impl::loop(async_ostream_sink::impl* that) {
        std::ostream& os_ = that->os_;
        for(;;) {
            // sleeps a little bit
            this_thread::sleep(boost::posix_time::milliseconds(1));
            { // scope needed don't remove
                // lock the map access
                tsss_type::lock_type lock(that->tsss_.get_mutex());
                const tsss_type::map_type& tmap(that->tsss_.get_map(lock));
                for (tsss_type::map_type::const_iterator it = tmap.begin(); it != tmap.end(); ++it) {
                    // takes the first element of each thread queue (if it exists) and push it on the ordered queue.
                    element_type* e= it->second->get();
                    if (e != 0) that->queue_.push(e);
                }
            }
            if (that->queue_.empty()) { //when the queue is empty sleeps a little more
                this_thread::sleep(boost::posix_time::milliseconds(10));
            } else {
                // takes the fist element of the ordered queue, write them on the output stream and delete it.
                element_type* e = that->queue_.top();
                that->queue_.pop();
                os_ << "["<< e->date_ <<"-" << e->seq_ << "] " << e->value_.str();
                delete e;
            }
        }
    }


[endsect]

[/========================]
[section:stm STM]
[/========================]

This section does not include a complete example using the library, but only a case study that could use the library in some way. I'm curently working on this.

Transactional memory (TM) is a recent parallel programming concept which reduces challenges found in parallel programming.
TM offers numerous advantages over other synchronization mechanisms.

This case study contains some thoughts on how I see a "boostified" version of DracoSTM, a software transactional memory (STM) system.
DracoSTM is a high performance lock-based C++ STM research library.
DracoSTM uses only native object-oriented language semantics, increasing its intuitiveness for developers while maintaining
high programmability via automatic handling of composition, locks and transaction termination.

The example will show only the part concerning how the different contexts are stored.

Let me start of with a typical use of this library with the Hello World! of transactional concurrent programming, Bank accounts and transfers.
Let BankAccount be a simple account.

    class BankAccount {
    public:
        void Deposit(unsigned amount);
        void Withdraw(unsigned amount);
        int GetBalance() const;
    };
    void Transfer(BankAccount* inA, BankAccount* outA, int amount);
    class AccountManager {
    public:
        BankAccount* checkingAcct_;
        BankAccount* savingsAcct_;
        AccountManager(BankAccount& checking, BankAccount& savings)
            : checkingAcct_(&checking)
            , savingsAcct_(&savings)
            {}
        void Checking2Savings(int amount) {
            Transfer(checkingAcct_, savingsAcct_, amount);
        }
    };

And here a little programm that emulates an employer and two employees behaviors.
The employees have requested the employer to transfer their salaries to their checking accounts every month.
The employer does the transfer on the 28th of each month.
The employees perform withdrawals and queries from their accounts using an ATM.
Some people have requested the Bank for automatic periodic transfers from their checking accounts to their saving accounts.
The transfer is done on the 3rd of each month.


    BankAccount *emp;
    BankAccount *c1;
    BankAccount *c2;
    BankAccount *s1;
    AccountManager *am1;

    int employer_th() {
        sleep_for(day(28));
        for (int i=0;i<2;++i) {
            Transfer(emp, c1, 3000);
            Transfer(emp, c2, 3200);
            sleep(month(1));
        }
    }

    void people_1_th() {
        sleep_for(day(1));
        c1->Withdraw(100);
        sleep_for(day(5));
        c1->Withdraw(500);
        sleep_for(day(4));
        c1->Withdraw(200);
    }

    void automatic_transfer_th(AccountManager *am, unsigned debit) {
        sleep_for(day(3));
        for (int i=0;i<2;++i) {
            am.Checking2Savings(debit);
            sleep_for(month(1));
        };
    }

Evidently every operation must be atomic. We use the STM_ATOMIC and STM_END_ATOMIC macors to hide all the transaction complexity

    class BankAccount {
        int balance_;
    public:
        void Deposit(unsigned amount) {
            STM_ATOMIC(t) {
                t.wr_ptr(this)->balance_ += amount;
            } STM_END_ATOMIC
        }
        // ...

    };

How all this works? Let me write what what is begind these macros. These macros use a trick to that ensure that when the statement between both macros succeed the transaction is committed. As the transaction can fail (exception transaction_aborted thrown) we need to reiterate the execution of the statement. So what a user needs to write is something like

        void Deposit(unsigned amount) {
            for (stm::transaction t; !t.commited() && t.restart(); t.no_throw_commit()) {
                try {
                    t.wr_ptr(this)->balance_ += amount;
                } catch (stm::transaction_aborted&) {}
            } 
        }

1. creation of a new transaction
2.a if not commited restart the transaction and enter the body of the for (3)
2.b if commited exit the for.
3. execute the statement
4 catch stm::transaction_aborted - if a stm::transaction_aborted is thrown the next commit will fail
5. do a no_throw commit (2)

Next follows the definition of the STM_ATOMIC and STM_END_ATOMIC macros. 


To access this in the current transaction we use `t.wr_ptr(this)` which return a smart pointer.

If there is a large use of t.wr_ptr(this) it is better to use a variable

        {
            STM_ATOMIC(t) {
                stm::tx_wr_ptr<BankAccount> this_ptr(this,t);
                this_ptr->balance_ += amount;
            } STM_END_ATOMIC
        }

The other `BankAccount` functions are coded as expected. Here is the comple code:

    class BankAccount {
        int balance_;
        using stm:;
    public:
        void Deposit(unsigned amount) {
            STM_ATOMIC(t) {
                t.wr_ptr(this)->balance_ += amount;
            } STM_END_ATOMIC
        }
        void Withdraw(unsigned amount) {
            STM_ATOMIC(t) {
                t.wr_ptr(this)->balance_ -= amount;
            }
        }
        int GetBalance() const {
            STM_ATOMIC(t) {
                return make_tx_rd_ptr(this,t)->balance_;
            } STM_END_ATOMIC
        }
    };

The transfer from accounts is done like:

    void Transfer(BankAccount* inA, BankAccount* outA, int amount) {
        using stm;
        STM_ATOMIC(t) {
            t.wr_ptr(inA)->Withdraw(amount);
            t.wr_ptr(outA)->Deposit(amount);
        } STM_END_ATOMIC
    }

The core of all this stuff is `stm::transaction`, `stm::tx_wr_ptr<>` and `stm::tx_rd_ptr<>`.

The interface of the transaction class is quite simple:

    class transaction {
    public:
        bool commit();
        bool no_throw_commit() throw();
        void abort();

        template <typename T>
        shared_ptr<transactional_object_cache<T> > rd_ptr(T* ptr);

        template <typename T>
        shared_ptr<transactional_object_cache<T> > wr_ptr(T* ptr);

        template <typename T> void delete_memory(T* ptr);
        template <typename T>
        shared_ptr<transactional_object_cache<T> > insert_in_new_cache(T* ptr);

        transaction_state const & state() const;
    };



The smart pointer interfaces follows:

    template <typename T>
    class tx_rd_ptr {
    public:

        typedef T element_type;
        typedef T value_type;
        typedef T * pointer;
        typedef T& reference;

        tx_rd_ptr(T* p, transaction& scope);

        const T* operator->() const;
        const T& operator*() const;
        const T * get() const;
    };


    template <typename T>
    class tx_wr_ptr {
    public:

        typedef T element_type;
        typedef T value_type;
        typedef T * pointer;
        typedef T& reference;

        tx_wr_ptr(T* p, transaction& scope);

        T* operator->() const;
        T& operator*() const;
        T * get() const;

        void delete_ptr();
    };

Let me start with the simple constructor:

        tx_wr_ptr(T* p);

This creates a smart pointer pointing to a specific transaction memory of the current transaction.

It contains the classic functions of a smart pointer overloaded with `const` or non `const`.

        T* operator->() const;
        T& operator*() const;
        T * get() const;

`tx_wr_ptr` points to a writable cache. When we use one of the smart pointer operators,
the pointers points to a upgraded write cache specific to the transaction. In the example

            this_ptr->balance_ += amount;

the use of `this_ptr->balance_` on the left hand side of the assignement operator requires a non const access,
so the upgrade to writable is done.

Every `new`/`delete` operation on a transaction must be in some way signaled to the transaction service.
The new created objects would be wrapped by a `tx_wr_ptr<>` initialized like that;

    tx_wr_ptr<BankAccount> this_ptr(new BackAccount(), is_new);

When we want to delete a pointer in a transaction we use `tx_wr_ptr::delete_ptr`

    tx_wr_ptr<BankAccount> p_ptr(p, t);
    // ...
    p_ptr.delete_ptr();
    
or the short-cut    
    
    t.delete_ptr(p);

Before finishing with the `transaction` class let me show you the
`transactional_object_cache<T>` and its base class `transactional_object_cache_base`.

    class transaction {
    public:
        bool commit();
        bool no_throw_commit();
        void abort();

        template <typename T>
        shared_ptr<transactional_object_cache<T> > read(T* ptr);

        template <typename T>
        shared_ptr<transactional_object_cache<T> > write(T* ptr);

        template <typename T> void delete_memory(T* ptr);
        template <typename T>
        shared_ptr<transactional_object_cache<T> > insert_in_new_cache(T* ptr);

        transaction_state const & state() const;
    };



[endsect]

[endsect]
