\documentclass{netobjectdays}

\newcommand{\Cpp}{C\kern-0.05em\texttt{+\kern-0.03em+}%
}
\newcommand{\mpl}{\code{boost::mpl}}
\newcommand{\mping}{meta\-program\-ming}
\newcommand{\mpgm}{meta\-program}
\newcommand{\mpgms}{meta\-programs}
\newcommand{\mpgmer}{meta\-program\-mer}
\newcommand{\mpgmers}{meta\-program\-mer}
\newcommand{\mfn}{meta\-function}
\newcommand{\mfns}{meta\-functions}

\input{defs}

\begin{document}

\title{The Boost \Cpp\ Template Metaprogramming Library}

\author{Aleksey Gurtovoy$^\dag$ and David Abrahams$^\ddag$ \\
\\
$^\dag$ Meta Communications \\
\texttt{agurtovoy@meta-comm.com}\\
\\
$^\ddag$ Boost Consulting \\
\texttt{david.abrahams@rcn.com}
}

\maketitle

\begin{abstract} $\!$This paper describes the Boost \Cpp template
\mping{} library (\mpl), an extensible compile-time framework
of algorithms, sequences and function classes. The library brings
together important abstractions from the generic and functional
programming worlds to build a powerful and easy-to-use
toolset which makes template \mping{}  practical
enough for the real-world environments. The MPL is heavily influenced
by its run-time equivalent - the Standard Template Library (STL), a
part of the C++ standard library. Like the STL, it defines an open
conceptual and implementation framework which can serve as a
foundation for future contributions in the domain. The library's
fundamental concepts and idioms enable the user to focus on solutions 
without navigating the universe of possible ad-hoc approaches to a 
given \mping{}  problem, even if no actual MPL code is used. 
{\mpl} also provides a compile-time lambda expression facility enabling
arbitrary currying and composition of class templates, a feature whose
runtime counterpart is often cited as missing from the STL. This paper
explains motivation, usage, design, and implementation of \mpl{} 
library, gives some advanced examples of its real-life applications, 
and offers some lessons learned about C++ template \mping{}.
\end{abstract}


\section{Introduction}

\subsection{What is Metaprogramming?}

Metaprogramming is usually defined as the creation of programs which
generate other programs. Parser generators such as YACC are examples
of one kind of program-generating program. The ipnput language to YACC
is a context-free grammar in EBNF, and its output is a program which
parses that grammar. Note that in this case the \mpgm{} (YACC) is
written in a language (`C') which does not directly support the
description of generated programs. These specifications, which we'll
call \emph{meta-data}, are not written in `C', but in a
\emph{meta-language}. Because the the rest of the user's program
typically requires a general-purpose programming system and must
interact with the generated parser, the meta-data is translated into
`C', which is then compiled and linked together with the rest of the
system. The meta-data thus undergoes two translation steps, and the
user is always very conscious of the boundary between his meta-data
and the rest of his program.
% need bibliography reference for YACC

A more interesting form of \mping{} is available in languages
such as Scheme, where the generated program specification is given in
the same language as the \mpgm{} itself. The metaprogrammer
defines his meta-language as a subset of the expressible forms of the
underlying language, and program generation can take place in the same
translation step used to process the rest of the user's program. This
allows users to switch transparently between ordinary programming,
generated program specification, and \mping{}, often without
being aware of the transition.
% bib reference for Scheme metaprogramming

\subsection{Metaprogramming in \Cpp{}}

In \Cpp, it was discovered almost by accident that the template
mechanism provides a rich facility for computation at compile-time. In
this section, we'll explore the basic mechanisms used for
metaprogramming in C++.

\subsubsection{Numeric Computations}

The availability of \emph{non-type template parameters} makes it
possible to perform integer computations at compile-time. For example,
the following tiny meta-function computes the factorial of its
argument:

{\footnotesize
\begin{verbatim}
template <unsigned n>
struct factorial
{
   static const unsigned value = n * factorial<n-1>::value;
};

template <>
struct factorial<0>
{
   static const unsigned value = 1;
};
\end{verbatim}
}

Because of the hard line between the expression of compile-time and
runtime computation in \Cpp, metaprograms look different from their
runtime counterparts. Thus, although as in Scheme the \Cpp\ \mpgmer\
writes her code in the same language as the ordinary program, only a
subset of the language is available to her: those expressions which
can be evaluated at compile-time. Compare the above with a
straightforward runtime definition of the factorial function:

{\footnotesize
\begin{verbatim}
unsigned factorial(unsigned N)
{
   return N == 0 ? 1 : N * factorial(N - 1);
}
\end{verbatim}
}

While it is easy to see the analogy between the two recursive
defintions, recursion is in general more important to \Cpp{}
metaprograms than it is to runtime \Cpp. In contrast to languages such
as Lisp where recursion is idiomatic, \Cpp\ programmers will typically
avoid it when possible. This is done not only for efficiency
reasons, but also because of ``cultural momentum'': recursive programs
are just harder (for \Cpp\ programmers) to think about. Like pure Lisp,
though, the \Cpp\ template mechanism is a \emph{functional} programming
language: as such it rules out the use of data mutation required to
maintain loop variables.

A key difference between the runtime and compile-time factorial
functions is the expression of the termination condition: our
meta-factorial uses template specialization as a kind of
\emph{pattern-matching} mechanism to describe the behavior when
\code{N} is zero. The syntactic analogue in the runtime world would
require two separate definitions of the same function. In this case
the impact of the second definition is minimal, but in large
metaprograms the cost of maintaining and understanding the terminating
definitions can become significant.

\subsubsection{Type Computations}

How could we apply our \code{factorial<>} \mfn{}? We might, for example,
produce an array type of an appropriate size to hold all permutations
of instances of another type:

{\footnotesize
\begin{verbatim}
// permutation_holder<T>::type is an array type which can contain all
// permutations of a given T.

// unspecialized template for scalars
template <class T> struct permutation_holder
{
   typedef T type[1][1];
};

// specialization for array types
template <class T, unsigned N> struct permutation_holder<T[N]>
{
   typedef T type[factorial<N>::value][N];
};
\end{verbatim}
}

Here we have introduced the notion of a \emph{type computation}.  Like
\code{factorial<>} above, \code{permutation\_\-holder<>} is a
\mfn{}. However, where \code{{factorial<>}} manipulates unsigned integer
values, \code{permutation\_\-holder<>} accepts and ``returns'' a
type (as the nested typedef ``\code{type}''). Because the \Cpp\ type
system provides a much richer set of expressions than anything we can
use as a nontype template argument (e.g. the integers), \Cpp\ \mpgms\
tend to be composed mostly of type computations.

\subsection{Why Metaprogramming?}

It's worth asking why anyone would want to do this. After all, even a
simple toy example like the factorial metafunction is somewhat
esoteric. To show how the type computation can be put to work, let's
examine a simple example. The following code produces an array
containing all possible permutations of another array:
{\footnotesize
\begin{verbatim}
// Can't return an array in C++, so we need this wrapper
template <class T>
struct wrapper
{
   T x;
};

// Return an array of the N! permutations of x
template <class T>
wrapper<typename permutation_holder<T>::type>
all_permutations(T const& in)
{
   wrapper<typename permutation_holder<T>::type> result;

   // Copy the unpermuted array to the first result element
   unsigned const N = sizeof(*result.x)/sizeof(**result.x);
   std::copy(&*in, &*in + N, result.x[0]);

   // Enumerate the permutations
   unsigned const result_size = sizeof(result.x)/sizeof(*result.x);
   for (T* dst = result.x + 1; dst != result.x + result_size; ++dst)
   {
       T* src = dst - 1;
       std::copy(*src, *src + N, *dst);
       std::next_permutation(*dst, *dst + N);
   }
   return result;
}
\end{verbatim}
}

The runtime definition of \code{factorial} would be useless in
\code{all\_\-permutations} above, since in \Cpp\ the sizes of array
members must be computed at compile-time. However, there are
alternative approaches; how could we avoid \mping, and what would the
consequences be?

\begin{enumerate}

\item We could write programs to interpret the meta-data directly. In
  our factorial example, the array size could have been a runtime
  quantity; then we'd have been able to use the straightforward
  factorial function. However, that would imply the use of dynamic
  allocation, which is often expensive.

  To carry this further, YACC might be rewritten to accept a
  pointer-to-function returning tokens from the stream to be parsed,
  and a string containing the grammar description. This approach,
  however, would impose unacceptable runtime costs for most
  applications: either the parser would have to treat the grammar
  nondeterministically, exploring the grammar for each parse, or it
  would have to begin by replicating at runtime the substantial
  table-generation and optimization work of the existing YACC for each
  input grammar.

\item We could replace the compile-time computation with our own
  analysis. After all, the size of arrays passed to
  \code{all\_\-permutations} are always known at compile-time, and
  thus can be known to its user. We could ask the user to supply the
  result type explicitly: {\footnotesize
  \begin{verbatim}
template <typename Result, typename T>
Result
all_permutations(T const& input);
  \end{verbatim}
  }
  The costs to this approach are obvious: we give up expressivity (by
  requiring the user to explicitly specify implementation details),
  and correctness (by allowing the user to specify them
  incorrectly). Anyone who has had to write parser tables by hand will
  tell you that the impracticality of this approach is the very reason
  YACC's existence.
\end{enumerate}

So, the motivation for \mping{} comes down to the combination
of three factors: efficiency, expressivity, and correctness.

\subsection{Why a Metaprogramming Library?}


\subsection{What about portability? }
\subsection{Relation to other work.}

\section{Basic usage (What can I do with boost::mpl?)}
\subsection{Sequences, algorithms, and iterators}
\subsection{Function classes, simple composition}
\subsection{Lambda facility}

\section{Design of boost::mpl}
\subsection{Design goals}
\subsection{Design decisions}
\subsubsection{Use of iterators}
\subsubsection{Abstraction of sequences}

\section{An advanced example - compile-time FSM generator}

Finite state machines (FSM) are an important tool of 
describing and implementing controlling program behavior 
[HU79], [Mar98]. They also are a good example of the domain 
where some \mping{} can be applied to reduce the amount of 
repetitive and boilerplate operations one have to perform 
in order to implement these simple mathematical models in 
code. As a further illustration of the tools and techniques 
described early in this paper, below we present a simple 
state machine generator that takes a compile-time automata 
description as its input, and produces a complete and 
efficient FSM implementation as the output, - all within 
the same language (\Cpp\ ), and at compile time.

Suppose we want to implement a simple music player using a 
finite state machine model. The state transition diagram for 
the FSM is shown in Figure 1, and Table 1 present the 
corresponding state transition table (STT). The SST format 
reflects the way one usually describes the behavior of a FSM 
in plain English. For example, the first line of the table 
can be read as follows: "If the model is in the \code{stopped}
state, and the \code{play\_\-event} is received, then the 
\code{do\_\-play} transition function is called, and the model 
goes into the \code{playing} state".

\begin{figure}[t]
\vskip.2in
\caption{Player's state transition diagram.}
\end{figure}

\begin{table}[t]
\caption{Player's state transition table with actions.}
\centering
\begin{verbatim}
  State      Event     Next state  Transition function 
 stopped  play_event     playing   do_play 
 playing  stop_event     stopped   do_stop 
 playing  pause_event    paused    do_pause
 paused   play_event     playing   do_resume
 paused   stop_event     stopped   do_stop
\end{verbatim}
\end{table}

The transition table provides us with complete formal 
definition of the target FSM, and there are sereval ways to 
transform that definition into code. For example, if we define
states as members of enumeration type, and events as classes 
derived from some base %%event%% class (they need to be passed 
to action functions, and they may contain some event-specific 
information for an action), 

{\footnotesize
\begin{verbatim}
class player
{
 public:
    // event declarations
    struct event;
    struct play_event;
    struct stop_event;
    struct pause_event;

    // "input" function
    void process_event(event const&); // throws

 private:
    // states
    enum state_t { stopped, playing, paused };

    // transition functions
    void do_play(play_event const&);
    void do_stop(stop_event const&);
    void do_pause(pause_event const&);
    void do_resume(play_event const&);

 private:
    state_t m_state;
};
\end{verbatim}
}

then the most straightforward way to derive the FSM 
implementation from the above table would be something 
like this:

{\footnotesize
\begin{verbatim}
void
player::process_event(event const& e)
{
    if (m_state == stopped)
    {
        if (typeid(e) == typeid(play_event))
        {
            do_play(static_cast<play_event const&>(e));
            m_state = playing;
            return;
        }
    }
    else if (m_state == playing)
    {
        if (typeid(e) == typeid(stop_event))
        {
            do_stop(static_cast<stop_event const&>(e));
            m_state = stopped;
            return;
        }

        if (typeid(e) == typeid(pause_event))
        {
            do_pause(static_cast<pause_event const&>(e));
            m_state = paused;
            return;
        }
    }
    else if (m_state == paused)
    {
        if (typeid(e) == typeid(stop_event))
        {
            do_stop(static_cast<stop_event const&>(e));
            m_state = stopped;
            return;
        }

        if (typeid(e) == typeid(play_event))
        {
            do_play(static_cast<play_event const&>(e));
            m_state = playing;
            return;
        }
    }
    else
    {
        throw logic_error(
            boost::format("unknown state: %d")
                % static_cast<int>(m_state)
            );
    }

    throw std::logic_error(
        "unexpected event: " + typeid(e).name()
        );
}
\end{verbatim}
}

Note that despite seemed obviousity of optimization of making 
a transition function to return the next state in not such a 
good idea. While it will reduce the amount of lines required 
to describe a single transition, it also would take the 
transition control away from FSM driver function into 
application-level code. For one, that would mean and you'd no 
longer be able to say in what state the machine is going to 
move after it handles a specific event - you'll have to look 
into transition function itself. [...] 

Although there is nothing particulary wrong with implementing 
a FSM's structure using nested \code{if} (or \code{switch-case})
statements, the obvious thing about this approach is that it 
doesn't scale - even for our simple FSM the 
\code{process\_\-event} function is already more than 50 lines
long. One way to reduce the maintainance problems would be to 
factor body's of top-level \code{if} statements in separate 
event processing functions, one for each state:

{\footnotesize
\begin{verbatim}
void
player::process_event(event const& e)
{
    if (m_state == stopped)  m_state = process_stopped_state_event(e);
    else if (m_state == playing) m_state = process_playing_state_event(e);
    else if (m_state == paused) m_state = process_paused_state_event(e);
    else
    {
        throw logic_error(
            boost::format("unknown state: %d")
                % static_cast<int>(m_state)
            );
    }
}
\end{verbatim}
}

where, for example, \code{process\_\-playing\_\-state\_\-event} 
function would look like this:

{\footnotesize
\begin{verbatim}
player::state_t
player::process_stopped_state_event(event const& e)
{
    if (typeid(e) == typeid(stop_event))
    {
        do_stop(static_cast<stop_event const&>(e));
        return stopped;
    }

    if (typeid(e) == typeid(pause_event))
    {
        do_pause(static_cast<pause_event const&>(e));
        return paused;
    }

    throw std::logic_error(
        "unexpected event: " + typeid(e).name()
        );

    return m_state;
}
\end{verbatim}
}

Still, if the number of events being handled from particular 
state is large, the problem remains. Of course, the fact that 
the technique tends to lead to large functions is only one 
side of the problem; after all, you can split the functions 
even further - and that's in fact what the State pattern does.

Another obvious thing about it that most of the code is 
boilerplate. What you tend to do with boilerplate code is copy 
and paste it, and then change names etc. to adjust it to its new 
location, and that's there the errors are most likely to creep in
- since all the lines of events processing look alike 
(structurally), it's very easy to overlook or forget something 
that's need to be changed, and many of such errors won't appear 
until the runtime.

[...]

Note that all the implementions we've looked on has this common 
trait - the transition table of our FSM is just a 5-lines table, 
and ideally, we would like the skeleton implemention of the 
automata's controlling logic to be equally small (or, at least, 
to look equally small, e.g. to be incapsulated in some form so 
we never see/worry about it). 

Implementing it

First thing to think about is how we would like the generator's 
input look like, in particular, how we want to represent a 
transition table. To represent the TTS in \Cpp\ program, we define 
a \code{transition} class template that represents a single line 
of the table, and than the table itself can be represented as a 
sequence of such lines:

{\footnotesize
\begin{verbatim}
typedef list<
      transition<stopped, play_event,  playing, &player::do_play>
    , transition<playing, stop_event,  stopped, &player::do_stop>
    , transition<playing, pause_event, paused,  &player::do_pause>
    , transition<paused,  play_event,  playing, &player::do_resume>
    , transition<paused,  stop_event,  stopped, &player::do_stop>
    >::type transition_table;
\end{verbatim}
}

pros:
\begin{enumerate}
\item readability, direct mapping between a FSM design and 
    implementation ( one-to-one relation between the 
    definition and the state table of the FSM )
\item performance ??
\item compile-time checking 
\item FSM "installation" is done at compile-time; cost 
    nothing in performance 
\item only transition actions need to be implemented 
    (no need to inherit, extend classes, etc.) 
\item entry and exit methods can be supported easily 
    (and will be called automatically); you also don't have 
    to pay for them, if you don't use them 
\end{enumerate}

cons:
\begin{enumerate}
\item can't handle large FSMs (N transitions > 100) 
\item compile times for FSMs with N transitions > 50 
\end{enumerate}


Related work

A notable prior work in the field of automation of general-purpose 
state machine implementation in \Cpp\ is the Robert Martin's State 
Machine Compiler [SMC]. The SMC takes an ASCII description of the 
machine's state transition table and produces a \Cpp\ code that 
implements the FSM using a variation of State design pattern [Hun91],
[GHJ+95]. [Laf00] presents another approach, where no external tools 
are used, and the FSMs are table driven. 


\section{About implementation}

\section{Lessons learned}

\section{Conclusions}
\section{Acknowledgements}
\section{References}

\bibliographystyle{abbrv} \bibliography{refs}

\end{document}
% LocalWords:  Aleksey David Gurtovoy Abrahams MPL STL Boost boost
