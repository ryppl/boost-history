\documentclass{netobjectdays}

\newcommand{\Cpp}{C\kern-0.05em\texttt{+\kern-0.03em+}%
}
\newcommand{\Mpl}{Boost Meta\-program\-ming Library}
\newcommand{\mping}{meta\-program\-ming}
\newcommand{\mpgm}{meta\-program}
\newcommand{\mpgms}{meta\-programs}
\newcommand{\mpgmer}{meta\-program\-mer}
\newcommand{\mpgmers}{meta\-program\-mer}
\newcommand{\mfn}{meta\-function}
\newcommand{\mfns}{meta\-functions}

\input{defs}

\begin{document}

\title{The Boost \Cpp\ Template Metaprogramming Library}

\author{Aleksey Gurtovoy$^\dag$ and David Abrahams$^\ddag$ \\
\\
$^\dag$ Meta Communications \\
\texttt{agurtovoy@meta-comm.com}\\
\\
$^\ddag$ Boost Consulting \\
\texttt{david.abrahams@rcn.com}
}

\maketitle

\begin{abstract} $\!$This paper describes the Boost \Cpp Template
Meta\-program\-ming Library (MPL), an extensible compile-time
framework of algorithms, sequences and function classes. The library
brings together important abstractions from the generic and functional
programming worlds to build a powerful and easy-to-use toolset which
makes template \mping{} practical enough for the real-world
environments. The MPL is heavily influenced by its run-time equivalent
- the Standard Template Library (STL), a part of the C++ standard
library. Like the STL, it defines an open conceptual and
implementation framework which can serve as a foundation for future
contributions in the domain. The library's fundamental concepts and
idioms enable the user to focus on solutions without navigating the
universe of possible ad-hoc approaches to a given \mping{} problem,
even if no actual MPL code is used.  The \Mpl also provides a
compile-time lambda expression facility enabling arbitrary currying
and composition of class templates, a feature whose runtime
counterpart is often cited as missing from the STL. This paper
explains the motivation, usage, design, and implementation of the MPL
with examples of its real-life applications, and offers some lessons
learned about C++ template \mping{}.
\end{abstract}


\section{Introduction}

\subsection{What is Metaprogramming?}

Metaprogramming is usually defined as the creation of programs which
generate other programs. Parser generators such as YACC are examples
of one kind of program-generating program. The ipnput language to YACC
is a context-free grammar in EBNF, and its output is a program which
parses that grammar. Note that in this case the \mpgm{} (YACC) is
written in a language (`C') which does not directly support the
description of generated programs. These specifications, which we'll
call \emph{meta-data}, are not written in `C', but in a
\emph{meta-language}. Because the the rest of the user's program
typically requires a general-purpose programming system and must
interact with the generated parser, the meta-data is translated into
`C', which is then compiled and linked together with the rest of the
system. The meta-data thus undergoes two translation steps, and the
user is always very conscious of the boundary between his meta-data
and the rest of his program.
% need bibliography reference for YACC

A more interesting form of \mping{} is available in languages
such as Scheme, where the generated program specification is given in
the same language as the \mpgm{} itself. The metaprogrammer
defines his meta-language as a subset of the expressible forms of the
underlying language, and program generation can take place in the same
translation step used to process the rest of the user's program. This
allows users to switch transparently between ordinary programming,
generated program specification, and \mping{}, often without
being aware of the transition.
% bib reference for Scheme metaprogramming

\subsection{Metaprogramming in \Cpp{}}

In \Cpp, it was discovered almost by accident that the template
mechanism provides a rich facility for computation at compile-time. In
this section, we'll explore the basic mechanisms and some common
idioms used for metaprogramming in C++.

\subsubsection{Numeric Computations}

The availability of \emph{non-type template parameters} makes it
possible to perform integer computations at compile-time. For example,
the following tiny meta-function computes the factorial of its
argument:

{\footnotesize
\begin{verbatim}
template <unsigned n>
struct factorial
{
   static const unsigned value = n * factorial<n-1>::value;
};

template <>
struct factorial<0>
{
   static const unsigned value = 1;
};
\end{verbatim}
}

Because of the hard line between the expression of compile-time and
runtime computation in \Cpp, metaprograms look different from their
runtime counterparts. Thus, although as in Scheme the \Cpp\ \mpgmer\
writes her code in the same language as the ordinary program, only a
subset of the language is available: those expressions which
can be evaluated at compile-time. Compare the above with a
straightforward runtime definition of the factorial function:

{\footnotesize
\begin{verbatim}
unsigned factorial(unsigned N)
{
   return N == 0 ? 1 : N * factorial(N - 1);
}
\end{verbatim}
}

While it is easy to see the analogy between the two recursive
defintions, recursion is in general more important to \Cpp{}
metaprograms than it is to runtime \Cpp. In contrast to languages such
as Lisp where recursion is idiomatic, \Cpp\ programmers will typically
avoid it when possible. This is done not only for efficiency
reasons, but also because of ``cultural momentum'': recursive programs
are just harder (for \Cpp\ programmers) to think about. Like pure Lisp,
though, the \Cpp\ template mechanism is a \emph{functional} programming
language: as such it rules out the use of data mutation required to
maintain loop variables.

A key difference between the runtime and compile-time factorial
functions is the expression of the termination condition: our
meta-factorial uses template specialization as a kind of
\emph{pattern-matching} mechanism to describe the behavior when
\code{N} is zero. The syntactic analogue in the runtime world would
require two separate definitions of the same function. In this case
the impact of the second definition is minimal, but in large
metaprograms the cost of maintaining and understanding the terminating
definitions can become significant.

Note also that a \Cpp\ \mfn's return value must be \emph{named}. The
name chosen here, \code{value}, is the same one used for all numeric
returns in the \Mpl. As we'll see, establishing a consistent naming
convention for \mfn\ returns is crucial to the power of the library.

\subsubsection{Type Computations}

How could we apply our \code{factorial<>} \mfn{}? We might, for example,
produce an array type of an appropriate size to hold all permutations
of instances of another type:

{\footnotesize
\begin{verbatim}
// permutation_holder<T>::type is an array type which can contain all
// permutations of a given T.

// unspecialized template for scalars
template <class T> struct permutation_holder
{
   typedef T type[1][1];
};

// specialization for array types
template <class T, unsigned N> struct permutation_holder<T[N]>
{
   typedef T type[factorial<N>::value][N];
};
\end{verbatim}
}

Here we have introduced the notion of a \emph{type computation}.  Like
\code{factorial<>} above, \code{permutation\_\-holder<>} is a
\mfn{}. However, where \code{{factorial<>}} manipulates unsigned integer
values, \code{permutation\_\-holder<>} accepts and ``returns'' a
type (as the nested typedef ``\code{type}''). Because the \Cpp\ type
system provides a much richer set of expressions than anything we can
use as a nontype template argument (e.g. the integers), \Cpp\ \mpgms\
tend to be composed mostly of type computations.

\subsubsection{Type Sequences}

The ability to programmatically manipulate collections of types is a
central tool of most interesting \Cpp\ metaprograms. Because this
capability is so well-supported by the MPL, we'll provide just a brief
introduction to the basics here.

First, we'd need a way to represent the collection. One
idea might be to store the types in a structure:

{\footnotesize
\begin{verbatim}
struct types {
  int t1;
  long t2;
  std::vector<double> t3;
};
\end{verbatim}
}

Unfortunately, this arrangement is not susceptible to the compile-time
type introspection power that \Cpp\ gives us: there's no way to find
out what the names of the members are, and even if we assume that
they're named according to some convention as above, there's no way to
now how many members there are. The key to solving this problem is to
increase the uniformity of the representation. If we have a consistent
wayt to get the first type of any sequence and the rest of the
sequence, we can easily access all members:

{\footnotesize
\begin{verbatim}
template <class First, class Rest>
struct cons
{
  typedef First first;
  typedef Rest rest;
};

struct nil {};

typedef
  cons<int, cons<long, cons<std::vector<double>, nil> > >
my_types;
\end{verbatim}
}

The structure described by \code{types} above is the compile-time
analogue of a singly-linked list. Now that we've adjusted the
structure so that the \Cpp\ template machinery can ``peel it apart'',
let's examine a simple function which does so. Suppose a user wished
to find the largest of an arbitrary collection of types. We can apply
the recursive metafunction formula which should by now be familiar:

{\footnotesize
\begin{verbatim}
// Choose the larger of two types
template <class T1, class T2
        , bool choose1 = (sizeof(T1) > sizeof(T2)) // hands off!
        >
struct choose_larger
{
   typedef T1 type;
};

// specialization for the case where sizeof(T2) >= sizeof(T1)
template <class T1, class T2>
struct choose_larger<T1,T2,false>
{
   typedef T2 type;
};

// Get the largest of a cons-list
template <class T> struct largest;

// Specialization to peel apart the cons list
template <class First, class Rest>
struct largest<cons<First,Rest> >
   : choose_larger<First, typename largest<Rest>::type>
{
   // type inherited from base
};

// specialization for loop termination
template <class First>
struct largest<cons<First,nil> >
{
   typedef First type;
};

int main()
{
   // print ht ename of the largest of my_types
   std::cout << typeid(largest<my_types>::type).name()
             << std::endl;
}

\end{verbatim}
}

There are several things worth noticing about this code:
\begin{itemize}

\item It uses a few ad-hoc, esoteric techniques, or ``hacks''. The
  default template argument \code{choose1} (labelled ``hands off!'')
  is one example. Without it, we would have needed yet another
  template to provide the implementation of \code{choose\_\-larger},
  or we would have had to provide the computation explicitly as a
  parameter to the template - perhaps not bad for this example, but it
  would make choose\_\-larger much less useful and more
  error-prone. The other hack is the derivation of a specialization of
  \code{largest} from \code{choose\_\-larger}. This is a code-saving
  device which allows the programmer to avoid writing \code{typedef
  typename}...\code{::type type} in the template body.

\item Even this simple metaprogram uses three separate partial
  specializations. The \code{largest} \mfn\ uses \emph{two}
  specializations. One might expect that this indicates there are two
  termination conditions, but there are not: one specialization is
  needed simply to deal with access to the sequence elements. These
  specializations make the code difficult to read by spreading the
  definition of a single \mfn\ over several \Cpp\ template
  definitions. Also, because they are \emph{partial} specializations,
  they make the code unusable for a large community of \Cpp\
  programmers whose compilers don't support that feature.
\end{itemize}

\subsection{Why Metaprogramming?}

%%% maybe we don't need another example of a metaprogram given what
%%% we've done above? We could rewrite and cut most of this section...

It's worth asking why anyone would want to do this. After all, even a
simple toy example like the factorial metafunction is somewhat
esoteric. To show how the type computation can be put to work, let's
examine a simple example. The following code produces an array
containing all possible permutations of another array:

{\footnotesize
\begin{verbatim}
// Can't return an array in C++, so we need this wrapper
template <class T>
struct wrapper
{
   T x;
};

// Return an array of the N! permutations of x
template <class T>
wrapper<typename permutation_holder<T>::type>
all_permutations(T const& in)
{
   wrapper<typename permutation_holder<T>::type> result;

   // Copy the unpermuted array to the first result element
   unsigned const N = sizeof(T)/sizeof(**result.x);
   std::copy(&*in, &*in + N, result.x[0]);

   // Enumerate the permutations
   unsigned const result_size = sizeof(result.x)/sizeof(T);
   for (T* dst = result.x + 1; dst != result.x + result_size; ++dst)
   {
       T* src = dst - 1;
       std::copy(*src, *src + N, *dst);
       std::next_permutation(*dst, *dst + N);
   }
   return result;
}
\end{verbatim}
}


%%% ...up to this point

The runtime definition of \code{factorial} would be useless in
\code{all\_\-permutations} above, since in \Cpp\ the sizes of array
members must be computed at compile-time. However, there are
alternative approaches; how could we avoid \mping, and what would the
consequences be?

\begin{enumerate}

\item We could write programs to interpret the meta-data directly. In
  our factorial example, the array size could have been a runtime
  quantity; then we'd have been able to use the straightforward
  factorial function. However, that would imply the use of dynamic
  allocation, which is often expensive.

  To carry this further, YACC might be rewritten to accept a
  pointer-to-function returning tokens from the stream to be parsed,
  and a string containing the grammar description. This approach,
  however, would impose unacceptable runtime costs for most
  applications: either the parser would have to treat the grammar
  nondeterministically, exploring the grammar for each parse, or it
  would have to begin by replicating at runtime the substantial
  table-generation and optimization work of the existing YACC for each
  input grammar.

\item We could replace the compile-time computation with our own
  analysis. After all, the size of arrays passed to
  \code{all\_\-permutations} are always known at compile-time, and
  thus can be known to its user. We could ask the user to supply the
  result type explicitly: {\footnotesize
  \begin{verbatim}
template <typename Result, typename T>
Result
all_permutations(T const& input);
  \end{verbatim}
  }
  The costs to this approach are obvious: we give up expressivity (by
  requiring the user to explicitly specify implementation details),
  and correctness (by allowing the user to specify them
  incorrectly). Anyone who has had to write parser tables by hand will
  tell you that the impracticality of this approach is the very reason
  YACC's existence.

  In a language such as \Cpp, where the meta-data can be expressed in
  the same language as the rest of the user's program, expressivity is
  further enhanced: the user can invoke \mpgms\ directly, without
  learning a foreign syntax or interrupting the flow of his code.
\end{enumerate}

So, the motivation for \mping{} comes down to the combination of three
factors: efficiency, expressivity, and correctness. While in classical
programming there is always a tension between expressivity and
correctness on one hand and efficiency on the other, in the \mping\
world we wield new power: can move the computation required for
expressivity from runtime to compile-time.

\subsection{Why a Metaprogramming \emph{Library}?}

One might just as well ask why we need any generic library: 
 
\begin{itemize}

\item Quality. Code that is appropriate for a general-purpose library
  is usually incidental to the purpose of its users. To a library
  developer, it is the central mission. On average, the containers and
  algorithms provided by any given \Cpp\ standard library
  implementation are more-flexible and better-implemented than the
  project-specific implementations which abound, because library
  development was treated as an end in itself rather than a task
  incidental to the development of some other application. With a
  centralized implementation for any given function, optimizations and
  improvements are more likely to have been applied.

\item Re-use. More important even than the re-use of code which all
  libraries provide, a well-designed generic library establishes a
  \emph{framework of concepts and idioms} which establish a reusable
  mental model for approaching problems. Just ast the \Cpp\ Standard
  Template Library gave us iterator concepts and a function object
  protocol, the \Mpl\ provides type-iterators and meta-function class
  protocol. A well-considered framework of idioms saves the \mpgmer{}
  from considering irrelevant implementation details and allows her to
  concentrate on the problem at hand.

\item Portability. A good library can smooth over the ugly realities
  of platform differences. While in theory a \mping\ library is fully
  generic and shouldn't be concerned with these issues, in practice,
  support for templates remains inconsistent even four years after
  standardization. This should perhaps not be surprising: \Cpp\
  templates are the language's furthest-reaching and most complicated
  feature, which largely accounts for the power of \mping\ in \Cpp.

\item Fun. Repeating the same idioms over and over is
  \emph{tedious}. It makes programmers tired and reduces
  productivity. Furthermore, when programmers get bored they get
  sloppy, and buggy code is even more costly than slowly-written
  code. Often the most useful libraries are simply patterns that have
  been ``plucked'' by an astute programmer from a sea of
  repetition. The MPL helps to reduce boredom by eliminating the need
  for the most commonly-repeated boilerplate coding patterns.

\end{itemize}

As you can see, the \Mpl's development is motivated primarily by the
same practical, real-world considerations that justify the development
of any other library. Perhaps this is an indication that template
\mping\ is finally ready to leave the realm of the esoteric and enter
the lingua franca of every day programmers.
%probably this paragraph would be better in the conclusions

\subsection{What about portability? }

\subsection{Relation to other work.}

\section{Basic usage (What can I do with boost::mpl?)}

\subsection{Conditional type selection}

Conditional type selection is the simplest basic construct of \Cpp\
template \mping{}. Veldhuizen [Vel95] was the first to show 
how to implement it, and Czarnecki and Eisenecker [CE00] first 
presented it as a standalone library primitive. The \Mpl\ defines the 
corresponding facility as follows:

%%% It would be a good idea to introduce/motivate the use of true_c/false_c
%%% types in place of bool parameters. 

{\footnotesize
\begin{verbatim}
// definition
template<
      typename Condition
    , typename T1
    , typename T2
    >
struct select_if
{
    typedef implementation-defined type;
};

// usage/semantics
typedef boost::mpl::select_if<boost::mpl::true_c,char,long>::type t1;
typedef boost::mpl::select_if<boost::mpl::false_c,char,long>::type t2;

BOOST_MPL_ASSERT_IS_SAME(t1, char);
BOOST_MPL_ASSERT_IS_SAME(t2, long);
\end{verbatim}
}

The construct is important because template \mpgms{} often 
contain a lot of decision-making code, and, as we will show, 
spelling it manually every time via (partial) class template 
specialization quickly becomes impractical. The template also 
important from the point of encapsulating the compiler 
workarounds (for example, not all \Cpp\ compilers support 
partial template specialization). However, the way \Cpp\ 
template instantiation mechanism works imposes some subtle 
limitations on applicability of the primitive, comparing to 
a manually implemented equivalent of the selection code. 
Below we present ???.

%%% This section digresses into dealing with what I would title
%%% "Delayed Evaluation". While a /very/ important topic, I would
%%% cover it elsewhere, enabling you to avoid using Partial Spec. as
%%% an excuse for dealing with it. Delayed evaluation for correctness
%%% deserves a mention but I think you might have one too many
%%% examples of unsuccessful attempts to deal with it ;-) 

For example, suppose we are implementing a \code{pointed\_\-type}
traits template such as \code{pointed\_\-type<T>::type} instantiated
for a \code{T} that is either a plain pointer
(\code{U*}), \code{std::auto\_ptr<U>}, or any of the \code{boost}
smart pointers, e.g. \code{boost::scoped\_ptr<U>}, will give you 
the pointed type (\code{U}):

{\footnotesize
\begin{verbatim}
BOOST_MPL_ASSERT_IS_SAME(pointed_type<my*>::type, my);
BOOST_MPL_ASSERT_IS_SAME(pointed_type< std::auto_ptr<my> >::type, my);
BOOST_MPL_ASSERT_IS_SAME(pointed_type< boost::scoped_ptr<my> >::type, my);
\end{verbatim}
}

An obvious way to implement \code{pointed\_type} would be to 
use partial specialization to distingiush between plain 
pointers and everything else:

{\footnotesize
\begin{verbatim}
// general case, handles std::auto_ptr and boost pointers
template< typename T >
struct pointed_type
{
    typedef typename T::element_type type;
};

// specialization for plain pointers
template< typename T >
struct pointed_type<T*>
{
    typedef T type;
};
\end{verbatim}
}

but if partial specialization is unavailable, then 
\code{select\_if} seems to be the right tool. Unfortunately,
the straighforward approach does not work:

{\footnotesize
\begin{verbatim}
template< typename T >
struct pointed_type
{
    typedef typename boost::mpl::select_if<
          boost::is_pointer<T>
        , typename boost::remove_pointer<T>::type
        , typename T::element_type // #1
        >::type type;
};

// the following code causes compilation error in line #1:
// name followed by "::" must be a class or namespace name
typedef pointed_type<char*>::type result;
\end{verbatim}
}

Clearly, \code{typename T::element\_type} expression is not 
valid in case of \code{T == char*}, and that's what the 
compiler is complaning about. Implementing the selection code 
manually solves the problem: 

{\footnotesize
\begin{verbatim}
namespace aux {
// general case
template< bool >
struct select_pointed_type
{
    template< typename T > struct result
    {
        typedef typename T::element_type type;
    };
};

// specialization for plain pointers
template<>
struct select_pointed_type<true>
{
    template< typename T > struct result
    {
        typedef typename
            boost::remove_pointer<T>::type type;
    };
};
}

template< typename T >
struct pointed_type
{
    typedef typename aux::select_pointed_type<
          boost::is_pointer<T>::value
        >::template result<T>::type type;
};
\end{verbatim}
}

But this quickly becomes awkward if needs to be done 
repeatedly. We can try to workaround the problem with 
\code{select\_\-if} code as follows:

{\footnotesize
\begin{verbatim}
namespace aux {
template< typename T >
struct element_type
{
	typedef typename T::element_type type;
};
}

template< typename T >
struct pointed_type
{
    typedef typename boost::mpl::select_if<
          boost::is_pointer<T>
        , typename boost::remove_pointer<T>::type
        , typename aux::element_type<T>::type
        >::type type;
};
\end{verbatim}
}

but this does't work either - the access to the 
\code{element\_type<T>}'s nested \code{type} member still 
forces the compiler to instantiate \code{element\_type<T>}
with \code{T == char*}, and that instantiation is of course 
invalid. Also, although in our case this does not lead to a 
compile error, the \code{boost::remove\_pointer<T>} template 
gets always instantiated as well, and for the same reason 
(because we are accessing it's nested \code{type} memeber). 
Such unnecessary instantiation that is not fatal from 
compiler's point of view may or may be not a problem, 
depending on the "weight" of the template (how much the 
instantiation taxes the compiler), but a general rule of 
thumb would be to avoid such code.

Returning to our error, to make the above code compile, we 
need to factor the act of "asking" \code{aux::element\_\-type<T>}
of its nested \code{type} out of the \code{select\_\-if} 
invocation. The fact that both \code{boost::remove\_\-pointer<T>}
trait template and \code{aux::element\_\-type<T>} use the same 
naming convention for their result types makes the refactoring 
easier:

{\footnotesize
\begin{verbatim}
template< typename T >
struct pointed_type
{
 private:
    typedef typename boost::mpl::select_if<
          boost::is_pointer<T>
        , boost::remove_pointer<T>
        , aux::element_type<T>
        >::type func_;

 public:
    typedef typename func_::type type;
};
\end{verbatim}
}

Now the compiler has no reasons instantiate both 
\code{boost::remove\_\-pointer<T>} and 
\code{aux::element\_\-type<T>} even although they are used as 
actual parameters to the \code{select\_if} template (and is 
guaranteed not to do so), so we are guaranteed to get away with 
\code{aux::element\_\-type<char*>} as far as it won't end up being 
selected as \code{func\_}.

The above technique is so common in template metaprograms, that it
even make sense to facilate the selection of nested \code{type} member
by introducing a high level equivalent to \code{select\_if} - the one
that will do \code{func\_::type} operation (that is called [nullary]
function class application) as a part of its invocation.  The \Mpl
provides such template - it's called \code{apply\_if}. Using it, we
can re-write the above code as simple as:

{\footnotesize
\begin{verbatim}
template< typename T >
struct pointed_type
{
    typedef typename boost::mpl::apply_if<
          boost::is_pointer<T>
        , boost::remove_pointer<T>
        , aux::element_type<T>
        >::type type;
};
\end{verbatim}
}

To make our techniques review complete, let's consider a slightly 
different example - suppose we want to define a high-level wrapper 
around \code{boost::remove\_pointer} traits template [], which will 
strip the pointer qualification conditionally. We will call it 
\code{remove\_pointer\_if}:

{\footnotesize
\begin{verbatim}
template<
      typename Condition
    , typename T
    >
struct remove_pointer_if
{
    typedef typename boost::mpl::select_if<
          Condition
        , typename boost::remove_pointer<T>::type
        , T
        >::type type;
};
\end{verbatim}
}

Now the above works from the first time, but it suffers from the 
problem we mentioned early - \code{boost::remove\_pointer<T>} gets 
instantiated even if its result is never used. In metaprogramming 
world compilation time is an important resource [Abr01], and it's 
one of the things that gets wasted by unnecessary template 
instantiations. We've just seen how to deal with the problem in 
case when both arguments to \code{select\_if} template are the 
results of nullary function class applications, but in this example 
one of the arguments - namely \code{T} is just simple a type, so 
the refactoring just doesn't seem possible. An easiest way out of 
this situation would be to pass to \code{select\_if} a real 
nullary function instead of \code{T}, - the one that returns 
\code{T} on its invocation. The \Mpl provides a simple way to do it -
we just substitute \code{T} with \code{boost::mpl::identity<T>},
and \code{boost::select\_if} with more compact 
\code{boost::apply\_if}:

{\footnotesize
\begin{verbatim}
template<
      typename Condition
    , typename T
    >
struct remove_pointer_if
{
    typedef typename boost::mpl::apply_if<
          Condition
        , boost::remove_pointer<T>
        , boost::mpl::identity<T>
        >::type type;
};
\end{verbatim}
}

Which gives us exactly what we wanted.


\subsection{Metafunctions, function classes and lambda}

%%% This intro material needs to come earlier, since you talk about
%%% nullary functions in the previous section.  

A \emph{metafunction} is an entity of a certain structure that
represents a function invocable at compile-time.  In \Cpp\, the basic
underlying language construct of any model of metafunction concept is
a \emph{class template}: it can take types and/or non-type arguments
as actual template parameters and "return" types or non-type values
through its nested type/static const data members
declarations. Obviously, a bare class template is the simplest
possible model of the concept:

{\footnotesize
\begin{verbatim}
// 'plus' metafunction
template<long N1, long N2>
struct plus
{
    static long const value = N1 + N2;
};

// metafunction "invocation"
long const sum = plus<5, 10>::value;
\end{verbatim}
}

Veldhuizen [Vel95] was first to talk about class templates 
as "compile-time functions", and [CE00] have introduced 
"template metafunction" as an equivalent term (they also 
use "metafunction" as the short form). As the definition 
above shows, we use the word "metafunction" as a slightly 
broader term. There are at least two common forms of 
compile-time invocable entities that are used in template 
metaprograms (see Figure 1), and we say "metafunction" when 
we broadly refer to any of those.


{\footnotesize
\begin{verbatim}
// form 1: class template metafunction (ct-metafunction)
template< typename T1, .., typename Tn >
struct f
{
    typedef ... type;
};

// form 2: function class
struct f
{
    template< typename T1, .., typename Tn >
    struct apply
    {
        typedef ... type;
    };
};
\end{verbatim}
}

Figure 1. Two common forms of metafunction concept.

%%% Should make the link between MPL metafunction classes and STL function
%%% objects 

These two forms exist because of some idiosyncrasy in 
how templates are defined in C++, - in particular, because 
of the lack of so called template typedefs [Sut01]. The 
latter makes it unnecessary awkward and tedious to define 
and work with higher-order ct-metafunctions (i.e. class 
template metafunctions that returns another class template 
metafunctions):

%%% Should make the link between template typedefs and closures

{\footnotesize
\begin{verbatim}
// a compile-time equivalent of std::bind1st
template<
      template< typename P1, typename P2 > class F
    , typename T1
    >
struct bind1st
{
    // template< typename U > typedef F<T1, U> type;
    template< typename U > struct type
        : F<T1, U>
    {
    };
};

// a compile-time equivalent of boost::compose_f_gx
template<
      template< typename > class F
    , template< typename > class G
    >
struct compose_f_gx
{
    // template< typename X > 
    // typedef F< typename G<X>::type > type;
    template< typename X > struct type
        : F< typename G<X>::type >
    {
    };
};

template< typename T >
struct some_type_computation
{
    // ...

    // define composite predicate, clumsy!
    template< typename U > struct is_T_or_const_T
        : compose_f_gx<
              bind1st< boost::is_same,T >::template type
            , boost::remove_const
            >::template type<U>
    {
    };

    // do something with it
    typedef find_if< types,is_T_or_const_T >::type itor;
    // ...
};
\end{verbatim}
}

%%% Can you make your case here with just bind1st? compose_f_gx is
%%% probably not too familiar to most people, and the code here is
%%% pretty complicated.

In this example, passing the body of 
\code{is\_T\_or\_const\_T} predicate directly to 
\code{find\_if} would make things a little bit prettier, 

%%% What point are you trying to make here? Consider cutting this.

{\footnotesize
\begin{verbatim}
template< typename T >
struct complex_type_computation
{
    // ...
    // define composite predicate and do something with it
    typedef find_if<
          types
        , compose_f_gx<
              bind1st< boost::is_same,T >::template type
            , boost::remove_const
            >::template type
        >::type itor;
    // ...
};
\end{verbatim}
}

but in general this doesn't scale. 

There are some problems with correctness of the above 
approach as well - deriving the \code{type} members of 
\code{bind1st} and \code{compose\_f\_gx} templates from 
the ct-metafunctions they are composing (\code{F} and 
\code{G}) \emph{changes the type of the result}. 
For instance:

{\footnotesize
\begin{verbatim}
template< typename T1, typename T2 >
struct my
{
    // ...
};

typedef bind1st<my, int>::type<long> result;
typedef my< int,long > expected_result;

BOOST_MPL_ASSERT_IS_SAME(result, expected_result); // fails!
BOOST_STATIC_ASSERT((boost::is_convertible<result,expected_result>::value));
\end{verbatim}
}

This may or may be not a problem, depending on how you 
want to use the result of a type computation algorithm 
that applies higher-order metafunctions internally. 
Unfortunately, within the current language inheritence 
is the only way to "return" a class template.

%%% A marginal issue. We don't have true closures either but it
%%% doesn't seem to cause problems... or maybe it does (we can't declare
%%% a variable to hold the result of bind)

\emph{MORE IMPORTANLY - why representing metafunctions as plain class
templates (ct-metafunctions) is not a option.}


Definitions: 
\begin{itemize}
  \item  A \emph{higher-order function} is a function 
  that can take other functions as arguments, and/or 
  return functions as results. Higher-order functions 
  is one of the distinguishing fetaures of the modern 
  functional languages [Hud89]. 

  \item A function is \emph{polymorphic} if it can 
  take arguments of an arbitrary type (a \Cpp\ term 
  from run-time world would be "generic")
\end{itemize}

\Cpp\ templates are \emph{polymorphic} regarding the type 
arguments (type template parameters) they take. However they 
are not polymorphic regarding ct-metafunctions (class 
template template parameters). In particular, the language 
rules dictate the compiler to enforce \emph{strict arity} of 
the class templates being passed as template template 
parameters. Moreever, polymorphism \emph{between} types and 
ct-metafunctions is not supported, and the syntax of 
"returning" ct-metafunctions is different from syntax of 
returning a type. All this seriously limits the 
applicability of higher-order functions, leads to 
unnecessary code duplication, and has an overall negitave 
effect on the both conceptual and implementation clarity, 
simplicity and size of the library.

%%% I think we should have a separate section to discuss
%%% limitations/complaints about C++ and possible suggestions for ways
%%% to make metaprogramming better. That would allow you to
%%% concentrate focus on ``here's what the lib does, here's how''
%%% where appropriate.

For example, that means that you cannot write a single 
generic metafunction that passes the result of one 
function's execution as the argument to another function:

%%% FWIW, when you start using template template parameters, using
%%% ``typename'' (instead of ``class'') for type template parameters
%%% really hurts readability IMO. We have 3 keywords that look quite
%%% similar: template typedef typename. I undestand the theoretical
%%% reasons for doing it this way.

{\footnotesize
\begin{verbatim}
// won't work if either F or G (or both) a higher-level functions
template<
      template< typename > class F
    , template< typename > class G
    , typename X
    >
struct f_gx
{
    typedef typename F< typename G<X>::type >::type type;
};

// how we have to write it if G returns F takes an unary ct-metafunction
template<
      template< template< typename > class > class F
    , template< typename > class G
    , typename X
    >
struct f_gx2
{
    typedef typename F< G<X>::template type >::type type;
};

// and another one for a binary ct-metafunction, etc.
template<
      template< template< typename, typename > class > class F
    , template< typename > class G
    , typename X
    >
struct f_gx3
{
    typedef typename F< G<X>::template type >::type type;
};
\end{verbatim}
}

Or, for example, that means that you cannot have a list of 
ct-metafunctions:

{\footnotesize
\begin{verbatim}
template< typename T1, typename T2 >
struct my_func
{
    typedef /* ... */ type;
};

typedef boost::mpl::list< 
      my_func
    , boost::is_same
    , boost::is_convertible
    > func_list; // error!
\end{verbatim}
}

You would need to have a special kind of list to do the above, 
and then yet another special kind of list for \emph{unary} 
ct-metafunction, etc.

So, basically, representing metafunctions as plain class 
template would lead to duplication of almost every library 
facility. "function class" metafunction form solves all these 
problems. On the other hand, it seems that accepting function 
classes as \emph{the} form of representation of compile-time 
function entites imposes code duplication danger in as well: 
if the library's own primitives, algorithms, etc. are 
represented as class templates, that means that you either 
cannot reuse these algorithms in context of higher-order 
functions, or you have to duplicate all algorithms in second 
form, so, for instance, there would be two versions of 
\code{find}:

{\footnotesize
\begin{verbatim}
// user-friendly form
template<
      typename Sequence
    , typename T
    >
struct find
{
    typedef /* ... */ type;
};

// "function class" form
struct find
{
    template< typename Sequence, typename T >
    struct apply
    {
        typedef /* ... */ type;
    };
};
\end{verbatim}
}

Of course, the third option is to eliminate 
"user-friendly form" completely so one would always 
have to write

{\footnotesize
\begin{verbatim}
typedef boost::mpl::find::apply<list,long>::type iter;
// or, if you prefer,
// typedef boost::mpl::apply< boost::mpl::find,list,long >::type iter;
\end{verbatim}
}

instead of 

{\footnotesize
\begin{verbatim}
typedef boost::mpl::find<list,long>::type iter;
\end{verbatim}
}

but that's would hurt usability, considering that the direct 
invocations of library's algorithms are more often-used than 
passing algorithms as arguments to another 
algorithms/functions. 

The library's answer to this dilemma is lambda expressions. 
Lambda is the mechanism that enables curring of 
ct-metafunctions and converting them into function classes, 
so when you want to pass \code{find} algorithm as an argument 
to a higher-oder function, you just write:

{\footnotesize
\begin{verbatim}
typedef boost::mpl::apply< my_f, boost::mpl::find<_1,_2> >::type result;
\end{verbatim}
}

and then you want just use \code{find} directly in your code, 
you still have the intuitive

{\footnotesize
\begin{verbatim}
typedef boost::mpl::find<list,long>::type iter;
\end{verbatim}
}


[to be continiued]

%%% Should say ``metafunction classes'' below?

Metafunctions are important by encapsulating an operation into 
compile-time invocable entity, they give you a possibility to 
defer its execution. You can store the entity, pass it around, 
and invoke the operation at any time you need.

\subsection{Sequences, algorithms, and iterators}

Compile-time iteration over a sequence (of types) is one of 
the basic concept of template metaprogramming. Difference in 
types of objects being manipulated is the most common point 
of variability of similar but not identical code/design, and 
such designs are the direct target for some metaprogramming. 
Templates in their original usage were intended to be used to 
solve this exact problem, (std::vector), but without predefined 
abstractions/constructs for manipulating/iterating 
\emph{sequences} of types instead of stanalone types, and 
without developed (known) techniques for emulating this 
constructs using the current language facilities, they effect 
on helping high-level metaprogramming happen has been limited. 

Czarnecki and Eisenecker [CE00] were the first to introduce 
the compile-time sequences of types and some simple algorithms 
on them, although the idea of representation common data 
structures like trees, lists, etc. at compile time using class 
template composition has been around for a while (for example, 
most of the expression template libraries build such trees as 
a part of their expression "parsing" process [Vel95b]). 
[Ale00] used list of types and some algorithms on them to 
implement several design patterns; the accompanishing code 
is known as the Loki library []. 

\emph{OLD introduction:}

A possibility to represent and manipulate theoreticaly 
unbound sequences of types and values at compile time opens an 
exciting opportunities for creating highly reusable, 
configurable, and amazingly easy-to-use generic components and 
classes [CE00, Ale01]. Compile-time-operable collections of 
types (and, to a slightly less extent, values) are at least as 
important in generic and template metaprogramming as their 
run-time equivalents in traditional programming. 
The \Mpl acknowledges this assertion by providing an 
STL-like framework of sequence, algorithm and function classes 
that can significantly simplify building of complex 
generic/generative components/systems. 

Topics to cover:

\subsubsection{Algorithms Operate on Sequences}
  
Most of algorithms in \Mpl\ operates on sequences. For example, 
searching type in a list looks like this:

{\footnotesize
\begin{verbatim}
typedef boost::mpl::list< char,short,int,long,float,double > types;
typedef boost::mpl::find< types,long >::type iter;
\end{verbatim}
}

Here, \code{find} accepts two parameters - a sequence where to 
search in (\code{types}), the type to search for (\code{long}), 
and returns an iterator \code{iter} pointing to the first 
element of the sequence such as \code{iter::type} is identical 
to \code{long}; if no such element exist, then \code{iter} is 
identical to \code{end<types>::type}. Basically, this is how one 
would search for a value in \code{std::list} or 
\code{std::vector}, except that \code{boost::mpl::find} accepts 
a sequence where to search as a whole, while \code{std::find} 
takes two iterators. 
Everything else is pretty much the same - the names are the same, 
the semantics is very close, there are iterators, and you can 
search not only by type, but using a predicate as well:

{\footnotesize
\begin{verbatim}
typedef boost::mpl::find_if< types,boost::is_float >::type iter;
\end{verbatim}
}

This conceptual/syntactical similarity with the STL is not 
coincidental. Reusing the conceptual framework of STL in 
compile-time world allows us to bring a familiarity and a whole 
bunch of well-known and sound approaches of dealing with 
sequential data structures there. The algorithms and idioms 
which programmers already know from STL can be applied again at 
compile-time. We consider this to be one of the main strong 
points that distinguish the library from other, mostly ad-hoc 
attempts of building a template metaprogramming library.
  

\subsubsection{Sequence Concepts}

In the \code{find} example above we searched for type in the 
sequence built using \code{boost::mpl::list} template, but 
\code{list} is not the only sequence that the library provides 
you with, nor the \code{boost::mpl::find} or any other 
algorithm is hard-coded to work only on the single 
\code{list} sequence. \code{list} is just one of the models of 
MPL's ForwardSequence concept, and \code{find} works with 
anything that satisfies this concept's requirements. The 
hierarchy of sequence concepts in \Mpl is quite simple - a 
Sequence is any compile-time entity to that you can apply 
\code{begin}/\code{end} operations in order to get iterators 
for accessing the range of its elements, a ForwardSequence 
is a sequence that provides iterators what satisfy 
ForwardIterator requirements, a BidirectionalSequence is a 
ForwardSequence that provides iterators what satisfy 
BidirectionalIterator requirements, and, finally, 
RandomAccessSequence is a BidirectionalSequence that provides 
iterators what satisfy RandomAccessIterator requirements. 

Decoupling algorithms from particular sequence implementation 
(through iterators) allows one to create her own sequence 
types, and still be able to have the rest of the library at 
her disposal. For example, you can define a \code{tiny\_\-list}
for dealing with sequences of 3 types as follows:

{\footnotesize
\begin{verbatim}
template< typename TinyList, long Pos >
struct tiny_list_item;

template< typename TinyList, long Pos >
struct tiny_list_iterator
{
    typedef typename tiny_list_item<TinyList,Pos>::type type;
    typedef tiny_list_iterator<TinyList, Pos-1> prior;
    typedef tiny_list_iterator<TinyList, Pos+1> next;
};

template< typename T0, typename T1, typename T2 >
struct tiny_list
{
    typedef tiny_list_iterator<tiny_list, 0> begin;
    typedef tiny_list_iterator<tiny_list, 3> end;
    typedef T0 type0;
    typedef T1 type1;
    typedef T2 type2;
};

template< typename TinyList >
struct tiny_list_item<TinyList,0>
{ typedef typename TinyList::type0 type; };

template< typename TinyList >
struct tiny_list_item<TinyList,1>
{ typedef typename TinyList::type1 type; };

template< typename TinyList >
struct tiny_list_item<TinyList,2>
{ typedef typename TinyList::type2 type; };
\end{verbatim}
}

and then use it with any of the library algorithms as if it 
was \code{boost::mpl::list}:

{\footnotesize
\begin{verbatim}
typedef tiny_list< char,short,int > types;
typedef boost::mpl::transform<
      types
    , boost::add_pointer
    >::type pointers;
\end{verbatim}
}

Note that \code{tiny\_list} is a model of 
BidirectionalSequence (it would be RandomAccess if 
we added \code{advance} memeber to \code{tiny\_\-list\_\-iterator}:

{\footnotesize
\begin{verbatim}
template< typename TinyList, long Pos >
struct tiny_list_iterator
{
    typedef typename tiny_list_item<TinyList,Pos>::type type;
    typedef tiny_list_iterator<TinyList, Pos-1> prior;
    typedef tiny_list_iterator<TinyList, Pos+1> next;
    template< typename N > struct advance
    {
        typedef tiny_list_iterator<
              TinyList
            , Pos + N::value
            > type;
    };
};
\end{verbatim}
}

).

While the \code{tiny\_list} itself might be not that 
interesting - after all, it can hold only 3 elements, if 
the technique above can be automated so we would be able to 
define not so tiny sequence - with 5, 10, 20, etc. number 
of elements, when it would be very valuable (random access 
is almost as important at compile-time as it is at run-time 
- for example searching something in a sorted random-access 
sequence using \code{lower\_bound} can be up to N 
[need to measure!] time faster than doing the same operation 
on forward-access only \code{list}). External code generation 
is one option here, but there is also a solution within the 
language, although it's not a template metaprogramming, 
but preprocessor metaprogramming [PRE]. In fact, 
\code{mpl::vector} - a fixed-size type sequence that 
provides random-access iterators - is implemented very like 
the above \code{tiny\_list}. 

\subsubsection{Why Library-Provided Iteration is Important}

So, the library provides you with almost complete compile-time 
equivalent of STL framework. Does it help you to solve you 
metaprogramming tasks? Let's return to our \code{largest} 
example to see if we can rewrite it in a better way with what 
\code{boost::mpl} has to offer. Well, actually there is not 
much to look at, because implementation of it with MPL is a 
one-liner:

{\footnotesize
\begin{verbatim}
template< typename Sequence >
struct largest
{
    typedef typename boost::mpl::max_element<
          Sequence
        , boost::mpl::less<
              boost::mpl::size_of<_1>
            , boost::mpl::size_of<_2>
            >
        >::type type;
};
\end{verbatim}
}

%%% agurt: I sound like a sales person below :)
No more termination conditions with a tricky patterns matching, 
no more partial specializations, and that's even more important, 
it's \emph{obvious} that's the above code does - even although 
it's all templates - something that you cannot say about the 
original version.

\subsubsection{iter\_fold/iter\_find as two main iteration 
algortihms}

For the purpose of examination a little bit more of the 
library's internal structure, let's look at how the 
\code{max\_element} algorithm from the above example is 
implemented. One might expect that \emph{now} we will again 
see all these awkward partial specializations, esoteric 
patterns matching, etc. Well, let's see:

{\footnotesize
\begin{verbatim}
namespace aux {
template< typename Predicate >
struct select_max
{
    template< typename OldIterator, typename Iterator >
    struct apply
    {
        typedef typename mpl::apply<
              Predicate
            , typename OldIterator::type
            , typename Iterator::type
            >::type condition_;

        typedef typename mpl::select_if<
              condition_
            , Iterator
            , OldIterator
            >::type type;
    };
};
} // namespace aux 

template<
      typename Sequence
    , typename Predicate
    >
struct max_element
{
    typedef typename mpl::iter_fold<    
          Sequence
        , typename mpl::begin<Sequence>::type
        , aux::select_max<Predicate>
        >::type type;
};
\end{verbatim}
}

First thing to notice here is that this algorithm is in fact 
implemented in terms of another one - \code{iter\_fold}. 
In fact, this is probably the most important point of the 
example, because all other generic sequence algorithms in 
the library are implemented either in terms of \code{iter\_fold}
(or it's counterpart \code{find\_if}) as well. In particular, 
that means that if you would ever need to implement your own 
sequence algorithm, there is a huge chance that you'll be able 
to do it using either \code{iter\_fold} or \code{find\_if} - 
in other words, that means that you won't have to resort to 
implementing hand-crafted iteration and everything that is 
associated with it (patterns matching/special cases for 
termination condition, workarounds for lack of partial 
specialization, etc.) yourself. Also, that means that if the 
library took special care for making such iteration as much 
effective as it's possible (for example, using such techniques 
as recursion unrolling), your brand-new algorithm will 
automatically benefit from these optimizations as well. And of 
course it means that your algorithm will work with any 
sequence that is a model of \code{boost::mpl}'s 
ForwardSequence, because it's the only requirement of 
\code{iter\_fold}/\code{find\_if} pair.

\code{iter\_fold} is basically a compile-time equivalent of 
\code{fold}/\code{reduce} functions that are one of the basic 
and well-known primitives in many functional programming 
languages. A more familiar to a \Cpp\ programmer analogy would 
be \code{std::accumulate} algorithm from the \Cpp\ standard 
library. \code{iter\_fold} is defined in \code{boost::mpl} 
as follows:

{\footnotesize
\begin{verbatim}
template<
      typename Sequence
    , typename InitialState
    , typename ForwardOp
    , typename BackwardOp = identity<_1>
    >
struct iter_fold
{
    typedef implementation-defined type;
};
\end{verbatim}
}

The algorithm returns the result of two-way successive 
applications of binary \code{ForwardOp} and \code{BackwardOp}
operations to iterators in range 
[\code{begin<Sequence>::type}, \code{end<Sequence>::type}) 
and previous result of an operation; 
the \code{InitialState} is logically placed before the 
sequence and included in the forward traversal. The result 
\code{type} is identical to the \code{InitialState} if the 
sequence is empty. 
The library also provides a little bit more high-level 
\code{fold} and \code{fold\_reverse} algorithms that wrap 
\code{iter\_fold} to accommodate it's most common usage 
patterns.

You may wonder why \code{find\_if} - which seems to be much 
more high-level - is placed on the same line with the 
\code{iter\_fold}. Well, one thing about it is that 
\code{find\_if} is the only sequence algorithm that is not 
itself implemented using \code{iter\_fold}. The key difference 
is that \code{find\_if} \emph{terminates} the iteration as 
soon as its predicate satisfied, while \code{iter\_fold} 
always iterates the whole sequence (backward and forward). 
An obviuos generalization here would be to add yet another 
parameter to \code{iter\_fold} so it become possible to 
implement everything in terms of the single iteration 
metafunction, but we decided that this would be an 
overgeneralization. For one, it would mean that the 
termination codition would be always calculated even 
although for most uses of \code{iter\_fold} it's not needed. 
An overhead like this just goes against the library's strike 
for maximum compile-time performance.


\subsubsection{Sequences of Types, but there are Shorcuts for Numbers}

What we've seen so far were sequences (and algorithms on 
sequences) of types. It's very much possible and easy to 
manipulate values using the library as well. The only thing 
to remember is that in \Cpp\ class template non-type template 
parameters is one more example of non-polymorphic behavior (??).
That means, that if you declared a metafunction to take a 
non-type template parameter - let's say \emph{long} - 
it's not possible to pass anything besides compile-time 
intergal constants to it:

{\footnotesize
\begin{verbatim}
template< long N1, long N2 >
struct equal_to
{
    static bool const value = (N1 == N2);
};

equal_to<5,5>::value; // ok
equal_to<int,int>::value; // error!
\end{verbatim}
}

And of course this doesn't work the other way around either:

{\footnotesize
\begin{verbatim}
typedef mpl::list<1,2,3,4,5> numbers; // error!
\end{verbatim}
}

While this may be an obvious limitation, it imposes yet 
another dilemma on the library design - on one hand, we don't 
want to restrict users to type namipulations only, and on another 
hand, full support for intergal manipulations would require at 
least duplication of most of the library facilities (ideally, 
if going this route, all the templates should be reimplemented 
for every integral type - \code{char}, \code{int}, \code{short},
\code{long}, etc.) - the same situation as we would have if we 
choosed to represent metafunctions as ordinary class templates.
The solution for this issue is the same as well - we represent 
integral values by wrapping them in types, so, for example, to 
create a list of numbers you write:

{\footnotesize
\begin{verbatim}
typedef mpl::list<
      mpl::int_c<1>
    , mpl::int_c<2>
    , mpl::int_c<3>
    , mpl::int_c<4>
    , mpl::int_c<5>
    > numbers;
\end{verbatim}
}

Wrapping integral constants into types to make them 
first-class citizens is important well inside metaprograms, 
where you often don't know (and don't care) if the 
metafunctions you are using operate on types, intergal 
values, other metafunctions, or something else, like 
fixed-point or rational numbers (\code{mpl::fixed\_c} 
and \code{mpl::rational\_c}).

But from user's perspective, the above example is much more
verbose than the shorter one, the one that was incorrect. So, 
for the convenience purposes, the library does provide users 
with a template that takes non-type template parameters, but 
allows a more compact notaion:

{\footnotesize
\begin{verbatim}
typedef mpl::list_c<long,1,2,3,4,5> numbers;
\end{verbatim}
}

There is a similar \code{vector} counterpart as well:

{\footnotesize
\begin{verbatim}
typedef mpl::vector_c<long,1,2,3,4,5> numbers;
\end{verbatim}
}


\subsubsection{Why External Functions for all Algorithms}

\begin{enumerate}
 \item while the nested functions notation in some cases is 
 less verbose, 

{\footnotesize
\begin{verbatim}
typedef mpl::list<char,short,int,long> types;
typedef mpl::select_if<
      types::empty
    , long
    , types::back
    >::type t;
\end{verbatim}
}

it is also less generic/more intrusive; requiring a sequence 
class to implement \code{size}, \code{empty}, \code{at}, etc. 
algorithms as members is often unnecessary and over restrictive. 
In many cases the default implementations provided by the library 
are sufficient.
Currently the only requirement that a "foreign" sequence should 
conform to in order to be used with the library algorithms is to 
implement external \code{begin}/\code{end} metafunctions; you 
don't have to modify your sequence code; with the requirement to 
provide these as nested functions that wouldn't be the case anymore. 

\item if a nested function has at least one argument, and it's 
invoked on a sequence that is a template parameter, or depends 
on a template parameter, the notation actually becomes more 
verbose, e.g. 

{\footnotesize
\begin{verbatim}
struct my_func
{
    template< typename Sequence, typename N > struct apply
    {
        // invoking 'at' nested metafunction on a Sequence class
        typedef typename Sequence::template at<N>::type type;
    };
};
\end{verbatim}
}

comparing to the current 

{\footnotesize
\begin{verbatim}
struct my_func
{
    template< typename Sequence, typename N > struct apply
    {
        typedef typename mpl::at< N,Sequence >::type type;
    };
};
\end{verbatim}
}

\item placing functions inside of a sequence class makes 
impossible to pass them around as predicates/function classes: 

{\footnotesize
\begin{verbatim}
typedef mpl::list< seq1,seq2,seq3 > sequences; // list of sequences
// find first non-empty sequence
typedef mpl::find_if< sequences, mpl::size<_1> >::type itor;
\end{verbatim}
}

instead, you have to write an explicit predicate for every such case, 

{\footnotesize
\begin{verbatim}
struct size_pred
{
    template< typename Sequence > struct apply
    {
        typedef typename Sequence::size type;
    };
};

// find first non-empty sequence
typedef mpl::find_if< sequences,size_pred >::type itor;
\end{verbatim}
}

\end{enumerate}

 
  \subsubsection{sequences of types, but there are shorcuts for numbers}

  \subsubsection{A Variety of Sequences}

Previous efforts to provide generalized /mping/ facilities for C++
have always concentrated on \code{cons}-style type lists and a few
core algorithms like 'size' and 'at' which are tied to the specific
sequence implementation. Such systems have an elegant simplicity
reminiscent of the analogous functionality in pure functional Lisp. It
is much more time-consuming to implement even a basic set of the
sequence algorithms provided by equivalent run-time libraries (STL in
particular), but if we have learned anything from the STL it is that
tying those algorithms' implementations to a specific sequence
implementation is a misgiuded effort!

The truth is that there is no single ``best'' type sequence
implementation for the same reasons that there will never be a single
``best'' runtime sequence implementation. Furthermore, there are
\emph{already} quite a number of type list implementations in use
today, and just as the STL algorithms can operate on sequences which
don't come from STL containers, so the MPL algorithms are designed to
work with foreign type sequences.

It may be an eye-opening fact for some that type lists are not the
only useful compile-time sequence. Again, the need for a variety of
compile-time containers arises for the same reasons that we have
lists, vectors, deques, and sets in the /Cpp/ standard library -
different containers have different functional and performance
characteristics which determine not only applicability and efficiency
of particular algorithms, but also the expressiveness or verbosity of
the code that uses them. While runtime performance is not an issue for
\Cpp\ metaprograms, compilation speed is often a significant
bottleneck to advanced \Cpp\ software development[Abr01].

The \Mpl\ provides four built-in sequences: \code{type\_\-list},
\code{value\_\-list} (really just a \code{type\_\-list} of value
wrappers), \code{type\_\-vector}, a randomly-accessible sequence of
fixed maximum size, and \code{range\_c}, a randomly-accessible
sequence of consecutive integral values. More important, however, is
its ability to adapt to arbitrary sequence types. The only core
operations that a sequence is required to provide in order to be used
with the library algorithms are \code{begin<>} and \code{end<>} \mfns\
which ``return'' iterators into to the sequence. As in the STL it is
the iterators which are used to implement most of the general purpose
sequence algorithms the library provides. Also as in STL, algorithm
specialization is used to take advantage of implementation knowledge
about particular sequences: many of the ``basic'' sequence operations
such as \code{back<>}, \code{front<>} \code{size<>} and \code{at<>}
are specialized on sequence type to provide a more efficient
implementation than the fully generic version.


  \subsubsection{loop unrolling}
  \subsubsection{numbered forms of \code{list}}
  \subsubsection{algorithm support lambda}


\subsection{Lambda facility}

\section{Design of boost::mpl}
\subsection{Design goals}
\subsection{Design decisions}
\subsubsection{Use of iterators}
\subsubsection{Abstraction of sequences}

\section{An advanced example - compile-time FSM generator}

Finite state machines (FSM) are an important tool of 
describing and implementing controlling program behavior 
[HU79], [Mar98]. They also are a good example of the domain 
where some \mping{} can be applied to reduce the amount of 
repetitive and boilerplate operations one have to perform 
in order to implement these simple mathematical models in 
code. As a further illustration of the tools and techniques 
described early in this paper, below we present a simple 
state machine generator that takes a compile-time automata 
description as its input, and produces a complete and 
efficient FSM implementation as the output, - all within 
the same language (\Cpp\ ), and at compile time.

Suppose we want to implement a simple music player using a 
finite state machine model. The state transition diagram for 
the FSM is shown in Figure 1, and Table 1 present the 
corresponding state transition table (STT). The SST format 
reflects the way one usually describes the behavior of a FSM 
in plain English. For example, the first line of the table 
can be read as follows: "If the model is in the \code{stopped}
state, and the \code{play\_\-event} is received, then the 
\code{do\_\-play} transition function is called, and the model 
goes into the \code{playing} state".

\begin{figure}[t]
\vskip.2in
\caption{Player's state transition diagram.}
\end{figure}

\begin{table}[t]
\caption{Player's state transition table with actions.}
\centering
\begin{verbatim}
  State      Event     Next state  Transition function 
 stopped  play_event     playing   do_play 
 playing  stop_event     stopped   do_stop 
 playing  pause_event    paused    do_pause
 paused   play_event     playing   do_resume
 paused   stop_event     stopped   do_stop
\end{verbatim}
\end{table}

%%% can we kill the ``_event'' suffix here?

The transition table provides us with complete formal 
definition of the target FSM, and there are sereval ways to 
transform that definition into code. For example, if we define
states as members of enumeration type, and events as classes 
derived from some base \code{event}
class (they need to be passed to action functions, and they may
contain some event-specific information for an action), 

{\footnotesize
\begin{verbatim}
class player
{
 public:
    // event declarations
    struct event;
    struct play_event;
    struct stop_event;
    struct pause_event;

    // "input" function
    void process_event(event const&); // throws

 private:
    // states
    enum state_t { stopped, playing, paused };

    // transition functions
    void do_play(play_event const&);
    void do_stop(stop_event const&);
    void do_pause(pause_event const&);
    void do_resume(play_event const&);

 private:
    state_t m_state;
};
\end{verbatim}
}

%%% IMO this implementation bends over backward to be inefficient. My
%%% first thought would have been:
%%
%%     // "input" function
%%     template <class Event>
%%     void process_event(Event const&); // throws
%%
%%  private:
%%     // states
%%     enum state_t { stopped, playing, paused };
%%
%%     // transition functions
%%     void transition(play_event const&);
%%     void transition(stop_event const&);
%%     void transition(pause_event const&);
%%     void transition(play_event const&);
%%
%%% Which avoids RTTI AFAICT.
%%%
%%% And then, once I realized that it wouldn't work ;-) I would have
%%% used an event base class which contained its own event ID. There
%%% are lots of ways to achieve this:
%%
%% struct event_base
%% {
%%   event_base(unsigned id) : m_id(id) {}
%% protected:
%%   static unsigned counter;
%% private:
%%   unsigned m_id;
%% };
%% template <class Event> struct event : event_base
%% {
%%    event() : event_base(id) {}
%%    virtual ~event();
%%    static unsigned id;
%% };
%% template <class Event> struct event_base<Event>::id = counter++;
%% struct play : event<play> { ... };

then the most straightforward way to derive the FSM 
implementation from the above table would be something 
like this:

{\footnotesize
\begin{verbatim}
void
player::process_event(event const& e)
{
    if (m_state == stopped)
    {
        if (typeid(e) == typeid(play_event))
        {
            do_play(static_cast<play_event const&>(e));
            m_state = playing;
            return;
        }
    }
    else if (m_state == playing)
    {
        if (typeid(e) == typeid(stop_event))
        {
            do_stop(static_cast<stop_event const&>(e));
            m_state = stopped;
            return;
        }

        if (typeid(e) == typeid(pause_event))
        {
            do_pause(static_cast<pause_event const&>(e));
            m_state = paused;
            return;
        }
    }
    else if (m_state == paused)
    {
        if (typeid(e) == typeid(stop_event))
        {
            do_stop(static_cast<stop_event const&>(e));
            m_state = stopped;
            return;
        }

        if (typeid(e) == typeid(play_event))
        {
            do_play(static_cast<play_event const&>(e));
            m_state = playing;
            return;
        }
    }
    else
    {
        throw logic_error(
            boost::format("unknown state: %d")
                % static_cast<int>(m_state)
            );
    }

    throw std::logic_error(
        "unexpected event: " + typeid(e).name()
        );
}
\end{verbatim}
}

%%% Not sure the part below is too relevant
Note that despite seemed obviousity of optimization of making 
a transition function to return the next state in not such a 
good idea. While it will reduce the amount of lines required 
to describe a single transition, it also would take the 
transition control away from FSM driver function into 
application-level code. For one, that would mean and you'd no 
longer be able to say in what state the machine is going to 
move after it handles a specific event - you'll have to look 
into transition function itself. [...] 

Although there is nothing particulary wrong with implementing 
a FSM's structure using nested \code{if} (or \code{switch-case})
statements, the obvious thing about this approach is that it 
doesn't scale - even for our simple FSM the 
\code{process\_\-event} function is already more than 50 lines
long. One way to reduce the maintainance problems would be to 
factor body's of top-level \code{if} statements in separate 
event processing functions, one for each state:

%%% I think a simple example of a switch statement from a naive lexer
%%% implementation would suffice to show why the switch/if approach is
%%% bad, and we could afford to show just a single example of this,
%%% taking it on faith that people will understand.

{\footnotesize
\begin{verbatim}
void
player::process_event(event const& e)
{
    if (m_state == stopped)  m_state = process_stopped_state_event(e);
    else if (m_state == playing) m_state = process_playing_state_event(e);
    else if (m_state == paused) m_state = process_paused_state_event(e);
    else
    {
        throw logic_error(
            boost::format("unknown state: %d")
                % static_cast<int>(m_state)
            );
    }
}
\end{verbatim}
}

where, for example, \code{process\_\-playing\_\-state\_\-event} 
function would look like this:

{\footnotesize
\begin{verbatim}
player::state_t
player::process_stopped_state_event(event const& e)
{
    if (typeid(e) == typeid(stop_event))
    {
        do_stop(static_cast<stop_event const&>(e));
        return stopped;
    }

    if (typeid(e) == typeid(pause_event))
    {
        do_pause(static_cast<pause_event const&>(e));
        return paused;
    }

    throw std::logic_error(
        "unexpected event: " + typeid(e).name()
        );

    return m_state;
}
\end{verbatim}
}

Still, if the number of events being handled from particular 
state is large, the problem remains. Of course, the fact that 
the technique tends to lead to large functions is only one 
side of the problem; after all, you can split the functions 
even further - and that's in fact what the State pattern does.

%%% This is a good point
Another obvious thing about it that most of the code is 
boilerplate. What you tend to do with boilerplate code is copy 
and paste it, and then change names etc. to adjust it to its new 
location, and that's there the errors are most likely to creep in
- since all the lines of events processing look alike 
(structurally), it's very easy to overlook or forget something 
that's need to be changed, and many of such errors won't appear 
until the runtime.

[...]

Note that all the implementions we've looked on has this common 
trait - the transition table of our FSM is just a 5-lines table, 
and ideally, we would like the skeleton implemention of the 
automata's controlling logic to be equally small (or, at least, 
to look equally small, e.g. to be incapsulated in some form so 
we never see/worry about it). 

Implementing it

First thing to think about is how we would like the generator's 
input look like, in particular, how we want to represent a 
transition table. To represent the TTS in \Cpp\ program, we define 
a \code{transition} class template that represents a single line 
of the table, and than the table itself can be represented as a 
sequence of such lines:

{\footnotesize
\begin{verbatim}
typedef list<
      transition<stopped, play_event,  playing, &player::do_play>
    , transition<playing, stop_event,  stopped, &player::do_stop>
    , transition<playing, pause_event, paused,  &player::do_pause>
    , transition<paused,  play_event,  playing, &player::do_resume>
    , transition<paused,  stop_event,  stopped, &player::do_stop>
    >::type transition_table;
\end{verbatim}
}

pros:
\begin{enumerate}
\item readability, direct mapping between a FSM design and 
    implementation ( one-to-one relation between the 
    definition and the state table of the FSM )
\item performance ??
\item compile-time checking 
\item FSM "installation" is done at compile-time; cost 
    nothing in performance 
\item only transition actions need to be implemented 
    (no need to inherit, extend classes, etc.) 
\item entry and exit methods can be supported easily 
    (and will be called automatically); you also don't have 
    to pay for them, if you don't use them 
\end{enumerate}

cons:
\begin{enumerate}
\item can't handle large FSMs (N transitions > 100) 
\item compile times for FSMs with N transitions > 50 
\end{enumerate}


Related work

A notable prior work in the field of automation of general-purpose 
state machine implementation in \Cpp\ is the Robert Martin's State 
Machine Compiler [SMC]. The SMC takes an ASCII description of the 
machine's state transition table and produces a \Cpp\ code that 
implements the FSM using a variation of State design pattern [Hun91],
[GHJ+95]. [Laf00] presents another approach, where no external tools 
are used, and the FSMs are table driven. 


\section{About implementation}

\section{Lessons learned}

\section{Conclusions}
\section{Acknowledgements}
\section{References}

\bibliographystyle{abbrv} \bibliography{refs}

\end{document}
% LocalWords:  Aleksey David Gurtovoy Abrahams MPL STL Boost boost
