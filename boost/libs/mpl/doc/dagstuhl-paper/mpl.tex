\documentclass{kapproc}
%\usepackage{semantic}
%\usepackage{math}

\newcommand{\Cpp}{C\kern-0.05em\texttt{+\kern-0.03em+}%
}
\newcommand{\Mpl}{Boost Meta\-program\-ming Library}
\newcommand{\mping}{meta\-program\-ming}
\newcommand{\mpgm}{meta\-program}
\newcommand{\mpgms}{meta\-programs}
\newcommand{\mpgmer}{meta\-program\-mer}
\newcommand{\mpgmers}{meta\-program\-mer}
\newcommand{\mfn}{meta\-function}
\newcommand{\mfns}{meta\-functions}
\newcommand{\mdat}{meta\-data}

\input{defs}

\begin{document}

\articletitle{The Boost \Cpp\ Metaprogramming Library}

\author{Aleksey Gurtovoy} 
 \affil{MetaCommunications, Inc.}
\email{agurtovoy@meta-comm.com}
\author{David Abrahams}
 \affil{Boost Consulting}
\email{david.abrahams@rcn.com}


\begin{abstract} $\!$This paper describes the Boost \Cpp Template
Meta\-program\-ming Library (MPL), an extensible compile-time
framework of algorithms, sequences and function classes. The library
brings together important abstractions from the generic and functional
programming worlds to build a powerful and easy-to-use toolset which
makes template \mping{} practical enough for the real-world
environments. The MPL is heavily influenced by its run-time equivalent
- the Standard Template Library (STL), a part of the C++ standard
library. Like the STL, it defines an open conceptual and
implementation framework which can serve as a foundation for future
contributions in the domain. The library's fundamental concepts and
idioms enable the user to focus on solutions without navigating the
universe of possible ad-hoc approaches to a given \mping{} problem,
even if no actual MPL code is used.  The \Mpl also provides a
compile-time lambda expression facility enabling arbitrary currying
and composition of class templates, a feature whose runtime
counterpart is often cited as missing from the STL. This paper
explains the motivation, usage, design, and implementation of the MPL
with examples of its real-life applications, and offers some lessons
learned about C++ template \mping{}.
\end{abstract}

\begin{keywords}
programming languages, type systems, generic programming,
polymorphism, metaprogramming, compile-time
\end{keywords}

%==============================================================================
\section{Introduction}

\subsection{What is Metaprogramming?}

Metaprogramming is usually defined as the creation of programs which
generate other programs. Parser generators such as YACC are examples
of one kind of program-generating program. The input language to YACC
is a context-free grammar in EBNF, and its output is a program which
parses that grammar. Note that in this case the \mpgm{} (YACC) is
written in a language (`C') which does not directly support the
description of generated programs. These specifications, which we'll
call \emph{\mdat}, are not written in `C', but in a
\emph{meta-language}. Because the the rest of the user's program
typically requires a general-purpose programming system and must
interact with the generated parser, the \mdat\ is translated into
`C', which is then compiled and linked together with the rest of the
system. The \mdat\ thus undergoes two translation steps, and the
user is always very conscious of the boundary between his \mdat\
and the rest of his program.
% need bibliography reference for YACC

A more interesting form of \mping{} is available in languages
such as Scheme, where the generated program specification is given in
the same language as the \mpgm{} itself. The metaprogrammer
defines his meta-language as a subset of the expressible forms of the
underlying language, and program generation can take place in the same
translation step used to process the rest of the user's program. This
allows users to switch transparently between ordinary programming,
generated program specification, and \mping{}, often without
being aware of the transition.
% bib reference for Scheme metaprogramming

\subsection{Metaprogramming in \Cpp{}}

In \Cpp, it was discovered almost by accident that the template
mechanism provides a rich facility for computation at compile-time. In
this section, we'll explore the basic mechanisms and some common
idioms used for metaprogramming in C++.

\subsubsection{Numeric Computations}

The availability of \emph{non-type template parameters} makes it
possible to perform integer computations at compile-time. For example,
the following template computes the factorial of its
argument:

{\small
\begin{codesamp}\begin{verbatim}
template <unsigned n>
struct factorial
{
   static const unsigned value = n * factorial<n-1>::value;
};

template <>
struct factorial<0>
{
   static const unsigned value = 1;
};
\end{verbatim}
\end{codesamp}
}

The program fragment above is called a \emph{\mfn}, and it is easy to
see its relationship to a function designed to be evaluated at
runtime: the ``\mfn\ argument'' is passed as a template parameter, and
its ``return value'' is defined as a nested static constant.  Because
of the hard line between the expression of compile-time and runtime
computation in \Cpp, metaprograms look different from their runtime
counterparts. Thus, although as in Scheme the \Cpp\ \mpgmer\ writes
her code in the same language as the ordinary program, only a subset
of the full \Cpp\ language is available to her: those expressions
which can be evaluated at compile-time. Compare the above with a
straightforward runtime definition of the factorial function:

{\small
\begin{codesamp}\begin{verbatim}
unsigned factorial(unsigned N)
{
   return N == 0 ? 1 : N * factorial(N - 1);
}
\end{verbatim}
\end{codesamp}
}

While it is easy to see the analogy between the two recursive
definitions, recursion is in general more important to \Cpp{}
metaprograms than it is to runtime \Cpp. In contrast to languages such
as Lisp where recursion is idiomatic, \Cpp\ programmers will typically
avoid recursion when possible. This is done not only for efficiency
reasons, but also because of ``cultural momentum'': recursive programs
are simply harder (for \Cpp\ programmers) to think about. Like pure
Lisp, though, the \Cpp\ template mechanism is a \emph{functional}
programming language: as such it rules out the use of data mutation
required to maintain loop variables.

A key difference between the runtime and compile-time factorial
functions is the expression of the termination condition: our
meta-factorial uses template specialization as a kind of
\emph{pattern-matching} mechanism to describe the behavior when
\code{N} is zero. The syntactic analogue in the runtime world would
require two separate definitions of the same function. In this case
the impact of the second definition is minimal, but in large
metaprograms the cost of maintaining and understanding the terminating
definitions can become significant.

Note also that a \Cpp\ \mfn's return value must be \emph{named}. The
name chosen here, \code{value}, is the same one used for all numeric
returns in the \Mpl. As we'll see, establishing a consistent naming
convention for \mfn\ returns is crucial to the power of the library.

\subsubsection{Type Computations}

How could we apply our \code{factorial<>} \mfn{}? We might, for example,
produce an array type of an appropriate size to hold all permutations
of instances of another type:

{\small
\begin{codesamp}\begin{verbatim}
// permutation_holder<T>::type is an array type which can contain all
// permutations of a given T.

// unspecialized template for scalars
template <class T> struct permutation_holder
{
   typedef T type[1][1];
};

// specialization for array types
template <class T, unsigned N> struct permutation_holder<T[N]>
{
   typedef T type[factorial<N>::value][N];
};
\end{verbatim}
\end{codesamp}
}

Here we have introduced the notion of a \emph{type computation}.  Like
\code{factorial<>} above, \code{permutation\_\-holder<>} is a
\mfn{}. However, where \code{{factorial<>}} manipulates unsigned integer
values, \code{permutation\_\-holder<>} accepts and ``returns'' a
type (as the nested typedef ``\code{type}''). Because the \Cpp\ type
system provides a much richer set of expressions than anything we can
use as a nontype template argument (e.g. the integers), \Cpp\ \mpgms\
tend to be composed mostly of type computations.

\subsubsection{Type Sequences}

The ability to programmatically manipulate collections of types is a
central tool of most interesting \Cpp\ metaprograms. Because this
capability is so well-supported by the MPL, we'll provide just a brief
introduction to the basics here.

First, we'd need a way to represent the collection. One
idea might be to store the types in a structure:

{\small
\begin{codesamp}\begin{verbatim}
struct types {
  int t1;
  long t2;
  std::vector<double> t3;
};
\end{verbatim}
\end{codesamp}
}

Unfortunately, this arrangement is not susceptible to the compile-time
type introspection power that \Cpp\ gives us: there's no way to find
out what the names of the members are, and even if we assume that
they're named according to some convention as above, there's no way to
now how many members there are. The key to solving this problem is to
increase the uniformity of the representation. If we have a consistent
way to get the first type of any sequence and the rest of the
sequence, we can easily access all members:

{\small
\begin{codesamp}\begin{verbatim}
template <class First, class Rest>
struct cons
{
  typedef First first;
  typedef Rest rest;
};

struct nil {};

typedef
  cons<int, cons<long, cons<std::vector<double>, nil> > >
my_types;
\end{verbatim}
\end{codesamp}
}

The structure described by \code{types} above is the compile-time
analogue of a singly-linked list. Now that we've adjusted the
structure so that the \Cpp\ template machinery can ``peel it apart'',
let's examine a simple function which does so. Suppose a user wished
to find the largest of an arbitrary collection of types. We can apply
the recursive \mfn\ formula which should by now be familiar:

{\small
\begin{codesamp}\begin{verbatim}
// Choose the larger of two types
template <class T1, class T2
        , bool choose1 = (sizeof(T1) > sizeof(T2)) // hands off!
        >
struct choose_larger
{
   typedef T1 type;
};

// specialization for the case where sizeof(T2) >= sizeof(T1)
template <class T1, class T2>
struct choose_larger<T1,T2,false>
{
   typedef T2 type;
};

// Get the largest of a cons-list
template <class T> struct largest;

// Specialization to peel apart the cons list
template <class First, class Rest>
struct largest<cons<First,Rest> >
   : choose_larger<First, typename largest<Rest>::type>
{
   // type inherited from base
};

// specialization for loop termination
template <class First>
struct largest<cons<First,nil> >
{
   typedef First type;
};

int main()
{
   // print the name of the largest of my_types
   std::cout << typeid(largest<my_types>::type).name()
             << std::endl;
}

\end{verbatim}
\end{codesamp}
}

There are several things worth noticing about this code:

\begin{itemize}
\item It uses a few ad-hoc, esoteric techniques, or ``hacks''. The
  default template argument \code{choose1} (labelled ``hands off!'')
  is one example. Without it, we would have needed yet another
  template to provide the implementation of \code{choose\_\-larger},
  or we would have had to provide the computation explicitly as a
  parameter to the template - perhaps not bad for this example, but it
  would make choose\_\-larger much less useful and more
  error-prone. The other hack is the derivation of a specialization of
  \code{largest} from \code{choose\_\-larger}. This is a code-saving
  device which allows the programmer to avoid writing \code{typedef
  typename}...\code{::type type} in the template body.

\item Even this simple \mpgm\ uses three separate partial
  specializations. The \code{largest} \mfn\ uses \emph{two}
  specializations. One might expect that this indicates there are two
  termination conditions, but there are not: one specialization is
  needed simply to deal with access to the sequence elements. These
  specializations make the code difficult to read by spreading the
  definition of a single \mfn\ over several \Cpp\ template
  definitions. Also, because they are \emph{partial} specializations,
  they make the code unusable for a large community of \Cpp\
  programmers whose compilers don't support that feature.
\end{itemize}

While these techniques are of course a valuable part of the arsenal of
any good \Cpp\ \mpgmer, their use tends to make programs written in
what is already an unusual style harder-to-read and
harder-to-write. By encapsulating commonly-used structures and dealing
with loop terminations internally, the \Mpl\ reduces the need for both
tricky hacks and for template specializations.

\subsection{Why Metaprogramming?}

%%% maybe we don't need another example of a metaprogram given what
%%% we've done above? We could rewrite and cut most of this section...

It's worth asking why anyone would want to do this. After all, even a
simple toy example like the factorial \mfn\ is somewhat
esoteric. To show how the type computation can be put to work, let's
examine a simple example. The following code produces an array
containing all possible permutations of another array:

{\small
\begin{codesamp}\begin{verbatim}
// Can't return an array in C++, so we need this wrapper
template <class T>
struct wrapper
{
   T x;
};

// Return an array of the N! permutations of x
template <class T>
wrapper<typename permutation_holder<T>::type>
all_permutations(T const& in)
{
   wrapper<typename permutation_holder<T>::type> result;

   // Copy the unpermuted array to the first result element
   unsigned const N = sizeof(T)/sizeof(**result.x);
   std::copy(&*in, &*in + N, result.x[0]);

   // Enumerate the permutations
   unsigned const result_size = sizeof(result.x)/sizeof(T);
   for (T* dst = result.x + 1; dst != result.x + result_size; ++dst)
   {
       T* src = dst - 1;
       std::copy(*src, *src + N, *dst);
       std::next_permutation(*dst, *dst + N);
   }
   return result;
}
\end{verbatim}
\end{codesamp}
}


%%% ...up to this point

The runtime definition of \code{factorial} would be useless in
\code{all\_\-permutations} above, since in \Cpp\ the sizes of array
members must be computed at compile-time. However, there are
alternative approaches; how could we avoid \mping, and what would the
consequences be?

\begin{enumerate}

\item We could write programs to interpret the \mdat\ directly. In
  our factorial example, the array size could have been a runtime
  quantity; then we'd have been able to use the straightforward
  factorial function. However, that would imply the use of dynamic
  allocation, which is often expensive.

  To carry this further, YACC might be rewritten to accept a
  pointer-to-function returning tokens from the stream to be parsed,
  and a string containing the grammar description. This approach,
  however, would impose unacceptable runtime costs for most
  applications: either the parser would have to treat the grammar
  nondeterministically, exploring the grammar for each parse, or it
  would have to begin by replicating at runtime the substantial
  table-generation and optimization work of the existing YACC for each
  input grammar.

\item We could replace the compile-time computation with our own
  analysis. After all, the size of arrays passed to
  \code{all\_\-permutations} are always known at compile-time, and
  thus can be known to its user. We could ask the user to supply the
  result type explicitly:
{\small
\begin{codesamp}\begin{verbatim}
template <typename Result, typename T>
Result
all_permutations(T const& input);
\end{verbatim}
\end{codesamp}
}
  The costs to this approach are obvious: we give up expressivity (by
  requiring the user to explicitly specify implementation details),
  and correctness (by allowing the user to specify them
  incorrectly). Anyone who has had to write parser tables by hand will
  tell you that the impracticality of this approach is the very reason
  YACC's existence.

  In a language such as \Cpp, where the \mdat\ can be expressed in
  the same language as the rest of the user's program, expressivity is
  further enhanced: the user can invoke \mpgms\ directly, without
  learning a foreign syntax or interrupting the flow of his code.
\end{enumerate}

So, the motivation for \mping{} comes down to the combination of three
factors: efficiency, expressivity, and correctness. While in classical
programming there is always a tension between expressivity and
correctness on one hand and efficiency on the other, in the \mping\
world we wield new power: can move the computation required for
expressivity from runtime to compile-time.

\subsection{Why a Metaprogramming \emph{Library}?}

One might just as well ask why we need any generic library: 
 
\begin{itemize}

\item Quality. Code that is appropriate for a general-purpose library
  is usually incidental to the purpose of its users. To a library
  developer, it is the central mission. On average, the containers and
  algorithms provided by any given \Cpp\ standard library
  implementation are more-flexible and better-implemented than the
  project-specific implementations which abound, because library
  development was treated as an end in itself rather than a task
  incidental to the development of some other application. With a
  centralized implementation for any given function, optimizations and
  improvements are more likely to have been applied.

\item Re-use. More important even than the re-use of code which all
  libraries provide, a well-designed generic library establishes a
  \emph{framework of concepts and idioms} which establish a reusable
  mental model for approaching problems. Just as the \Cpp\ Standard
  Template Library gave us iterator concepts and a function object
  protocol, the \Mpl\ provides type-iterators and meta-function class
  protocol. A well-considered framework of idioms saves the \mpgmer{}
  from considering irrelevant implementation details and allows her to
  concentrate on the problem at hand.

\item Portability. A good library can smooth over the ugly realities
  of platform differences. While in theory a \mping\ library is fully
  generic and shouldn't be concerned with these issues, in practice,
  support for templates remains inconsistent even four years after
  standardization. This should perhaps not be surprising: \Cpp\
  templates are the language's furthest-reaching and most complicated
  feature, which largely accounts for the power of \mping\ in \Cpp.

\item Fun. Repeating the same idioms over and over is
  \emph{tedious}. It makes programmers tired and reduces
  productivity. Furthermore, when programmers get bored they get
  sloppy, and buggy code is even more costly than slowly-written
  code. Often the most useful libraries are simply patterns that have
  been ``plucked'' by an astute programmer from a sea of
  repetition. The MPL helps to reduce boredom by eliminating the need
  for the most commonly-repeated boilerplate coding patterns.

\end{itemize}

As you can see, the \Mpl's development is motivated primarily by the
same practical, real-world considerations that justify the development
of any other library. Perhaps this is an indication that template
\mping\ is finally ready to leave the realm of the esoteric and enter
the lingua franca of every day programmers.
%probably this paragraph would be better in the conclusions

\subsection{What about portability? }

Although the MPL aims to reduce the user's need to be concerned with
issues of nonstandard \Cpp\ implementations, some concessions are
inevitable. For example, the current implementation of the
\code{lambda} facility does not work on compilers which lack either
support for template partial specialization or for template template
parameters.\footnote{We believe that a workaround is possible, but
that it would impose some additional restrictions on the way users
must represent \mfn{}s. The fact remains that without both
features, \mping\ expressivity is somewhat reduced.} Another
concession which may not be apparent at first is the need for the
\code{apply1}...\code{applyN} templates. On most compilers,
\code{applyN<F,T1,T2...TN>} (for example) is derived from
\code{F::template apply<T1,T2...TN>}: it is nearly a synonym, and one
might well wonder whether it is even worth providing \code{apply} as a
library facility since the language construct only costs one
additional keyword. On one compiler, however, this construct causes an
internal compiler error and must be replaced with a workaround so
odious that it would be unreasonable to expect even an expert to find
it.\footnote{In fact, the workaround isn't even legal \Cpp\, but it is
accepted by the compiler in question.} The library hides all this
nastiness within its implementation of \code{applyN}, but anyone
writing portable \mpgms\ is required to use the library instead of
taking what might be considered the more obvious approach.

\subsection{Relation to other work.}

\section{Basic usage (What can I do with mpl?)}

\subsection{Conditional type selection}

Conditional type selection is the simplest basic construct of \Cpp\
template \mping{}. Veldhuizen [Vel95] was the first to show 
how to implement it, and Czarnecki and Eisenecker [CE00] first 
presented it as a standalone library primitive. The \Mpl\ defines the 
corresponding facility as follows:

%%% It would be a good idea to introduce/motivate the use of true_c/false_c
%%% types in place of bool parameters. 

{\small
\begin{codesamp}\begin{verbatim}
// definition
template<
      typename Condition
    , typename T1
    , typename T2
    >
struct select_if
{
    typedef implementation-defined type;
};

// usage/semantics
typedef mpl::select_if<mpl::true_c,char,long>::type t1;
typedef mpl::select_if<mpl::false_c,char,long>::type t2;

BOOST_MPL_ASSERT_IS_SAME(t1, char);
BOOST_MPL_ASSERT_IS_SAME(t2, long);
\end{verbatim}
\end{codesamp}
}

The construct is important because template \mpgms{} often 
contain a lot of decision-making code, and, as we will show, 
spelling it manually every time via (partial) class template 
specialization quickly becomes impractical. The template also 
important from the point of encapsulating the compiler 
workarounds (for example, not all \Cpp\ compilers support 
partial template specialization). However, the way \Cpp\ 
template instantiation mechanism works imposes some subtle 
limitations on applicability of the primitive, comparing to 
a manually implemented equivalent of the selection code. 

%%% This section digresses into dealing with what I would title
%%% "Delayed Evaluation". While a /very/ important topic, I would
%%% cover it elsewhere, enabling you to avoid using Partial Spec. as
%%% an excuse for dealing with it. Delayed evaluation for correctness
%%% deserves a mention but I think you might have one too many
%%% examples of unsuccessful attempts to deal with it ;-) 

For example, suppose we are implementing a \code{pointed\_\-type}
traits template such as \code{pointed\_\-type<T>::type} instantiated
for a \code{T} that is either a plain pointer
(\code{U*}), \code{std::auto\_ptr<U>}, or any of the \code{boost}
smart pointers, e.g. \code{boost::scoped\_ptr<U>}, will give you 
the pointed type (\code{U}):

{\small
\begin{codesamp}\begin{verbatim}
BOOST_MPL_ASSERT_IS_SAME(pointed_type<my*>::type, my);
BOOST_MPL_ASSERT_IS_SAME(pointed_type< std::auto_ptr<my> >::type, my);
BOOST_MPL_ASSERT_IS_SAME(pointed_type< boost::scoped_ptr<my> >::type, my);
\end{verbatim}
\end{codesamp}
}

An obvious way to implement \code{pointed\_type} would be to 
use partial specialization to distinguish between plain 
pointers and everything else:

{\small
\begin{codesamp}\begin{verbatim}
// general case, handles std::auto_ptr and boost pointers
template< typename T >
struct pointed_type
{
    typedef typename T::element_type type;
};

// specialization for plain pointers
template< typename T >
struct pointed_type<T*>
{
    typedef T type;
};
\end{verbatim}
\end{codesamp}
}

but if partial specialization is unavailable, then 
\code{select\_if} seems to be the right tool. Unfortunately,
the straightforward approach does not work:

{\small
\begin{codesamp}\begin{verbatim}
template< typename T >
struct pointed_type
{
    typedef typename mpl::select_if<
          boost::is_pointer<T>
        , typename boost::remove_pointer<T>::type
        , typename T::element_type // #1
        >::type type;
};

// the following code causes compilation error in line #1:
// name followed by "::" must be a class or namespace name
typedef pointed_type<char*>::type result;
\end{verbatim}
\end{codesamp}
}

Clearly, \code{typename T::element\_type} expression is not 
valid in case of \code{T == char*}, and that's what the 
compiler is complaining about. Implementing the selection code 
manually solves the problem: 

{\small
\begin{codesamp}\begin{verbatim}
namespace aux {
// general case
template< bool >
struct select_pointed_type
{
    template< typename T > struct result
    {
        typedef typename T::element_type type;
    };
};

// specialization for plain pointers
template<>
struct select_pointed_type<true>
{
    template< typename T > struct result
    {
        typedef typename
            boost::remove_pointer<T>::type type;
    };
};
}

template< typename T >
struct pointed_type
{
    typedef typename aux::select_pointed_type<
          boost::is_pointer<T>::value
        >::template result<T>::type type;
};
\end{verbatim}
\end{codesamp}
}

But this quickly becomes awkward if needs to be done 
repeatedly. We can try to workaround the problem with 
\code{select\_\-if} code as follows:

{\small
\begin{codesamp}\begin{verbatim}
namespace aux {
template< typename T >
struct element_type
{
	typedef typename T::element_type type;
};
}

template< typename T >
struct pointed_type
{
    typedef typename mpl::select_if<
          boost::is_pointer<T>
        , typename boost::remove_pointer<T>::type
        , typename aux::element_type<T>::type
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

but this doesn't work either - the access to the 
\code{element\_type<T>}'s nested \code{type} member still 
forces the compiler to instantiate \code{element\_type<T>}
with \code{T == char*}, and that instantiation is of course 
invalid. Also, although in our case this does not lead to a 
compile error, the \code{boost::remove\_pointer<T>} template 
gets always instantiated as well, and for the same reason 
(because we are accessing it's nested \code{type} member). 
Such unnecessary instantiation that is not fatal from 
compiler's point of view may or may be not a problem, 
depending on the ``weight'' of the template (how much the 
instantiation taxes the compiler), but a general rule of 
thumb would be to avoid such code.

Returning to our error, to make the above code compile, we 
need to factor the act of ``asking'' \code{aux::element\_\-type<T>}
of its nested \code{type} out of the \code{select\_\-if} 
invocation. The fact that both \code{boost::remove\_\-pointer<T>}
trait template and \code{aux::element\_\-type<T>} use the same 
naming convention for their result types makes the refactoring 
easier:

{\small
\begin{codesamp}\begin{verbatim}
template< typename T >
struct pointed_type
{
 private:
    typedef typename mpl::select_if<
          boost::is_pointer<T>
        , boost::remove_pointer<T>
        , aux::element_type<T>
        >::type func_;

 public:
    typedef typename func_::type type;
};
\end{verbatim}
\end{codesamp}
}

Now the compiler has no reasons instantiate both 
\code{boost::remove\_\-pointer<T>} and 
\code{aux::element\_\-type<T>} even although they are used as 
actual parameters to the \code{select\_if} template (and is 
guaranteed not to do so), so we are guaranteed to get away with 
\code{aux::element\_\-type<char*>} as far as it won't end up being 
selected as \code{func\_}.

The above technique is so common in template metaprograms, that it
even make sense to facilitate the selection of nested \code{type} member
by introducing a high level equivalent to \code{select\_if} - the one
that will do \code{func\_::type} operation (that is called [nullary]
function class application) as a part of its invocation.  The \Mpl
provides such template - it's called \code{apply\_if}. Using it, we
can re-write the above code as simple as:

{\small
\begin{codesamp}\begin{verbatim}
template< typename T >
struct pointed_type
{
    typedef typename mpl::apply_if<
          boost::is_pointer<T>
        , boost::remove_pointer<T>
        , aux::element_type<T>
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

To make our techniques review complete, let's consider a slightly 
different example - suppose we want to define a high-level wrapper 
around \code{boost::remove\_pointer} traits template [], which will 
strip the pointer qualification conditionally. We will call it 
\code{remove\_pointer\_if}:

{\small
\begin{codesamp}\begin{verbatim}
template<
      typename Condition
    , typename T
    >
struct remove_pointer_if
{
    typedef typename mpl::select_if<
          Condition
        , typename boost::remove_pointer<T>::type
        , T
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

Now the above works from the first time, but it suffers from the 
problem we mentioned early - \code{boost::remove\_pointer<T>} gets 
instantiated even if its result is never used. In metaprogramming 
world compilation time is an important resource [Abr01], and it's 
one of the things that gets wasted by unnecessary template 
instantiations. We've just seen how to deal with the problem in 
case when both arguments to \code{select\_if} template are the 
results of nullary function class applications, but in this example 
one of the arguments - namely \code{T} is just simple a type, so 
the refactoring just doesn't seem possible. An easiest way out of 
this situation would be to pass to \code{select\_if} a real 
nullary function instead of \code{T}, - the one that returns 
\code{T} on its invocation. The \Mpl provides a simple way to do it -
we just substitute \code{T} with \code{mpl::identity<T>},
and \code{boost::select\_if} with more compact 
\code{boost::apply\_if}:

{\small
\begin{codesamp}\begin{verbatim}
template<
      typename Condition
    , typename T
    >
struct remove_pointer_if
{
    typedef typename mpl::apply_if<
          Condition
        , boost::remove_pointer<T>
        , mpl::identity<T>
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

Which gives us exactly what we wanted.


%%% This intro material needs to come earlier, since you talk about
%%% nullary functions in the previous section.  

\subsection{The Form of Metafunctions}

In \Cpp\, the basic underlying language construct which allows
parameterized compile-time computation is the \emph{class template}. A
bare class template is the simplest possible model we could choose for
\mfns: it can take types and/or non-type arguments as actual template
parameters and instantiation ``returns'' a new type. For example, the
following produces a type derived from its arguments:

{\small
\begin{codesamp}\begin{verbatim}
template<class N1, class N2>
struct derive : N1, N2
{
};
\end{verbatim}
\end{codesamp}
}

However, this model is far too limiting: it restricts the \mfn\ result
not only to class types, but to instantiations of a given class
template, to say nothing of the fact that every \mfn\ invocation
introduces an additional level of template nesting. While that might
be acceptable for this particular \mfn\, any model which prevented us
from ``returning'', say, \code{int} is obviously not general
enough. To meet this basic requirement, we must rely on a nested type
to provide our return value:

{\small
\begin{codesamp}\begin{verbatim}
template<class N1, class N2>
struct derive
{
  struct type : N1, N2 {};
};
// silly specialization, but demonstrates ``returning'' int.
template<>
struct derive<void,void>
{
  typedef int type;
};
\end{verbatim}
\end{codesamp}
}

Veldhuizen [Vel95] was first to talk about class templates of this
form as ``compile-time functions'', and [CE00] have introduced
``template \mfn'' as an equivalent term (they also use the simpler
term ``\mfn'' as do we). While syntactically simple, however, this
form of \mfn\ does not always interact optimally with the rest of
\Cpp. In particular, the use of simple \mfns\ makes the use of
higher--order functions difficult.

\begin{glossary}
  \term{Higher-Order Function} is a function that can take other
  functions as arguments, and/or return functions as
  results. Higher-order functions are a distinguishing features of the
  modern functional languages [Hud89].
\end{glossary}


In order to pass such a \mfn\ to another template, we need to
use \emph{template template parameters}:

{\small
\begin{codesamp}\begin{verbatim}
// Returns F(T1,F(T2,T3))
template<template<typename>class F, class T1, class T2, class T3>
struct apply_twice
{
  typedef typename F<
        T1
        , typename F<T2,T3>::type
  >::type type;
};

// A new metafunction returning a type derived from T1, T2, and T3
template <class T1, class T2, class T3>
struct derive3
  : apply_twice<derive,T1,T2,T3>
{};
\end{verbatim}
\end{codesamp}
}

Because \Cpp\ makes a strict distinction between type and class
template template parameters, this approach creates an artificial
``wall'' between \mfns\ and other \mdat, relegating \mfns\ to the
status of second-class citizens. For example, recalling our
introduction to type sequences, there's no way to make a \code{cons}
list of \mfns:

{\small
\begin{codesamp}\begin{verbatim}
typedef cons<derive, cons<derive3, nil> > derive_functions; // error!
\end{verbatim}
\end{codesamp}
}

We might consider redefining our \code{cons} cell so we can pass
\code{derive} as the head element:

{\small
\begin{codesamp}\begin{verbatim}
template <
    template<template<class T,class U> class F
  , class Tail
> struct cons;
\end{verbatim}
\end{codesamp}
}

However, now we have another problem: \Cpp\ strictly enforces the
\emph{arity} (number of parameters) of any template template
parameter, so we \emph{still} can't embed \code{derive3} in a
\code{cons} list. Fortunately, the truism that ``there is no problem
in software which can't be solved by adding yet another level of
indirection''\footnote{Andrew Koening calls this ``The Fundamental
Theorem of Software Engineering''} applies here. To elevate \mfns\ to
the status of first-class objects, the MPL introduces the concept of a
``\mfn\ class'':

{\small
\begin{codesamp}\begin{verbatim}
// metafunction class form of derive
struct derive
{
  template<class N1, class N2>
  struct apply
  {
    struct type : N1, N2 {};
  };
};
\end{verbatim}
\end{codesamp}
}

This form should look familiar to anyone acquainted with function
objects in STL, with the nested \code{apply} template taking the same
role as the runtime function-call operator. In fact, compile-time
metafunction classes have the same relationship to metafunctions that
runtime function objects have to functions:

{\small
\begin{codesamp}\begin{verbatim}
// function form of add
template <class T> T add(T x, T y) { return x + y; }

// function object form of add
struct add
{
  template<class T>
  T operator()(T x, T y) { return x + y; }
};
\end{verbatim}
\end{codesamp}
}

These two forms exist because of some idiosyncrasy in 
how templates are defined in C++, - in particular, because 
of the lack of so called template typedefs [Sut01]. The 
latter makes it unnecessary awkward and tedious to define 
and work with higher-order ct-\mfns\ (i.e. class 
template \mfns\ that returns another class template 
\mfns):

%%% Should make the link between template typedefs and closures

{\small
\begin{codesamp}\begin{verbatim}
// a compile-time equivalent of std::bind1st
template<
      template< typename P1, typename P2 > class F
    , typename T1
    >
struct bind1st
{
    // template< typename U > typedef F<T1, U> type;
    template< typename U > struct type
        : F<T1, U>
    {
    };
};

// a compile-time equivalent of boost::compose_f_gx
template<
      template< typename > class F
    , template< typename > class G
    >
struct compose_f_gx
{
    // template< typename X > 
    // typedef F< typename G<X>::type > type;
    template< typename X > struct type
        : F< typename G<X>::type >
    {
    };
};

template< typename T >
struct some_type_computation
{
    // ...

    // define composite predicate, clumsy!
    template< typename U > struct is_T_or_const_T
        : compose_f_gx<
              bind1st< boost::is_same,T >::template type
            , boost::remove_const
            >::template type<U>
    {
    };

    // do something with it
    typedef find_if< types,is_T_or_const_T >::type itor;
    // ...
};
\end{verbatim}
\end{codesamp}
}

%%% Can you make your case here with just bind1st? compose_f_gx is
%%% probably not too familiar to most people, and the code here is
%%% pretty complicated.

In this example, passing the body of 
\code{is\_T\_or\_const\_T} predicate directly to 
\code{find\_if} would make things a little bit prettier, 

%%% What point are you trying to make here? Consider cutting this.

{\small
\begin{codesamp}\begin{verbatim}
template< typename T >
struct complex_type_computation
{
    // ...
    // define composite predicate and do something with it
    typedef find_if<
          types
        , compose_f_gx<
              bind1st< boost::is_same,T >::template type
            , boost::remove_const
            >::template type
        >::type itor;
    // ...
};
\end{verbatim}
\end{codesamp}
}

but in general this doesn't scale. 

There are some problems with correctness of the above 
approach as well - deriving the \code{type} members of 
\code{bind1st} and \code{compose\_f\_gx} templates from 
the ct-\mfns\ they are composing (\code{F} and 
\code{G}) \emph{changes the type of the result}. 
For instance:

{\small
\begin{codesamp}\begin{verbatim}
template< typename T1, typename T2 >
struct my
{
    // ...
};

typedef bind1st<my, int>::type<long> result;
typedef my< int,long > expected_result;

BOOST_MPL_ASSERT_IS_SAME(result, expected_result); // fails!
BOOST_STATIC_ASSERT((boost::is_convertible<result,expected_result>::value));
\end{verbatim}
\end{codesamp}
}

This may or may be not a problem, depending on how you 
want to use the result of a type computation algorithm 
that applies higher-order \mfns\ internally. 
Unfortunately, within the current language inheritance 
is the only way to ``return'' a class template.

%%% A marginal issue. We don't have true closures either but it
%%% doesn't seem to cause problems... or maybe it does (we can't declare
%%% a variable to hold the result of bind)

%%\emph{MORE IMPORTANTLY - why representing metafunctions as plain class
%% templates (ct-metafunctions) is not a option.}


\begin{glossary}
  \term{polymorphic} A function is \emph{polymorphic} if it can take
  arguments of an arbitrary type (a \Cpp\ term from run-time world
  would be ``generic'')
\end{glossary}

\Cpp\ templates are \emph{polymorphic} regarding the type 
arguments (type template parameters) they take. However they 
are not polymorphic regarding ct-\mfns\ (class 
template template parameters). In particular, the language 
rules dictate the compiler to enforce \emph{strict arity} of 
the class templates being passed as template template 
parameters. Moreover, polymorphism \emph{between} types and 
ct-\mfns\ is not supported, and the syntax of 
``returning'' ct-\mfns\ is different from syntax of 
returning a type. All this seriously limits the 
applicability of higher-order functions, leads to 
unnecessary code duplication, and has an overall negative 
effect on the both conceptual and implementation clarity, 
simplicity and size of the library.

%%% I think we should have a separate section to discuss
%%% limitations/complaints about C++ and possible suggestions for ways
%%% to make metaprogramming better. That would allow you to
%%% concentrate focus on ``here's what the lib does, here's how''
%%% where appropriate.

For example, that means that you cannot write a single 
generic metafunction that passes the result of one 
function's execution as the argument to another function:

%%% FWIW, when you start using template template parameters, using
%%% ``typename'' (instead of ``class'') for type template parameters
%%% really hurts readability IMO. We have 3 keywords that look quite
%%% similar: template typedef typename. I understand the theoretical
%%% reasons for doing it this way.

{\small
\begin{codesamp}\begin{verbatim}
// won't work if either F or G (or both) a higher-level functions
template<
      template< typename > class F
    , template< typename > class G
    , typename X
    >
struct f_gx
{
    typedef typename F< typename G<X>::type >::type type;
};

// how we have to write it if G returns F takes an unary ct-metafunction
template<
      template< template< typename > class > class F
    , template< typename > class G
    , typename X
    >
struct f_gx2
{
    typedef typename F< G<X>::template type >::type type;
};

// and another one for a binary ct-metafunction, etc.
template<
      template< template< typename, typename > class > class F
    , template< typename > class G
    , typename X
    >
struct f_gx3
{
    typedef typename F< G<X>::template type >::type type;
};
\end{verbatim}
\end{codesamp}
}

Or, for example, that means that you cannot have a list of 
ct-\mfns:

{\small
\begin{codesamp}\begin{verbatim}
template< typename T1, typename T2 >
struct my_func
{
    typedef /* ... */ type;
};

typedef mpl::list< 
      my_func
    , boost::is_same
    , boost::is_convertible
    > func_list; // error!
\end{verbatim}
\end{codesamp}
}

You would need to have a special kind of list to do the above, 
and then yet another special kind of list for \emph{unary} 
ct-metafunction, etc.

So, basically, representing \mfns\ as plain class 
template would lead to duplication of almost every library 
facility. ``function class'' metafunction form solves all these 
problems. On the other hand, it seems that accepting function 
classes as \emph{the} form of representation of compile-time 
function entities imposes code duplication danger in as well: 
if the library's own primitives, algorithms, etc. are 
represented as class templates, that means that you either 
cannot reuse these algorithms in context of higher-order 
functions, or you have to duplicate all algorithms in second 
form, so, for instance, there would be two versions of 
\code{find}:

{\small
\begin{codesamp}\begin{verbatim}
// user-friendly form
template<
      typename Sequence
    , typename T
    >
struct find
{
    typedef /* ... */ type;
};

// "function class" form
struct find
{
    template< typename Sequence, typename T >
    struct apply
    {
        typedef /* ... */ type;
    };
};
\end{verbatim}
\end{codesamp}
}

Of course, the third option is to eliminate 
``user-friendly form'' completely so one would always 
have to write

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::find::apply<list,long>::type iter;
// or, if you prefer,
// typedef mpl::apply< mpl::find,list,long >::type iter;
\end{verbatim}
\end{codesamp}
}

instead of 

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::find<list,long>::type iter;
\end{verbatim}
\end{codesamp}
}

but that's would hurt usability, considering that the direct 
invocations of library's algorithms are more often-used than 
passing algorithms as arguments to another 
algorithms/functions. 

The library's answer to this dilemma is lambda expressions. 
Lambda is the mechanism that enables currying of 
ct-\mfns\ and converting them into function classes, 
so when you want to pass \code{find} algorithm as an argument 
to a higher-order function, you just write:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::apply< my_f, mpl::find<_1,_2> >::type result;
\end{verbatim}
\end{codesamp}
}

and then you want just use \code{find} directly in your code, 
you still have the intuitive

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::find<list,long>::type iter;
\end{verbatim}
\end{codesamp}
}


[to be continued]

%%% Should say ``metafunction classes'' below?

Metafunctions are important by encapsulating an operation into 
compile-time invocable entity, they give you a possibility to 
defer its execution. You can store the entity, pass it around, 
and invoke the operation at any time you need.

\subsection{Sequences, algorithms, and iterators}

Compile-time iteration over a sequence (of types) is one of 
the basic concept of template metaprogramming. Difference in 
types of objects being manipulated is the most common point 
of variability of similar but not identical code/design, and 
such designs are the direct target for some metaprogramming. 
Templates in their original usage were intended to be used to 
solve this exact problem, (std::vector), but without predefined 
abstractions/constructs for manipulating/iterating 
\emph{sequences} of types instead of standalone types, and 
without developed (known) techniques for emulating this 
constructs using the current language facilities, they effect 
on helping high-level metaprogramming happen has been limited. 

Czarnecki and Eisenecker [CE00] were the first to introduce 
the compile-time sequences of types and some simple algorithms 
on them, although the idea of representation common data 
structures like trees, lists, etc. at compile time using class 
template composition has been around for a while (for example, 
most of the expression template libraries build such trees as 
a part of their expression ``parsing'' process [Vel95b]). 
[Ale00] used list of types and some algorithms on them to 
implement several design patterns; the accompanying code 
is known as the Loki library []. 

%%%\emph{OLD introduction:}

%%%A possibility to represent and manipulate theoretically 
%%%unbound sequences of types and values at compile time opens an 
%%%exciting opportunities for creating highly reusable, 
%%%configurable, and amazingly easy-to-use generic components and 
%%%classes [CE00, Ale01]. Compile-time-operable collections of 
%%%types (and, to a slightly less extent, values) are at least as 
%%%important in generic and template metaprogramming as their 
%%%run-time equivalents in traditional programming. 
%%%The \Mpl acknowledges this assertion by providing an 
%%%STL-like framework of sequence, algorithm and function classes 
%%%that can significantly simplify building of complex 
%%%generic/generative components/systems. 

\subsubsection{Algorithms Operate on Sequences}
  
Most of algorithms in \Mpl\ operates on sequences. For example, 
searching type in a list looks like this:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list< char,short,int,long,float,double > types;
typedef mpl::find< types,long >::type iter;
\end{verbatim}
\end{codesamp}
}

Here, \code{find} accepts two parameters - a sequence to search
(\code{types}), the type to search for (\code{long}), and returns an
iterator \code{iter} pointing to the first element of the sequence
such that \code{iter::type} is identical to \code{long}; if no such
element exists, \code{iter} is identical to
\code{end<types>::type}. Basically, this is how one would search for a
value in \code{std::list} or \code{std::vector}, except that
\code{mpl::find} accepts the sequence as a single parameter,
while \code{std::find} takes two iterators.  Everything else is pretty
much the same - the names are the same, the semantics is very close,
there are iterators, and you can search not only by type, but also
using a predicate:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::find_if< types,boost::is_float >::type iter;
\end{verbatim}
\end{codesamp}
}

This conceptual/syntactical similarity with the STL is not
coincidental. Reusing the conceptual framework of STL in compile-time
world allows us to apply familiar and sound approaches for dealing
with sequential data structures. The algorithms and idioms which
programmers already know from STL can be applied again at
compile-time. We consider this to be one of the greatest strengths
that distinguishes the library from earlier attempts to build a
template metaprogramming library.

\subsubsection{Sequence Concepts}

In the \code{find} example above we searched for a type in the
sequence built using the \code{mpl::list} template, but
\code{list} is not the only sequence that the library provides you
with. Neither is\code{mpl::find} or any other algorithm
hard-coded to work only with \code{list} sequences. \code{list} is
just one model of MPL's ForwardSequence concept, and \code{find} works
with anything that satisfies this concept's requirements. The
hierarchy of sequence concepts in \Mpl is quite simple - a Sequence is
any compile-time entity for which \code{begin<>} and \code{end<>}
produce iterators to the range of its elements; a ForwardSequence is a
sequence whose iterators satisfy ForwardIterator requirements, a
BidirectionalSequence is a ForwardSequence whose iterators satisfy
BidirectionalIterator requirements, and, finally, RandomAccessSequence
is a BidirectionalSequence whose iterators satisfy
RandomAccessIterator requirements.

Decoupling algorithms from particular sequence implementation s
(through iterators) allows a \mpgmer\ to create her own sequence types
and to retain the rest of the library at her disposal. For example,
you can define a \code{tiny\_\-list} for dealing with sequences of 3
types as follows:

{\small
\begin{codesamp}\begin{verbatim}
template< typename TinyList, long Pos >
struct tiny_list_item;

template< typename TinyList, long Pos >
struct tiny_list_iterator
{
    typedef typename tiny_list_item<TinyList,Pos>::type type;
    typedef tiny_list_iterator<TinyList, Pos-1> prior;
    typedef tiny_list_iterator<TinyList, Pos+1> next;
};

template< typename T0, typename T1, typename T2 >
struct tiny_list
{
    typedef tiny_list_iterator<tiny_list, 0> begin;
    typedef tiny_list_iterator<tiny_list, 3> end;
    typedef T0 type0;
    typedef T1 type1;
    typedef T2 type2;
};

template< typename TinyList >
struct tiny_list_item<TinyList,0>
{ typedef typename TinyList::type0 type; };

template< typename TinyList >
struct tiny_list_item<TinyList,1>
{ typedef typename TinyList::type1 type; };

template< typename TinyList >
struct tiny_list_item<TinyList,2>
{ typedef typename TinyList::type2 type; };
\end{verbatim}
\end{codesamp}
}

and then use it with any of the library algorithms as if it 
was \code{mpl::list}:

{\small
\begin{codesamp}\begin{verbatim}
typedef tiny_list< char,short,int > types;
typedef mpl::transform<
      types
    , boost::add_pointer
    >::type pointers;
\end{verbatim}
\end{codesamp}
}

Note that \code{tiny\_list} is a model of 
BidirectionalSequence (it would be RandomAccess if 
we added \code{advance} member to \code{tiny\_\-list\_\-iterator}:

{\small
\begin{codesamp}\begin{verbatim}
template< typename TinyList, long Pos >
struct tiny_list_iterator
{
    typedef typename tiny_list_item<TinyList,Pos>::type type;
    typedef tiny_list_iterator<TinyList, Pos-1> prior;
    typedef tiny_list_iterator<TinyList, Pos+1> next;
    template< typename N > struct advance
    {
        typedef tiny_list_iterator<
              TinyList
            , Pos + N::value
            > type;
    };
};
\end{verbatim}
\end{codesamp}
}

).

While the \code{tiny\_list} itself might be not that 
interesting - after all, it can hold only 3 elements, if 
the technique above can be automated so we would be able to 
define not so tiny sequence - with 5, 10, 20, etc. number 
of elements, when it would be very valuable (random access 
is almost as important at compile-time as it is at run-time 
- for example searching something in a sorted random-access 
sequence using \code{lower\_bound} can be up to N 
[need to measure!] time faster than doing the same operation 
on forward-access only \code{list}). External code generation 
is one option here, but there is also a solution within the 
language, although it's not a template metaprogramming, 
but preprocessor metaprogramming [PRE]. In fact, 
\code{mpl::vector} - a fixed-size type sequence that 
provides random-access iterators - is implemented very like 
the above \code{tiny\_list}. 

\subsubsection{Why Library-Provided Iteration is Important}

So, the library provides you with almost complete compile-time 
equivalent of STL framework. Does it help you to solve you 
metaprogramming tasks? Let's return to our \code{largest} 
example to see if we can rewrite it in a better way with what 
\code{mpl} has to offer. Well, actually there is not 
much to look at, because implementation of it with MPL is a 
one-liner:

{\small
\begin{codesamp}\begin{verbatim}
template< typename Sequence >
struct largest
{
    typedef typename mpl::max_element<
          Sequence
        , mpl::less<
              mpl::size_of<_1>
            , mpl::size_of<_2>
            >
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

%%% agurt: I sound like a sales person below :)
No more termination conditions with a tricky patterns matching, 
no more partial specializations, and that's even more important, 
it's \emph{obvious} that's the above code does - even although 
it's all templates - something that you cannot say about the 
original version.

\subsubsection{iter\_fold/iter\_find as two main iteration 
algorithms}

For the purpose of examination a little bit more of the 
library's internal structure, let's look at how the 
\code{max\_element} algorithm from the above example is 
implemented. One might expect that \emph{now} we will again 
see all these awkward partial specializations, esoteric 
patterns matching, etc. Well, let's see:

{\small
\begin{codesamp}\begin{verbatim}
namespace aux {
template< typename Predicate >
struct select_max
{
    template< typename OldIterator, typename Iterator >
    struct apply
    {
        typedef typename mpl::apply<
              Predicate
            , typename OldIterator::type
            , typename Iterator::type
            >::type condition_;

        typedef typename mpl::select_if<
              condition_
            , Iterator
            , OldIterator
            >::type type;
    };
};
} // namespace aux 

template<
      typename Sequence
    , typename Predicate
    >
struct max_element
{
    typedef typename mpl::iter_fold<    
          Sequence
        , typename mpl::begin<Sequence>::type
        , aux::select_max<Predicate>
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

First thing to notice here is that this algorithm is in fact 
implemented in terms of another one - \code{iter\_fold}. 
In fact, this is probably the most important point of the 
example, because all other generic sequence algorithms in 
the library are implemented either in terms of \code{iter\_fold}
(or it's counterpart \code{find\_if}) as well. In particular, 
% Do you really mean to say these are counterparts? You had iter_find
% in the section title.
that means that if you would ever need to implement your own 
sequence algorithm, there is a huge chance that you'll be able 
to do it using either \code{iter\_fold} or \code{find\_if} - 
in other words, that means that you won't have to resort to 
implementing hand-crafted iteration and everything that is 
associated with it (patterns matching/special cases for 
termination condition, workarounds for lack of partial 
specialization, etc.) yourself. Also, that means that if the 
library took special care for making such iteration as much 
effective as it's possible (for example, using such techniques 
as recursion unrolling), your brand-new algorithm will 
automatically benefit from these optimizations as well. And of 
course it means that your algorithm will work with any 
sequence that is a model of \code{mpl}'s 
ForwardSequence, because it's the only requirement of 
\code{iter\_fold}/\code{find\_if} pair.

\code{iter\_fold} is basically a compile-time equivalent of 
\code{fold}/\code{reduce} functions that are one of the basic 
and well-known primitives in many functional programming 
languages. A more familiar to a \Cpp\ programmer analogy would 
be \code{std::accumulate} algorithm from the \Cpp\ standard 
library. \code{iter\_fold} is defined in \code{mpl} 
as follows:

{\small
\begin{codesamp}\begin{verbatim}
template<
      typename Sequence
    , typename InitialState
    , typename ForwardOp
    , typename BackwardOp = identity<_1>
    >
struct iter_fold
{
    typedef ... type;
};
\end{verbatim}
\end{codesamp}
}

% it's not really ``implementation-defined'', but unspecified.

The algorithm ``returns'' the result of two-way successive 
applications of binary \code{ForwardOp} and \code{BackwardOp}
operations to iterators in range 
[\code{begin<Sequence>::type}, \code{end<Sequence>::type}) 
and previous result of an operation; 
the \code{InitialState} is logically placed before the 
sequence and included in the forward traversal. The result 
\code{type} is identical to the \code{InitialState} if the 
sequence is empty. 
The library also provides a little bit more high-level 
\code{fold} and \code{fold\_reverse} algorithms that wrap 
\code{iter\_fold} to accommodate it's most common usage 
patterns.

You may wonder why \code{find\_if} - which seems to be much 
more high-level - is placed on the same line with the 
\code{iter\_fold}. Well, one thing about it is that 
\code{find\_if} is the only sequence algorithm that is not 
itself implemented using \code{iter\_fold}. The key difference 
is that \code{find\_if} \emph{terminates} the iteration as 
soon as its predicate satisfied, while \code{iter\_fold} 
always iterates the whole sequence (backward and forward). 
An obvious generalization here would be to add yet another 
parameter to \code{iter\_fold} so it become possible to 
implement everything in terms of the single iteration 
metafunction, but we decided that this would be an 
over-generalization. For one, it would mean that the 
termination condition would be always calculated even 
although for most uses of \code{iter\_fold} it's not needed. 
An overhead like this just goes against the library's strike 
for maximum compile-time performance.


\subsubsection{Sequences of Types, but there are Shortcuts for Numbers}

What we've seen so far were sequences (and algorithms on 
sequences) of types. It's very much possible and easy to 
manipulate values using the library as well. The only thing 
to remember is that in \Cpp\ class template non-type template 
parameters is one more example of non-polymorphic behavior. %%% (??).
That means, that if you declared a metafunction to take a 
non-type template parameter - let's say \emph{long} - 
it's not possible to pass anything besides compile-time 
integral constants to it:

{\small
\begin{codesamp}\begin{verbatim}
template< long N1, long N2 >
struct equal_to
{
    static bool const value = (N1 == N2);
};

equal_to<5,5>::value; // ok
equal_to<int,int>::value; // error!
\end{verbatim}
\end{codesamp}
}

And of course this doesn't work the other way around either:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list<1,2,3,4,5> numbers; // error!
\end{verbatim}
\end{codesamp}
}

While this may be an obvious limitation, it imposes yet 
another dilemma on the library design - on one hand, we don't 
want to restrict users to type manipulations only, and on another 
hand, full support for integral manipulations would require at 
least duplication of most of the library facilities (ideally, 
if going this route, all the templates should be re-implemented 
for every integral type - \code{char}, \code{int}, \code{short},
\code{long}, etc.) - the same situation as we would have if we 
had chosen to represent \mfns\ as ordinary class templates.
The solution for this issue is the same as well - we represent 
integral values by wrapping them in types, so, for example, to 
create a list of numbers you write:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list<
      mpl::int_c<1>
    , mpl::int_c<2>
    , mpl::int_c<3>
    , mpl::int_c<4>
    , mpl::int_c<5>
    > numbers;
\end{verbatim}
\end{codesamp}
}

Wrapping integral constants into types to make them 
first-class citizens is important well inside metaprograms, 
where you often don't know (and don't care) if the 
\mfns\ you are using operate on types, integral 
values, other \mfns\, or something else, like 
fixed-point or rational numbers (\code{mpl::fixed\_c} 
and \code{mpl::rational\_c}).

But from user's perspective, the above example is much more
verbose than the shorter one, the one that was incorrect. So, 
for the convenience purposes, the library does provide users 
with a template that takes non-type template parameters, but 
allows a more compact notation:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list_c<long,1,2,3,4,5> numbers;
\end{verbatim}
\end{codesamp}
}

There is a similar \code{vector} counterpart as well:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::vector_c<long,1,2,3,4,5> numbers;
\end{verbatim}
\end{codesamp}
}


\subsubsection{Why External Functions for all Algorithms}

\begin{enumerate}
 \item while the nested functions notation in some cases is 
 less verbose, 

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list<char,short,int,long> types;
typedef mpl::select_if<
      types::empty
    , long
    , types::back
    >::type t;
\end{verbatim}
\end{codesamp}
}

it is also less generic/more intrusive; requiring a sequence 
class to implement \code{size}, \code{empty}, \code{at}, etc. 
algorithms as members is often unnecessary and over restrictive. 
In many cases the default implementations provided by the library 
are sufficient.
Currently the only requirement that a ``foreign'' sequence should 
conform to in order to be used with the library algorithms is to 
implement external \code{begin}/\code{end} \mfns; you 
don't have to modify your sequence code; with the requirement to 
provide these as nested functions that wouldn't be the case anymore. 

\item if a nested function has at least one argument, and it's 
invoked on a sequence that is a template parameter, or depends 
on a template parameter, the notation actually becomes more 
verbose, e.g. 

{\small
\begin{codesamp}\begin{verbatim}
struct my_func
{
    template< typename Sequence, typename N > struct apply
    {
        // invoking 'at' nested metafunction on a Sequence class
        typedef typename Sequence::template at<N>::type type;
    };
};
\end{verbatim}
\end{codesamp}
}

comparing to the current 

{\small
\begin{codesamp}\begin{verbatim}
struct my_func
{
    template< typename Sequence, typename N > struct apply
    {
        typedef typename mpl::at< N,Sequence >::type type;
    };
};
\end{verbatim}
\end{codesamp}
}

\item placing functions inside of a sequence class makes 
impossible to pass them around as predicates/function classes: 

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list< seq1,seq2,seq3 > sequences; // list of sequences
// find first non-empty sequence
typedef mpl::find_if< sequences, mpl::size<_1> >::type itor;
\end{verbatim}
\end{codesamp}
}

instead, you have to write an explicit predicate for every such case, 

{\small
\begin{codesamp}\begin{verbatim}
struct size_pred
{
    template< typename Sequence > struct apply
    {
        typedef typename Sequence::size type;
    };
};

// find first non-empty sequence
typedef mpl::find_if< sequences,size_pred >::type itor;
\end{verbatim}
\end{codesamp}
}

\end{enumerate}

 
  \subsubsection{A Variety of Sequences}

Previous efforts to provide generalized /mping/ facilities for C++
have always concentrated on \code{cons}-style type lists and a few
core algorithms like 'size' and 'at' which are tied to the specific
sequence implementation. Such systems have an elegant simplicity
reminiscent of the analogous functionality in pure functional Lisp. It
is much more time-consuming to implement even a basic set of the
sequence algorithms provided by equivalent run-time libraries (STL in
particular), but if we have learned anything from the STL it is that
tying those algorithms' implementations to a specific sequence
implementation is a misguided effort!

The truth is that there is no single ``best'' type sequence
implementation for the same reasons that there will never be a single
``best'' runtime sequence implementation. Furthermore, there are
\emph{already} quite a number of type list implementations in use
today, and just as the STL algorithms can operate on sequences which
don't come from STL containers, so the MPL algorithms are designed to
work with foreign type sequences.

It may be an eye-opening fact for some that type lists are not the
only useful compile-time sequence. Again, the need for a variety of
compile-time containers arises for the same reasons that we have
lists, vectors, deques, and sets in the \Cpp\ standard library -
different containers have different functional and performance
characteristics which determine not only applicability and efficiency
of particular algorithms, but also the expressiveness or verbosity of
the code that uses them. While runtime performance is not an issue for
\Cpp\ metaprograms, compilation speed is often a significant
bottleneck to advanced \Cpp\ software development [Abr01].

The \Mpl\ provides four built-in sequences: \code{type\_\-list},
\code{value\_\-list} (really just a \code{type\_list} of value
wrappers), \code{type\_vector}, a randomly--accessible sequence of
fixed maximum size, and \code{range\_c}, a randomly--accessible
sequence of consecutive integral values. More important, however, is
its ability to adapt to arbitrary sequence types. The only core
operations that a sequence is required to provide in order to be used
with the library algorithms are \code{begin<>} and \code{end<>} \mfns\
which ``return'' iterators into to the sequence. As in the STL it is
the iterators which are used to implement most of the general purpose
sequence algorithms the library provides. Also as in STL, algorithm
specialization is used to take advantage of implementation knowledge
about particular sequences: many of the ``basic'' sequence operations
such as \code{back<>}, \code{front<>} \code{size<>} and \code{at<>}
are specialized on sequence type to provide a more efficient
implementation than the fully generic version.


  \subsubsection{loop unrolling}

Almost coincidentally, loop unrolling can be as important to
compile-time iterative algorithms as it is to runtime algorithms. To
see why, one must first remember that all ``loops'' in \Cpp\
metaprograms are in fact implemented with recursion, and that the
depth of template instantiations can be a valuable resource in a
compiler implementation. In fact, Annex B of the \Cpp\ standard
\emph{recommends} a minimum depth of 17 recursively nested template
instantiations, but this is far too low for many serious \mpgms\ some
of which easily exceed the hard-coded instantiation limits of some
otherwise excellent compilers. To see how this works in action, let's
examine a straightforward implementation of the \code{fold} \mfn,
which combines some algorithm state with each element of a sequence:

{\small
\begin{codesamp}\begin{verbatim}
// Unspecialized version combines the initial state and first element
// and recurses to process the rest
template<class Start, class Finish, class State, class BinaryFunction>
struct fold
  : fold<typename Start::next, Finish
      , apply<BinaryFunction,State,typename Start::type>::type
      , BinaryFunction>
{
};

// Specialization for loop termination
template<class Finish, class State, class BinaryFunction>
struct fold<Finish,Finish,State,BinaryFunction>
{
    typedef State type;
};
\end{verbatim}
\end{codesamp}
}

Although simple and elegant, this implementation will always incur at
least as many levels of recursive template instantiation as there are
elements in the input sequence.\footnote{It could be much more,
depending on the complexity of the \code{apply<...>} expression, whose
depth is added to the overall recursion depth.} The library addresses
this problem by explicitly ``unrolling'' the recursion. To apply the
technique to our \code{fold} example, we begin by factoring out a
single step of the algorithm. Our \code{fold\_\-step} \mfn\ has two
results: \code{type} (the next state), and \code{iterator} (the next sequence position).

{\small
\begin{codesamp}\begin{verbatim}
template <class BinaryFunction, class State, class Start, class Finish>
struct fold_step
{
    typedef typename
         apply<BinaryFunction,State,typename Start::type>::type
    type;
    typedef typename Start::next iterator;
};
\end{verbatim}
\end{codesamp}
}

As with our main algorithm implementation, we specialize for the loop
termination condition so that the step becomes a no-op:

{\small
\begin{codesamp}\begin{verbatim}
template <class BinaryFunction, class State, class Finish>
struct fold_step<BinaryFunction,State,Finish,Finish>
{
    typedef State type;
    typedef Finish iterator;
};
\end{verbatim}
\end{codesamp}
}

Now we can now reduce \code{fold}'s instantiation depth by any
constant factor N simply by inserting N invocations of
\code{fold\_\-step}. Here we've chosen a factor of 4:

{\small
\begin{codesamp}\begin{verbatim}
template<
      typename Start
    , typename Finish
    , typename State
    , typename BinaryFunction
    >
struct fold
{
 private:
    typedef fold_step<
        BinaryFunction,State,Start,Finish> next1;
    
    typedef fold_step<
        BinaryFunction,typename next1::type
      , typename next1::iterator,Finish> next2;
    
    typedef fold_step<
        BinaryFunction,typename next2::type
      , typename next2::iterator,Finish> next3;
    
    typedef fold_step<
        BinaryFunction,typename next3::type
      , typename next3::iterator,Finish> next4;
    
    typedef fold<
        typename next4::iterator
        , Finish
        , typename next4::type
        , BinaryFunction
     > recursion;
 public:
    typedef typename recursion::type type;
};
\end{verbatim}
\end{codesamp}
}

The \Mpl\ applies this unrolling technique across all algorithms with
an unrolling factor tuned according to the demands of the \Cpp\
implementation in use, and with an option for the user to override the
value.\footnote{This implementation detail is made relatively painless
through heavy reliance on the Boost Preprocessor Library, so only one
copy of the code needs to be maintained.} This fact enables users to
push beyond the \mping\ limits they would usually encounter with more
naive algorithm implementations. Experiments also show a small
increase in \mpgm\ instantiation speed on some compilers when loop
unrolling is used.

{\small
\begin{codesamp}\begin{verbatim}
\end{verbatim}
\end{codesamp}
}

  \subsubsection{numbered forms of \code{list}}
  \subsubsection{algorithm support lambda}

\subsection{Code generation facilities}

\subsection{execute}

There are cases, especially in domain of numeric computations, then 
you want make some part of calculations at compile-time, and then 
pass the results to a run-time part of the program for further 
processing. For example, suppose you've implemented a complex 
compile-time algorithm that works with fixed-point arithmetics:

{\small
\begin{codesamp}\begin{verbatim}
// fixed-point algorithm input
typedef mpl::vector<
      mpl::fixed_c<-1,2345678>
    , mpl::fixed_c<9,0001>
    // ..
    , mpl::fixed_c<3,14159>
    > input_data;

/*
  complex compile-time algorithm 
*/
typedef /*...*/ result_data;
\end{verbatim}
\end{codesamp}
}

Suppose the \code{result\_\-data} here is a sequence of 
\code{mpl::fixed\_c} types that keeps the results of your 
algorithm, and now you want to feed that result to run-time part 
of the algorithm. With \code{boost::mpl} you can do it this way:

{\small
\begin{codesamp}\begin{verbatim}
namespace aux {
struct push_back
{
    template< typename T > struct apply
    {
        template< typename C > void execute(C& c)
        {
            // in our case T() == fixed_c() == fixed_c().operator()()
            c.push_back(T());
        }
    };
};
}

double my_algorithm()
{
    // passing the results to the run-time part of the program
    std::vector<double> results;
    results.reserve(mpl::size<result_data>::value);
    mpl::for_each<result_data, aux::push_back>::execute(results);
    // ...
}
\end{verbatim}
\end{codesamp}
}

\code{for\_each<...>::\-execute} call there is what actually 
transfers the compile-time \code{result\_\-data} into run-time 
\code{std::vector<double> results}. The \code{for\_each} algorithm 
is one of the explicit facilities the library provides for run-time 
code generation:

{\small
\begin{codesamp}\begin{verbatim}
template<
      typename Sequence
    , typename Operation
    >
struct for_each
{
    template< typename T >
    static void execute(T& x)
    {
       // ...
    }

    static void execute()
    {
       // ...
    }
};
\end{verbatim}
\end{codesamp}
}

The semantics of \code{for\_each::\-execute} is simple: it 
iterates over a \code{Sequence} and applies the \code{Operation}
for each element \code{E} of the sequence:

{\small
\begin{codesamp}\begin{verbatim}
mpl::apply<Operation,E>::execute(x);
\end{verbatim}
\end{codesamp}
}

Applying this to our example, the 

{\small
\begin{codesamp}\begin{verbatim}
mpl::for_each<result_data, aux::push_back>::execute(results);
\end{verbatim}
\end{codesamp}
}

line is equivalent to this:

{\small
\begin{codesamp}\begin{verbatim}
mpl::apply< Operation, mpl::at_c<result_data,0>::type >::execute(results);
mpl::apply< Operation, mpl::at_c<result_data,1>::type >::execute(results);
// ...
mpl::apply< Operation, mpl::at_c<result_data,n>::type >::execute(results);
\end{verbatim}
\end{codesamp}
}

There are other ways to generate an analogous code, 
but they are much less expressive.


\subsection{Lambda facility}

\section{Design of mpl}
\subsection{Design goals}
\subsection{Design decisions}
\subsubsection{Use of iterators}
\subsubsection{Abstraction of sequences}

\section{An advanced example - compile-time FSM generator}

Finite state machines (FSM) are an important tool of 
describing and implementing controlling program behavior 
[HU79], [Mar98]. They also are a good example of the domain 
where some \mping{} can be applied to reduce the amount of 
repetitive and boilerplate operations one have to perform 
in order to implement these simple mathematical models in 
code. As a further illustration of the tools and techniques 
described early in this paper, below we present a simple 
state machine generator that takes a compile-time automata 
description as its input, and produces a complete and 
efficient FSM implementation as the output, - all within 
the same language (\Cpp\ ), and at compile time.

Suppose we want to implement a simple music player using a 
finite state machine model. The state transition diagram for 
the FSM is shown in Figure 1, and Table 1 present the 
corresponding state transition table (STT). The SST format 
reflects the way one usually describes the behavior of a FSM 
in plain English. For example, the first line of the table 
can be read as follows: ``If the model is in the \code{stopped}
state, and the \code{play\_\-event} is received, then the 
\code{do\_\-play} transition function is called, and the model 
goes into the \code{playing} state''.

\begin{figure}[t]
\vskip.2in
\caption{Player's state transition diagram.}
\end{figure}

\begin{table}[ht]
\begin{center}
\caption[Player's state transition table with actions.]%<-- this version will appear in List of Tables
{Player's state transition table with actions.}%<-- this version will appear on page
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}cccc}
\sphline
\it State &\it Event &\it Next State &\it Transition Function\cr
\sphline
stopped&play\_event&playing&do\_play\cr
playing&stop\_event&stopped&do\_stop\cr
playing&pause\_event&paused&do\_pause\cr
paused&play\_event&playing&do\_resume\cr
paused&stop\_event&stopped&do\_stop\cr
\sphline
\end{tabular*}
\end{center}
\end{table}

%%% can we kill the ``_event'' suffix here?

The transition table provides us with complete formal 
definition of the target FSM, and there are several ways to 
transform that definition into code. For example, if we define
states as members of enumeration type, and events as classes 
derived from some base \code{event}
class (they need to be passed to action functions, and they may
contain some event-specific information for an action), 

{\small
\begin{codesamp}\begin{verbatim}
class player
{
 public:
    // event declarations
    struct event;
    struct play_event;
    struct stop_event;
    struct pause_event;

    // "input" function
    void process_event(event const&); // throws

 private:
    // states
    enum state_t { stopped, playing, paused };

    // transition functions
    void do_play(play_event const&);
    void do_stop(stop_event const&);
    void do_pause(pause_event const&);
    void do_resume(play_event const&);

 private:
    state_t m_state;
};
\end{verbatim}
\end{codesamp}
}

%%% IMO this implementation bends over backward to be inefficient. My
%%% first thought would have been:
%%
%%     // "input" function
%%     template <class Event>
%%     void process_event(Event const&); // throws
%%
%%  private:
%%     // states
%%     enum state_t { stopped, playing, paused };
%%
%%     // transition functions
%%     void transition(play_event const&);
%%     void transition(stop_event const&);
%%     void transition(pause_event const&);
%%     void transition(play_event const&);
%%
%%% Which avoids RTTI AFAICT.
%%%
%%% And then, once I realized that it wouldn't work ;-) I would have
%%% used an event base class which contained its own event ID. There
%%% are lots of ways to achieve this:
%%
%% struct event_base
%% {
%%   event_base(unsigned id) : m_id(id) {}
%% protected:
%%   static unsigned counter;
%% private:
%%   unsigned m_id;
%% };
%% template <class Event> struct event : event_base
%% {
%%    event() : event_base(id) {}
%%    virtual ~event();
%%    static unsigned id;
%% };
%% template <class Event> struct event_base<Event>::id = counter++;
%% struct play : event<play> { ... };

then the most straightforward way to derive the FSM 
implementation from the above table would be something 
like this:

{\small
\begin{codesamp}\begin{verbatim}
void
player::process_event(event const& e)
{
    if (m_state == stopped)
    {
        if (typeid(e) == typeid(play_event))
        {
            do_play(static_cast<play_event const&>(e));
            m_state = playing;
            return;
        }
    }
    else if (m_state == playing)
    {
        if (typeid(e) == typeid(stop_event))
        {
            do_stop(static_cast<stop_event const&>(e));
            m_state = stopped;
            return;
        }

        if (typeid(e) == typeid(pause_event))
        {
            do_pause(static_cast<pause_event const&>(e));
            m_state = paused;
            return;
        }
    }
    else if (m_state == paused)
    {
        if (typeid(e) == typeid(stop_event))
        {
            do_stop(static_cast<stop_event const&>(e));
            m_state = stopped;
            return;
        }

        if (typeid(e) == typeid(play_event))
        {
            do_play(static_cast<play_event const&>(e));
            m_state = playing;
            return;
        }
    }
    else
    {
        throw logic_error(
            boost::format("unknown state: %d")
                % static_cast<int>(m_state)
            );
    }

    throw std::logic_error(
        "unexpected event: " + typeid(e).name()
        );
}
\end{verbatim}
\end{codesamp}
}

%%% Not sure the part below is too relevant
Note that despite seemed obviousness of optimization of making 
a transition function to return the next state in not such a 
good idea. While it will reduce the amount of lines required 
to describe a single transition, it also would take the 
transition control away from FSM driver function into 
application-level code. For one, that would mean and you'd no 
longer be able to say in what state the machine is going to 
move after it handles a specific event - you'll have to look 
into transition function itself. [...] 

Although there is nothing particularly wrong with implementing 
a FSM's structure using nested \code{if} (or \code{switch-case})
statements, the obvious thing about this approach is that it 
doesn't scale - even for our simple FSM the 
\code{process\_\-event} function is already more than 50 lines
long. One way to reduce the maintenance problems would be to 
factor bodies of top-level \code{if} statements in separate 
event processing functions, one for each state:

%%% I think a simple example of a switch statement from a naive lexer
%%% implementation would suffice to show why the switch/if approach is
%%% bad, and we could afford to show just a single example of this,
%%% taking it on faith that people will understand.

{\small
\begin{codesamp}\begin{verbatim}
void
player::process_event(event const& e)
{
    if (m_state == stopped)  m_state = process_stopped_state_event(e);
    else if (m_state == playing) m_state = process_playing_state_event(e);
    else if (m_state == paused) m_state = process_paused_state_event(e);
    else
    {
        throw logic_error(
            boost::format("unknown state: %d")
                % static_cast<int>(m_state)
            );
    }
}
\end{verbatim}
\end{codesamp}
}

where, for example, \code{process\_\-playing\_\-state\_\-event} 
function would look like this:

{\small
\begin{codesamp}\begin{verbatim}
player::state_t
player::process_stopped_state_event(event const& e)
{
    if (typeid(e) == typeid(stop_event))
    {
        do_stop(static_cast<stop_event const&>(e));
        return stopped;
    }

    if (typeid(e) == typeid(pause_event))
    {
        do_pause(static_cast<pause_event const&>(e));
        return paused;
    }

    throw std::logic_error(
        "unexpected event: " + typeid(e).name()
        );

    return m_state;
}
\end{verbatim}
\end{codesamp}
}

Still, if the number of events being handled from particular 
state is large, the problem remains. Of course, the fact that 
the technique tends to lead to large functions is only one 
side of the problem; after all, you can split the functions 
even further - and that's in fact what the State pattern does.

%%% This is a good point
Another obvious thing about it that most of the code is 
boilerplate. What you tend to do with boilerplate code is copy 
and paste it, and then change names etc. to adjust it to its new 
location, and that's there the errors are most likely to creep in
- since all the lines of events processing look alike 
(structurally), it's very easy to overlook or forget something 
that's need to be changed, and many of such errors won't appear 
until the runtime.

[...]

Note that all the implementations we've looked on has this common 
trait - the transition table of our FSM is just a 5-lines table, 
and ideally, we would like the skeleton implementation of the 
automata's controlling logic to be equally small (or, at least, 
to look equally small, e.g. to be encapsulated in some form so 
we never see/worry about it). 

Implementing it

First thing to think about is how we would like the generator's 
input look like, in particular, how we want to represent a 
transition table. To represent the TTS in \Cpp\ program, we define 
a \code{transition} class template that represents a single line 
of the table, and than the table itself can be represented as a 
sequence of such lines:

{\small
\begin{codesamp}\begin{verbatim}
typedef list<
      transition<stopped, play_event,  playing, &player::do_play>
    , transition<playing, stop_event,  stopped, &player::do_stop>
    , transition<playing, pause_event, paused,  &player::do_pause>
    , transition<paused,  play_event,  playing, &player::do_resume>
    , transition<paused,  stop_event,  stopped, &player::do_stop>
    >::type transition_table;
\end{verbatim}
\end{codesamp}
}

pros:
\begin{enumerate}
\item readability, direct mapping between a FSM design and 
    implementation ( one-to-one relation between the 
    definition and the state table of the FSM )
\item performance %%%??
\item compile-time checking 
\item FSM ``installation'' is done at compile-time; cost 
    nothing in performance 
\item only transition actions need to be implemented 
    (no need to inherit, extend classes, etc.) 
\item entry and exit methods can be supported easily 
    (and will be called automatically); you also don't have 
    to pay for them, if you don't use them 
\end{enumerate}

cons:
\begin{enumerate}
\item can't handle large FSMs (N transitions > 100) 
\item compile times for FSMs with N transitions > 50 
\end{enumerate}


Related work

A notable prior work in the field of automation of general-purpose 
state machine implementation in \Cpp\ is the Robert Martin's State 
Machine Compiler [SMC]. The SMC takes an ASCII description of the 
machine's state transition table and produces a \Cpp\ code that 
implements the FSM using a variation of State design pattern [Hun91],
[GHJ+95]. [Laf00] presents another approach, where no external tools 
are used, and the FSMs are table driven. 


\section{About implementation}

\section{Lessons learned}

\section{Conclusions}
\section{Acknowledgements}
\section{References}

\bibliographystyle{abbrv} \bibliography{refs}

\end{document}
% LocalWords:  Aleksey David Gurtovoy Abrahams MPL STL Boost boost
