[/
  (C) Copyright 2009 Justin E. Gottchlich.
  (C) Copyright 2009 Vicente J. Botet Escriba
 /
 / Distributed under the Boost Software License, Version 1.0. (See accompanying
 / file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)
 /]

[section:rationale Appendix B: Rationale]

[section TM-Specific Concepts]

[section Optimistic concurrency]
[endsect]

[section ACI transactions]

Transactional memory was founded on the database ACID principle (atomic, consistent, isolated and durable), except without the D (durability) because unlike database transactions, TM transactions are not saved to permanent storage (e.g., hard drives).

* Transactions are atomic; the operations all commit or none of them do.
* Transactions are consistent; transactions must begin and end in legal memory states.
* Transactions are isolated; memory changes made within a transaction are invisible until committed.

The below example gives a basic introduction into __Boost_STM_s__ transactional framework and demonstrates __Boost_STM_s__ ACI conformance.

    native_trans<int> global_int;
    int increment_global() {
        atomic(t) {
            t.write(global_int)++;
            val = t.read(global_int);
        } end_atom
        return val;
    }

In the above example, (A) both the t.write() and t.read() operations function atomically or neither operations are performed.
In addition, (C) the transaction begins and ends in legal memory states, meaning global int is guaranteed to be read correctly, preventing thread data races from causing inconsistent results. Lastly, (I) the intermediate state of the incremented global int is isolated until the transaction commits. These three attributes fulfill __Boost_STM_s__
conformance to the ACI principles. The above example also gives a basic introduction into __Boost_STM_s__ transactional
framework.

[endsect]

[section STM Synchronization Types]

There are two ways STM systems synchronize memory:

# using non-blocking mechanisms (lock-free) or
# using lock-based (or blocking) mechanisms.

Non-blocking STM systems use atomic primitives, such as, compare-and-swap (CAS) or load-linked and store-conditional (LL-SC), that do not lock the STM system to perform their transactional operations. Lock-based STM systems use locks, such as mutual exclusion locks, which lock the STM system to perform some portion of their transactional operations.

__Boost_STM__ is a lock-based STM system. At its core, __Boost_STM__ uses one lock per thread to implement transactional reads and writes. This allows multiple transactions to simultaneously read and write without blocking other transactions' progress. When a transaction is committing, a global locking strategy is used to temporarily block forward progress on all transactions except the committing one. Once the committing transaction completes, other transactions are allowed to resume their work. __Boost_STM_s__ lockbased strategy allows it to gain the performance benefits of a nonblocking system, such that when transactions are not committing, the transactions do not block each other and are guaranteed to make forward progress. Yet __Boost_STM__ maintains the benefits of a lockbased system, enabling it to perform commit-time invalidation, its primary consistency model mechanism.

Recent research shows lock-based STM systems outperform non-blocking systems. Our own research shows that through
__Boost_STM_s__ design, scaling concerns and other lock-based specific problems, such as deadlocking and priority inversion, can be overcome with specific contention management and conflict detection policies.

[endsect]

[section Updating policies]

In any STM system, an updating protocol must be used to perform transactional commits for writes. Updating policies determine how a transaction commits its memory updates to global memory. Two general ways exist to perform updating:

# direct updating, which copies the original global memory state off to the side and then writes directly to global memory, and
# deferred updating, which copies the original global memory off to the side and the writes to the local copy.

When a transaction of a direct updating system commits its changes, no changes to global memory are made as the STM system has written directly to global memory. When a transaction of a deferred updating system commits its changes, it writes the local changes to global memory. When a direct updating system aborts, it uses the original copy of memory to update global memory, restoring it to its original state. When a deferred updating system aborts, no changes to global memory are made as the STM system has not written anything to global memory. One of __Boost_STM_s__ novel features is its implementation of both direct and deferred updating.

[endsect]

[section Conflict Detection]

Conflict detection is the process of identifying when two or more transactions conflict. Conflicts can exist when a transaction writes to memory that another transaction then reads or writes (write after write, write after read), or when a transaction reads memory that is then used in another transaction's write (read after write). Unlimited readers, on the other hand, can read the same piece of memory without any conflict (read after read).

[table Comparaison with other STM systems
    [
        [[*Features]]       [[*after write]]   [[*after read]]
    ]
    [
        [[*write]]       [[*YES]]   [[*YES]]
    ]
    [
        [[*read]]     [[*YES]]   [[*NO]]
    ]
]


Before determining how to handle a conflict, STM systems must determine when they will detect conflicts. There are two primary ways to detect conflicts:

* Early conflict detection attempts to identify conflicts as soon as a transaction reads or writes to memory.
* Late conflict detection attempts to identify conflicts some time after the initial read or write.

For direct updating, __Boost_STM__ implements a run-time configurable early and late conflict detection mechanism. For deferred updating, __Boost_STM__ only implements late conflict detection. The decision to have __Boost_STM__ only support late conflict detection for deferred updating was made after identifying numerous lost optimizations using early conflict detection with deferred updating.

Future work may lead to the implementation of early conflict detection for deferred updating simply for symmetry.

[endsect]

[section Consistency checking policies]

An STM system can identify a conflict in two principal ways: through validation or invalidation.

* Validation is the process a transaction performs on its own read and write set to check itself for consistency.
* Invalidation is the process a transaction performs on other transaction's read and write sets to check them for consistency.

Validation strategies usually have the the transaction abort itself if an inconsistency is found. Invalidation strategies usually do just the opposite, aborting the other transactions if an inconsistency is found. In addition, STM systems can use contention managers to determine how best to behave when inconsistent transactions are identified.

__Boost_STM__ currently implements consistency checking only through invalidation. One of the next goals of __Boost_STM__ is to build run-time configuration of consistency checking for both invalidation and validation, as it is believed that both may be necessary for varying problems. This aside, __Boost_STM__ is unique in that it is the first STM system to implement commit-time invalidation. While other systems, such as __RSTM__, have implemented invalidation, no other system implements commit-time invalidation.

We believe __Boost_STM__ is the first commit-time invalidating system due to commit-time invalidation being seemingly only possible in lock-based STM systems and as lock-based STM systems are relatively new, other lock-based systems not being far enough along to implement it yet. The two key differences we focus on in this work between invalidation and validation are;

# invalidation can save many wasted operations by early notification of doomed transactions, whereas validation cannot and
# invalidation can detect true priority inversion, whereas validation cannot

(other significant differences exist, but are not discussed here).

* Fully validating systems must iterate through all transactional operations and determine consistency only at commit-time. Thus, each transaction must fully execute its transactional operations. A substantial amount of work can be saved by an invalidating system which can flag doomed transactions early, as shown in table 1. Table 1 details 4, 8 and 12 threaded runs for red-black trees, linked lists and hash tables in __Boost_STM__. While the percentage of operational savings decreases for each benchmark as the structure size increases, the actual operational savings improves. For example, if a linked list is inserting at the end of a 1600 node list and receives an early termination notification saving 50% of its operations, the savings gained is an 800 node iteration and insert. Likewise, performing a 90% operations savings in a linked list insert operation of size 100, saves only a 90 node iteration and insert.

Furthermore, not shown in the tables here, due to space limitations, is that abort percentages grow for each benchmark as the data structure size increases. Thus, the number of aborts increases, resulting in an even high amount of abort savings per benchmark. The increasing number of aborts as the data structure grows is quite intuitive as longer running transactions are more likely to incur collisions, especially while operating on the same data structure.

* Priority inversion occurs in TM when a lower priority transaction causes a higher priority transaction to abort. Furthermore, priority inversion can be guaranteed to only abort true priority inverted transactions in an invalidating system. However, validating systems can also build priority inversion schemes, they simply must suffer penalties of potentially aborting transactions unnecessarily. The following section gives concrete examples of handling priority inversion in both validating and invalidating models.


[endsect]

[section Consistency versus Updating policies composition]

While __Boost_STM__ benchmarks show that, deferred updating in our system usually outperforms direct updating, this is not always the case. In particular, direct updating eventually outperforms deferred updating in __Boost_STM__ as the data structure size grows. With this in mind, we believe that direct updating is useful for specific algorithms with highly innate parallelism (such as hash tables). Likewise, we believe validation may outperform invalidation for high thread counted uses. From these conclusions, we believe final STM systems may be required to implement direct updating,  deferred updating, validation and invalidation, all of which should be configurable at run-time and compile-time. By doing this, each problem which demands a different four-way configuration can be handled appropriately. Rather than attempting to build a single implementation which solves all problems universally, the end resulting STM system will handle each specific problem with the most appropriate configuration.

[table Consistency versus Updating policies composition
    [
        [[*Features]]       [[*Direct]]   [[*Deferred]]
    ]
    [
        [[*Validation]]       [[*YES]]   [[*YES]]
    ]
    [
        [[*Invalidation]]     [[*Not Yet Implemented]]   [[*YES]]
    ]
]

[endsect]


[section Memory Granularity]

STM systems must use a memory granularity size of either word or object for transactions. Word memory granularity allows transactions to read and write at the machine's architectural word size. Type memory granularity allows transactions to read and write at the type level, usually controlled by implementation of a transactional object cache. Object memory granularity allows transactions to read and write at the object level, usually controlled by implementation of a transactional object base class using subtype polymorphism. __Boost_STM__ implements the latter, performing reads and writes at the object level.

[endsect]

[section Memory Rollback Capability]

STM systems must implement memory rollback capabilities for aborted transactions. Memory rollbacking restores the original state of memory in the event a transaction aborts. There are three rollbacking aspects any STM system must handle when implemented in an unmanaged language;

* updates to global,
* allocated memory and
* deallocated memory.

__Boost_STM__ handles rollbacking to global memory internally for both direct and deferred updating, requiring no programmer-based code. However, allocated and deallocated memory rollbacking require programmer-specific interfaces to be used. These interfaces handle C++ memory operations in their native capacity - new and delete - as well as their transactional memory capacity, ensuring no memory is leaked nor deleted prematurely.

Examples of this are presented in the following section.

[endsect]

[section Composable transactions]

Composition is the process of taking separate transactions and adding them together to compose a larger single transaction. Composition is a very important aspect of transactions as, unlike locks, transactions can compose. Without a composable TM system, nested transactions each act independently committing their state as they complete. This is highly problematic if an outer transaction then aborts, as there may be no way to rollback the state of a nested (and already committed) transaction. Therefore, implementation of composable transactions is paramount to any TM system which hopes to build large transactions.

__Boost_STM__ implements composition via subsumption and is a closed nested system. Composition via subsumption merges all nested transactional memory of a single thread into the outer most active transaction of that same thread. The outer transaction subsumes all the inner transactions' changes. Once the outer transaction completes, all the transactional memory from the nested transactions and their parent either commit or abort. __Boost_STM_s__ closed nesting system enables each nested transaction visibility into its parent's transactional memory and vice versa, but does not allow other transactions to see this intermediate state.

Future versions of __Boost_STM__ will implement closed nested transactions.

[endsect]

[section Contention management]

[heading Priority-Based Tasks]

Real-time systems or systems that have strict requirements for task behavior, such as deadline-drive systems, usually guarantee such behavior through priority scheduling. While significant prior TM contention management (CM) research has been done, its attention has been primarily focused on preventing starvation through fairness. In many systems preventing starvation may be sufficient, yet some systems (e.g. deadline-driven or real-time systems) require stronger behavioral guarantees. In these cases, user-defined priority-based transactions are necessary.

[heading Approach]

This work extends the prior TM contention management research by concretely implementing user-defined contention managers as determined consequential. We approach this by first presenting a brief background of TM aspects important to understanding the complexities of contention management. Next, we review and expand upon prior contention management work. We then show how consistency models play a significant role in the correctness and capability of priority-based transactional scheduling. We then build user-defined priority-based transactions with __Boost_STM__, demonstrating how contention management frameworks work with different consistency checking models. Last, we present our experimental results.

[heading Attacking & Victim Transactions]

We refer to transactions which can identify a memory conflict in another in-flight transaction as attacking transactions. Transactions which are targeted by attacking transactions are referred to as victim transactions. The attacking and victim transaction terms help simplify the invalidation process. An example of attacking and victim transactions is as follows. Consider transaction Tv, a victim transaction and transaction Ta, an attacking transaction. Tv writes to memory location L0. Ta then tries to write to L0. If our STM system only allows single-writers, both Ta and Tv cannot write to L0 at the same time. As Ta is the second transaction attempting to write to L0, the single-writer semantics require it to deal with the conflict located at L0. Handling this conflict makes Ta the attacking transaction as it decides if Tv is aborted. Tv is the victim transaction since Ta may abort it.

[heading User-Defined Priority-Based Transactions]

Validation and invalidation

consistency checking are both practical solutions to transactional memory for different classes of problems. When inflight transactions are low and memory usage is high, invalidation may be preferred. When transactional traffic is high and transactions are small, validation may be preferred. Neither type of consistency checking seems to perform universally better than the other. Though certain classes of problems perform better under different consistency checking models, the ramifications of these consistency checking schemes performing within strict user-defined priority-based transactional systems is unclear from prior research. Our work clarifies the advantages and disadvantages of validation and invalidation in user-defined priority-based transactional environments.

[heading Extensible Polymorphic Contention Management Interface]

Due to the innumerable possibilities of consistency checking model combinations, for the remainder of this work, we narrow our scope of consistency checking to commit-time validation and committime invalidation. We do this for a number of reasons. First, validation and invalidation are near opposites and commit-time consistency checking is straight forward in that it is only performed once per transaction. Due to this, we can see the two primary views of consistency checking in an understandable fashion. Second, early TM systems tended toward validation while newer TM systems tend toward invalidation. This makes considering both viewpoints practical. Third, both validation and invalidation perform well under different circumstances. By considering both types, we can help extend their current understanding to user-defined priority-based systems as well. Finally, __Boost_STM__ supports both commit-time validation and commit-time invalidation.

__Boost_STM__ extensible contention manager supports two types of management: abort behavior management and conflict resolution management. The abort behavior interfaces are somewhat novel compared to prior work, in that they allow __Boost_STM_s__ contention manager to decide how the system should behave when a transaction must abort. These interfaces, shown in bellow, were added as it was determined that not all aborted transactions should behave in the same manner. For example, some transactions which have extremely large read and write sets, should perhaps sleep for some period of time before running again. Other transactions which have already high priorities, should perhaps receive larger priority boosts.

    class base_contention_manager {
    public:
        virtual void abort_on_new(transaction const &t) = 0;
        virtual void abort_on_delete(transaction const &t, base_transaction_object const &in) = 0;
        virtual void abort_on_read(transaction const &t, base_transaction_object const &in) = 0;
        virtual void abort_on_write(transaction &t, base_transaction_object const &in) = 0;
        // conflict interfaces removed
    };

The interfaces shown above do not manage any memory contention, instead they only handle how required aborts behave.

The second type of __Boost_STM__ contention management interfaces is shown in below.

    class base_contention_manager
    {
    public:
        // abort interfaces removed
        virtual bool abort_before_commit(transaction const &t) = 0;
        virtual bool permission_to_abort(transaction const &lhs, transaction const &rhs) = 0;
    };

These interfaces implement true management of memory conflicts. The two interfaces shown: abort_before_commit() and permission_to_abort() enable two fundamentally different types of consistency checking. abort_before_commit() is called when __Boost_STM__ is performing validating consistency checking, while permission_to_abort() is called when __Boost_STM__ is performing invalidating consistency checking. Both APIs are called internally at different points in the transaction's commit phase.

[endsect]

[section Lock-aware transaction]

Transactional memory (TM) has garnered significant interest as an alternative to existing concurrency methods due to its simplified programming model, natural composition characteristics and native support of optimistic concurrency. Yet, mutual exclusion locks are ubiquitous in existing parallel software due to their fast execution, inherent property for irreversible operations and long-standing underlying support in modern instruction set architectures (ISAs). For transactions to become practical, lock-based and TM-based concurrency methods must be unified into a single model.

__Boost_STM__ presents a lock-aware transactional memory (LATM) solution with a deliberate library-based approach. Our LATM system supports locks inside of transactions (LiT) and locks outside of transactions (LoT) while preserving the original programmer-intended locking structure. Our solution provides three policies with varying degrees of performance and required programming. The most basic LATM policy enables transactionlock correctness without any programming overhead, while improved performance can be achieved by programmer-specified conflicts between locks and transactions. The differences in LATM policy performance are presented through a number of experimental benchmarks on .

[heading Introduction]

Yet, for all of the benefits of transactional programming, its native inoperability with mutual exclusion locks is a major obstacle to its adoption as a practical solution. Mutual exclusion (implemented through locks) is arguably the most predominant form of thread synchronization used in parallel software, yet its native incompatibility with transactions places a considerable restriction on the practical use of TM in real-world software.

A TM system that is cooperative with locks can extend the lifetime and improve the behavior of previously generated parallel programs. __Boost_STM__ C++ library is a lock-aware transactional memory (LATM) system supporting the simultaneous execution of transactions and locks. Of critical importance is that the extended __Boost_STM__ LATM system naturally supports lock-based composition for locks placed inside of transactions (LiT), a characteristic previously unavailable in locks. The LATM policies present in __Boost_STM__ are implemented with software library limitations as a central concern. While novel operating system (OS)-level and language-based transaction-lock cooperative models have been previously found, these implementations use constructs not available in library-based STM systems. While useful, the previously identified OS-level and language-based solutions do not address the critical need for a transaction-lock unified model expressed entirely within the limitations of a software library. In languages that are unlikely to be extended, such as C++, and development environments bound to specific constraints, such as a particular compiler or OS, library based solutions are paramount as they present practical solutions within industry-based constraints. Our approach presents a novel library-based LATM solution aimed at addressing these concerns. __Boost_STM__ makes the following contributions:

# Extension of the __Boost_STM__ library for support of locks outside of transactions (LoT) and locks inside of transactions (LiT).

# Proof that an LATM LiT system naturally enables lock composition. Analytical examples are examined that show LiT composable locks demonstrating atomicity, isolation and consistency as well as deadlock avoidance.

# Introduction of three novel LATM policies: full lock protection, TM-lock protection, and TX-lock protection. Each LATM policy provides different programming / performance trade offs. Experimental results are provided which highlight the performance and programming differences of the three LATM policies.

[heading Background]

Transaction-lock interaction does not natively exhibit shared memory consistency and correctness due to differences in underlying critical section semantics. Strongly and weakly isolated transactional memory systems are susceptible to incorrect execution when used with pessimistic critical sections.

Mutual exclusion locks use pessimistic critical section semantics; execution of a lock-controlled critical section is limited to one thread and guarantees the executing thread has mutually exclusive (isolated) access to the critical section code region. Transactions use optimistic critical section semantics; transaction controlled critical sections support unlimited concurrent thread execution. Shared memory conflicts arising from simultaneous transaction execution are handled by the TM system during the commit phase of the transaction. Optimistic critical sections and pessimistic critical sections are natively inoperable due to their contradictive semantics as demonstrated in the below example:

Lock and transaction violation (code).

    1   native_trans<int> x;
    2
    3   int lock_dec() {
    4       lock(L1);
    5       int val = --x;
    6       unlock(L1);
    7       return val;
    8       }
    9
    10  void tx_inc() {
    11      for (transaction t;;t.restart())
    12      try {
    13          ++t.write(x);
    14          t.end(); break;
    15      } catch (aborted_tx &) {}
    16  }

Without an intervening system, thread T1 executing lock_dec() and thread T2 executing tx_inc() are not guaranteed to operate consistently, as they would if each function were run in a lock-only or transaction-only system, respectively. The following example demonstrates how the correctness of the above code is violated from a deferred update and direct update standpoint.

Deferred Update Lock/Transaction Violation. A deferred update TM system stores transactional writes off to the side, updating global memory once the transaction commits. A deferred update system can exhibit an inconsistency in the above code in the following way. Given: x = 0, thread T1 executes lock_dec() and thread T2 executes tx_inc(). T2 executes line 10 - the first half of line 13 (storing a transactional value for x = 0, but not performing the increment). T1 executes lines 3-5 (global x = -1). T2 executes the remainder of line 13 and line 14 (++x on its stored reference of 0, setting its local x = 1) and then commits. T1 executes lines 6-7. The resulting global state of x = 1 is incorrect; x = 0 is correct as one thread has incremented it and one thread has decremented it.

Direct Update Lock/Transaction Violation. A direct update TM system stores transactional writes directly in global memory, storing an original backup copy off to the side in the event the transaction must be unwound. In a direct update system, threads T1 and T2 can exhibit inconsistencies using the code shown above in a variety of ways; T1 executes line 3 - the first half of line 5 (decrementing x, but not setting val). T2 executes lines 10-13 (incrementing the global x and creating a restore point of x = -1). T1 executes the remainder of line 5 (val = 0). T2 executes line 14, but is required to abort, restoring x to -1. T1 completes and returns val = 0 which is incorrect. T2 never committed its x = 0 and has not successfully committed, therefore, x has never correctly been set to 0.

Overcoming Transaction-Lock Inoperability

In order for transactions and locks to cooperate, transactions must adhere to a single mutual exclusion rule: Mutual exclusion semantics require that instructions within a mutex guarded critical section be limited to <=1 simultaneous thread of execution.

Our LATM implementation adheres to this rule and is discussed in two high-level views:

# locks outside of transactions (LoT) and
# locks inside of transactions (LiT).

__Boost_STM__ supports lock-aware transactions by supplying a pass-through interface that is used in place of prior locking calls.

The __Boost_STM__ locking API is used to perform the additional transaction-lock communication before or after the pthreads interface is called. In all cases, the __Boost_STM__ pass-through interface results in at least one corresponding call to the appropriated  interface to lock, try to lock or unlock the mutual exclusion lock. Further details are provided in later sections.

[heading Locks Outside of Transactions (LoT)]

Locks outside of transactions (LoT) are scenarios where a pessimistic critical section of a lock is executed in a thread T1 while an optimistic critical section of a transaction is executed in a thread T2, simultaneously. Thread T1's lock-based pessimistic critical section is entirely outside of thread T2's transaction, thus the term locks outside of transactions or LoT. Figure 5 sets up a running LoT example, used throughout this section, by constructing six functions which are simultaneously executed by six threads. Three of the functions in the below example, tx1(), tx2() and tx3(), are transaction-based, while the other three functions, lock1(), lock2() and lock3(), are lock-based. The functions tx1(), tx2() and lock3() do not have any memory conflict with any other transaction-based or lock-based function and should therefore be able to run concurrently with any of the other functions. However, certain LoT policies inhibit the execution of these nonconflicting functions; details of such inhibited behavior is explained in the following subsections. The below example is used throughout this section to illustrate the differences in the LoT policies.

    1   native_trans<int> arr1[99], arr2[99];
    2
    3   void tx1() { /* no conflict */ }
    4   void tx2() { /* no conflict */ }
    5   void tx3() {
    6       for (transaction t;;t.restart())
    7       try {
    8           for (int i = 0; i < 99; ++i)
    9           {
    10              ++t.w(arr1[i]).value();
    11              ++t.w(arr2[i]).value();
    12          }
    13          t.end(); break;
    14      } catch (aborted_tx&) {}
    15  }
    16
    17  int lock1() {
    18      transaction::lock(L1); int sum = 0;
    19      for (int i = 0; i < 99; ++i) sum += arr1[i];
    20      transaction::unlock(L1); return sum;
    21  }
    22  int lock2() {
    23      transaction::lock(L2); int sum = 0;
    24      for (int i = 0; i < 99; ++i) sum += arr2[i];
    25      transaction::unlock(L2); return sum;
    26  }
    27  int lock3() { /* no conflict */ }

[heading LoT Full Lock Protection]

The most basic implementation of transaction-lock cooperation, what we call full lock protection, is to enforce all transactions to commit or abort before a lock's critical section is executed. All locks outside of transactions are protected from transactions violating their critical section execution by disallowing transactions to run in conjunction with locks. Transactions are stalled until all LoT critical sections are complete and their corresponding locks are released.

An example of full lock protection is shown in Figure 6 using the previously described six threaded model. Full lock protection has no programmer requirements; no new code is required, aside from alteration of existing locking code to use the LATM passthrough interfaces. Additionally, an understanding of how the locks behave within the system to enable transaction-lock cooperation is also not needed. However, full lock protection suffers some performance penalties. As seen in Figure 6, T1 ?? T3 are blocked for the entire duration of the critical sections obtained in T4 ?? T6, since full lock protection prevents any transactions from running while LoTs are obtained. Although T3 does conflict with T4 ?? T5, T6's critical section does not interfere with any of the transactions and should therefore not prevent any transactions from running concurrently; TM-lock protection, the next level of lock protection, is able to avoid such unnecessary stalling.

[heading LoT TM-Lock Protection]

TM-lock protection is slightly more complex than full lock protection, yet it can yield better overall system performance. TMlock protection works in the following way: locks which can conflict with transactions are identified by the programmer at startup. Once a conflicting LoT is acquired, all in-flight transactions are either committed or aborted. Transactions are then blocked until the conflicting lock-based critical sections are completed and released. Locks that do not conflict with transactions do not cause any transactions to stall.

The identification of locks that can conflict with transactions requires the programmer to (1) write new code and (2) have a basic understanding of the software system. Due to this, the requirements of TM-lock protection are greater on the end programmer. The trade-off for higher programmer requirements is greater overall system performance.

TM-lock protection addresses the problem of transactions unnecessarily stalled when T6 is executing. When using TM-lock protection, the end programmer must explicitly express which locks can conflict with the TM system. In this example, locks L1 and L2 from threads T4 and T5 conflict with tx3 in thread T3. The end programmer would explicitly label these locks as conflicting in the following way:

    1 transaction::do_tm_conflicting_lock_protection();
    2 transaction::add_tm_conflicting_lock(L1);
    3 transaction::add_tm_conflicting_lock(L2);

As shown in the six threaded example, TM-lock protection shortens the overall TM run-time by allowing T1 ?? T3 to restart their transactions as soon as L2's critical section is completed. Yet, there still exists unnecessary stalls in threads T1 and T2 as their associated transactions do not conflict with any of the lock-based critical sections of T4 ??T6. The remaining unnecessary stalls are resolved by using TX-lock protection, the third lock protection policy.

[heading LoT TX-Lock Protection]

TX-lock protection enables maximum performance throughput by identifying only true conflicts as they exist per transaction. TXlock protection is similar to TM-lock protection except rather than requiring conflicting locks be identified at a general TM-level, conflicting locks are identified at a transaction-level. While this level of protection yields the highest level of performance, it also requires the greatest level of familiarity of the locks within the system and the most hand-crafted code.

An example of TX-lock protection is in Figure 8. By using TX-lock protection and explicitly identifying conflicting locks per transaction, the system only stalls for true conflicts, increasing overall system performance. The code required for correct TX-lock protection in the prior six threaded example is shown below by extending the original tx3() implementation:

    1   void tx3() {
    2       for (transaction t;;t.restart())
    3       try {
    4           // identify conflicting locks
    5           t.add_tx_conflicting_lock(L1);
    6           t.add_tx_conflicting_lock(L2);
    7           for (int i = 0; i < 99; ++i)
    8           {
    9               ++t.w(arr1[i]).value();
    10              ++t.w(arr2[i]).value();
    11          }
    12          t.end(); break;
    13      } catch (aborted_tx&) {}
    14  }

Using TX-lock protection, threads T1 and T2 are no longer stalled when threads T4 and T5 lock their associated locks, L1 and L2. In fact, only thread T3 (the only true conflict) is stalled while the critical sections created by L1 and L2 are executing, resulting in the highest transaction-lock cooperative performance while still adhering to the rule.


[heading Locks Inside of Transactions (LiT)]

Locks inside of transactions (LiT) are scenarios where a lock-based pessimistic critical section is executed partially or completely inside a transaction. Only two of the three possible LiT scenarios are supported by our work: (1) pessimistic critical sections are encapsulated entirely within a transaction or (2) pessimistic critical sections start inside a transaction but end after the transaction has terminated.We do not support LiT scenarios where pessimistic critical sections start before a transaction begins, having the front-end of the transaction encapsulated by the pessimistic critical section. The reason to disallow such behavior is to avoid deadlocks.

Consider the following scenario. Thread T1 has an in-flight irrevocable transaction Tx1 and thread T2, after obtaining lock L2, starts a transaction Tx2. Tx2 is not allowed to make forward progress until it is made irrevocable (details to follow). Tx1 is already in-flight and irrevocable. Since two irrevocable transactions cannot run simultaneously as they are not guaranteed to be devoid of conflicts with one another, Tx2 must stall until Tx1 completes. If irrevocable transaction Tx1 requires lock L2 to complete its work the system will deadlock. Tx1 cannot make forward progress due to its dependency upon L2 (currently held by Tx2) and Tx2 cannot make forward progress as it requires Tx1 to complete before it can run. As such, LiT scenarios where locks encapsulate the front-end of a transaction are disallowed; our implementation immediately throws an exception when this behavior is detected.

Irrevocable and Isolated Transactions

The LiT algorithms use the same policies as the LoT algorithms: full lock protection, TM-lock protection and TX-lock protection. Locks inside of transactions have the same characteristics as normal mutual exclusion locks, and Lemma 1 must be followed in order to ensure correctness. Since the LiT algorithms use locks acquired inside of transactions and these locks are not guaranteed to have failure atomicity as transactions do, the containing transactions must become irrevocable (see Lemma 2). Irrevocable transactions, characterized by T(irrevocable) = true, are transactions that cannot be aborted. The concept of irrevocable (or inevitable) transactions is not new; Welc et al. and Spear et al. have shown these types of transactions to be of significant importance as well as having a variety of practical uses [17, 19]. We extend the prior work of Welc et al. and Spear et al. by using irrevocable transactions to enable pessimistic critical sections within transactions, as well as to create composable locks within transactions. In addition to irrevocable transactions, the LiT full lock protection and TM-lock protection require a new type of transaction, one that we term as an isolated transaction. Isolated transactions, characterized by T(isolated) = true, are transactions that cannot be aborted and require that no other type of transaction run along side it simultaneously. Isolated transactions can be viewed as a superset of irrevocable transactions; isolated transactions have the properties of irrevocable transactions and must be run in isolation. To demonstrate how the LiT algorithms work, consider the six threaded example shown in Figure 12.

3 LiT Transaction Threads, 3 Locking Threads.

    1   native_trans<int> g1, g2, g3, g4;
    2
    3   void tx1() { /* no conflict */ }
    4   void tx2() {
    5       transaction::add_tm_conflicting_lock(L2);
    6       for (transaction t;;t.restart())
    7       try {
    8           t.add_tx_conflicting_lock(L2);
    9           inc2();
    10          t.end(); break;
    11      } catch (aborted_tx&) {}
    12  }
    13  void tx3() {
    14      transaction::add_tm_conflicting_lock(L3);
    15      for (transaction t;;t.restart())
    16      try {
    17          t.add_tx_conflicting_lock(L3);
    18          inc3();
    19          t.end(); break;
    20      } catch (aborted_tx&) {}
    21  }
    22
    23  void inc2() {
    24      lock(L2); ++g2.value(); unlock(L2);
    25  }
    26  void inc3() {
    27      lock(L3); ++g3.value(); unlock(L3);
    28  }
    29  void inc4() { /* no conflict */ }

In Figure 12 thread T1 executes tx1(), T2 executes tx2(), T3 executes tx3(), T4 executes inc2(), T5 executes inc3() and T6 executes inc4(). Threads T1 (tx1()) and T6 (inc4()) do not conflict with any other thread, yet their execution can be inhibited by other threads based on the LiT policy employed. Thread T2 has a true conflict with thread T4 (both threads call inc2()) and thread T3 has a true conflict with thread T5 (both threads call inc3()). A staggered start time is used in the coming diagrams: T1 starts, followed by T2, T3, T4, T5 and finally T6.We label the LiT threads based on the locks they acquire: tx1 acquires lock L1, thread tx2 acquires lock L2 and thread tx3 acquires lock L3. The same taxonomy is used for locking threads: thread lockL2 acquires lock L2, thread lockL3 acquires lock L3 and thread lockL4 acquires lock L4.

In Figure 12, both add_tm_conflicting_lock() and add_tx_conflicting_lock() are present. If the system is using TM-lock protection only the add_tm_conflicting_lock() is necessary, whereas if the system is using TX-lock protection only the add_tx_conflicting_lock() is necessary. If neither TMlock or TX-lock protection is in use, neither call is needed. These interfaces are supplied for the completeness of the example.

[heading LiT Full-Lock Protection]

Figure 13 demonstrates how the six threads interact using the full lock protection policy, as well as showing policy conflicts in comparison to true conflicts. The LiT full lock protection algorithm requires that any transaction that has a lock inside of it be run as an isolated transaction. Prior to a lock inside the transaction being obtained, all other in-flight transactions are aborted or committed and all currently held locks must execute through release. Future attempts to obtain locks outside of the isolated transaction are prevented until the transaction commits. This behavior is required as the system must assume (1) all external locks can conflict with the isolated transaction, so no external locks can be obtained; and (2) all external transactions can conflict with the LiT transaction, and therefore no external transactions can execute.

For Figure 13, once tx2 begins, tx1 is stalled as tx2 must run as an isolated transaction. Due to tx2's isolation, tx3 is also stalled. Both lockL2 and lockL3 are also stalled because full lock protection disallows transactions from running while LoT locks are obtained; as tx2 is an isolated transaction, the threads attempting to lock L2 and L3 are stalled until tx2 completes. When tx2 completes, tx3 is started as it has stalled for the longest amount of time. The thread executing lockL4 is stalled until tx3 completes. When tx3 completes, tx1, lockL2, lockL3 and lockL4 are all allowed to resume.

[heading LiT TM-Lock Protection]

Like full lock protection, LiT TM-lock protection runs transactions encapsulating locks in isolation. However, LiT TM-lock protection also requires the end programmer to identify locks obtained within any transaction prior to transaction execution (just as LoT TM-lock protection). Unlike LiT full lock protection, TM-lock protection allows non-conflicting LoT locks to execute along side LiT locks, increasing overall system throughput.

As shown in Figure 14 TM-lock protection reduces the overall policy-induced conflicting time to a range closer to the true conflicting time. Since tx2 and tx3 are true conflicts with lockL2 and lockL3, lockL2 and lockL3 must stall while tx2 and tx3 are executing. However, lockL4 does not conflict with either tx2 or tx3 and as such, should not be stalled while the LiT transactions are inflight. TM-lock protection correctly identifies this conflict as false, allowing lockL4's execution to be unimpeded by tx2 and tx3's execution.

Three problems still exist in the LiT example: (1) tx1 is stalled by tx2 and tx3, (2) lockL2 is stalled by tx3 and (3) lockL3 is stalled by tx2. Ideally, none of these stalls should occur as none represent true conflicts. All three false conflicts are avoided by using the following LiT protection policy, LiT TX-lock protection.

[heading LiT TX-Lock Protection]

Like LoT TX-lock protection, the Lit TX-lock protection algorithm allows for the highest throughput of both transactions and locks while requiring the highest level of programmer involvement and system understanding. Unlike both prior LiT algorithms, TX-lock protection allows LiT transactions to run as irrevocable transactions, rather than isolated transactions. This optimization can increase overall system throughput substantially if other revocable transactions can be run along side the LiT transaction.

With LiT TX-lock protection, the programmer specifies locking conflicts for each transaction. In Figure 12's case, the programmer would specify that tx2 conflicts with L2 and tx3 conflicts with L3. By specifying true transactional conflicts with locks, the TM system can relax the requirement of running LiT transactions in isolation and instead run them as irrevocable. While no two irrevocable transactions can be run simultaneously, as they may conflict with each other (resulting in a violation of their irrevocable characteristic), other non-irrevocable transactions can be run along side them, improving overall system throughput.

The run-time result of using LiT TX-lock protection is shown in Figure 15. Transaction tx1 is able to run without being stalled as it has no conflicts with other transactions or locks. Transaction tx2 is run as an irrevocable transaction, rather than as an isolated transaction, allowing tx1 to run along side it. Irrevocable transaction tx3 is prevented from starting as irrevocable transaction tx2 is already in-flight. Likewise, lockL2 cannot lock L2 since tx2 conflicts with L2 and allowing lockL2 to proceed would require tx2 to abort. Since tx2 is irrevocable (e.g. unabortable), lockL2 is stalled. However, lockL3 and lockL4 start immediately, since neither conflict with any in-flight transaction. When tx2 completes, both tx3 and lockL2 can try to proceed. Transaction tx3 is stalled by lockL3, but lockL2 executes immediately as its conflict with tx2 has passed. When lockL3 completes tx3 begins and runs through to completion.


[heading Lock Composition]

Any TM system that supports locks inside of transactions must ensure the pessimistic critical sections of the locks inside of transactions are not violated. This is achieved by making the containing transactions either isolated or irrevocable once the lock inside the transaction is obtained. Lemma 2 proves the necessity of the irrevocability characteristic for LiT transactions.

Locks Inside of Transactions Lemma 2. Any lock L obtained during an in-flight transaction Tif requires Tif be immediately and permanently promoted to an irrevocable transaction, characterized by Tif (irrevocable) = true, which cannot be aborted.

Proof. (Contradiction) Given: threads T1 and T2 execute inc() and get() from Figure 19, respectively and variables x = 0, y = 0. ++x and ++y operations within inc() are unguarded direct access variable operations that perform no transactional undo or redo logging operation; these operations are irreversible (e.g. normal pessimistic critical section operations). The atomic property of any transaction T requires all memory operations of T are committed or none are committed.

Execution: T1 starts transaction Tx1 (Tx1(irrevocable) = false) and completely executes lines 3-7, setting x = 1. T2 executes 13- 14, obtains lock L1, released by Tx1 and flags Tx1 to abort due to its identified lock conflict. T2 reads x = 1 and y = 0, unlocks L1 and returns. Tx1 tries to lock L1, but instead is required to abort, causing the atomic transactional property of Tx1 to be violated since ++x has been performed and will not be undone when Tx1 is aborted.

    1   int x = 0, y = 0;
    2
    3   void inc() {
    4       for (transaction t;;t.restart())
    5       try {
    6           t.add_conflicting_lock(L1);
    7           lock(L1); ++x; unlock(L1);
    8           lock(L1); ++y; unlock(L1);
    9           t.end(); break;
    10      } catch (aborted_tx&) {}
    11  }
    12
    13  void get(int &retX, int &retY) {
    14      lock(L1);
    15      retX = x; retY = y;
    16      unlock(L1);
    17  }

    Figure 19. Violating LiT Lemma 2.

Referring again to Figure 19, now consider the correct execution (following Lemma 2) of threads T1 and T2 of inc() and get(), respectively, with variables x = 0, y = 0. T1 starts transaction Tx1 and executes lines 3-7, setting x = 1 and Tx1(irrevocable) = true. T2 executes 13-14, but fails to obtain lock L1 even though it is released by Tx1. T2 fails to obtain lock L1 because in order to do so would require Tx1 be aborted as it has flagged itself as conflicting with lock L1 via t.add_conflicting_lock(L1). Yet, Tx1 cannot be aborted since Tx1(irrevocable) = true. T2 stalls until Tx1 completes, setting x = 1, y = 1. T2 then executes, obtaining the necessary locks and returning x = 1 and y = 1 the atomically correct values for x and y (equivalent values) given transaction Tx1.

By incorporating both Lemma 1 and 2, locks inside of transactions naturally compose and emit database ACI characteristics; atomic, consistent and isolated. They are atomic (all operations commit): once a lock is obtained inside a transaction, the transaction becomes irrevocable. This ensures that all operations will commit, irrespective of how many locks are obtained within the LiT transaction. They are consistent: no conflicting locks or transactions can run along side the irrevocable LiT transaction, ensuring memory correctness. They are isolated: conflicting locks or transactions are disallowed from running in conjunction with an LiT transaction, preventing its state from being visible before it commits. Even when a lock is released inside an LiT transaction, other threads remain unable to obtain the lock until the transaction commits.

[heading Criticality of LiT Lock Composition]

The composable nature of LiT locks is critical to the incremental adoption of transactions into pre-existing, lock-based parallel software. To understand this, consider a multi-threaded linked list implemented using mutual exclusion locks. The linked list software is mature, thoroughly tested and contains lookup(), insert() and remove() methods. A software designer wishes to extend the linked list's behavior to include a move() operation. The move() operation behaves in the following way: if element A exists in the list and element B does not exist in the list, element A is removed from the list and element B is inserted into the list.With LiT lock composition, the move() operation could be implemented entirely from the previously built locking implementation. Figure 20 demonstrates how this is achieved within the __Boost_STM__ LATM extension.

    1   bool move(node const &A, node const &B) {
    2       // compose locking operations: lookup(), remove()
    3       // & insert() in an irrevocable & indivisible tx
    4       // to make a new transaction-based move() method
    5       for (transaction t;;t.restart())
    6       try {
    7           t.add_tx_conflicting_lock(list_lock_);
    8           // lookup() uses lock list_lock_
    9           if (lookup(A) && !lookup(B)) {
    10              remove(A); // uses lock list_lock_
    11              insert(B); // uses lock list_lock_
    12          }
    13          else return false;
    14
    15          t.end(); return true;
    16      } catch (aborted_tx&) {}
    17  }

    Figure 20. Move Implemented with LiT Lock Composition.

The move() method in Figure 20 is viewed by other threads as an indivisible operation whose intermediate state is isolated from other threads, even though it contains four disjoint pessimistic critical section invocations (e.g. two lookups, a remove and an insert). Even when list_lock_ is released intermittently during the transaction execution, other threads are prevented from obtaining it until the transaction commits. This behavior ensures each pessimistic critical section within the transaction is prevented from being viewed independently. Once the transaction commits other threads can obtain list_lock_ and view the cumulative affects of the move() operation.

[heading Understanding LiT Lock Composition]

Figure 21 shows a transfer function implemented using LiT lock composition. This example was chosen because the code sample is small enough to be presented in full (not possible with the prior linked list move() example). Figure 21 uses LiT TX-lock protection and contains two locks inside of the same transaction that are subsumed by the transaction. The transaction composes the two separate lock-based critical sections into an atomically viewed and isolated operation.

Consider threads T1 executing lit_transfer(1), T2 executing get1() and T3 executing get2() with x1 = 0 and x2 = 0 in the time line shown in Figure 22. The dotted vertical lines in the conflicting lock time in Figure 22 demonstrate when T1's transaction tx1 obtains and releases locks L1 and L2 with regard to T2 and T3. Thread T1 starts transaction tx1 and adds L1 and L2 to tx1's conflicting lock list. Next, tx1 locks L2 and becomes irrevocable (Lemma 2). Thread T2 then attempts to lock L1, however, since L1 conflicts with tx1 and tx1 is irrevocable, thread T2 is disallowed from aborting tx1 and is therefore prevented from obtaining L1, stalling instead. After tx1 sets x2 = ??1 and unlocks L2, thread T3 tries to lock L1, however, it is disallowed because L1 is on tx1's conflicting lock list and tx1 is irrevocable. Thus, thread T3 is stalled. Transaction tx1 then locks L1, sets x1 = 1 and unlocks

    1   int x1 = 0, x2 = 0;
    2
    3   void lit_transfer(int transfer) {
    4       for (transaction t;;t.restart())
    5       try {
    6           t.add_tx_conflicting_lock(L1);
    7           t.add_tx_conflicting_lock(L2);
    8
    9           lock(L2); x2 -= transfer; unlock(L2);
    10          lock(L1); x1 += transfer; unlock(L1);
    11
    12          t.end(); break;
    13      } catch (aborted_tx&) {}
    14  }
    15
    16  void get1and2(int& val1, int& val2) {
    17      lock(L1); lock(L2);
    18      val1 = x1; val2 = x2;
    19      unlock(L2); unlock(L1);
    20  }
    21  void get1(int& val) {
    22      lock(L1); val = x1; unlock(L1);
    23  }
    24  void get2(int& val) {
    25      lock(L2); val = x2; unlock(L2);
    26  }

    Figure 21. LiT Transaction and Two Locking Getters.

L1. When tx1 commits, threads T2 and T3 are unstalled and read x1 = 1 and x2 = ??1, respectively, the correct atomic values for the lit_transfer(1) operation with lock composition.

Figure 22. Composed LiT Example using TX-Lock Protection.

In the above scenario, both T2 and T3 tried to acquire the unlocked locks L1 and L2 but failed due to tx1's irrevocability even though the locks themselves were available. The characteristic of disallowing lock acquisition even when locks are available is a primary attribute of LiT transactions. This characteristic is not present in systems which use locks alone, and is a key attribute to enabling lock composition. As demonstrated earlier with LoT transactions, a lock and a transaction conflicting with the same lock cannot both execute simultaneously. LiT transactions use this same behavior and extend it to favor transactions over locks once a lock is obtained inside of a transaction, making it irrevocable. By restricting access of locks to in-flight LiT transactions which have acquired (and then released) them, the system ensures any remaining behavior not yet performed by the transaction will occur prior to other threads obtaining such released locks. This ensures

all the pessimistic critical sections within an LiT transaction are executed in isolation and consistently without memory interference from outside locking threads. Note that this was the case when T3 tried to acquire lock L2 even after transaction tx1 had completed
its operations on its shared memory x2.

[heading LiT Lock Identification]

LiT TX-lock protection requires that all transaction conflicting locks, those locks used directly inside of transactions, be identified prior to any lock being obtained within the transaction; failure to do so can lead to deadlocks. A simple example of how adding conflicting locks as they are obtained inside of transactions can lead to deadlocks can be derived from Figure 21. If lit_transfer() is executed without adding conflicting locks (e.g. no calls to add_conflicting_lock()), the following deadlock is possible. Thread T1 executes lines 3-5, skips lines 6-7 (the conflict calls) and executes line 9 locking L2 and adding it to its conflicting lock list. Thread T2 then executes lines 16 and part of line 17 of get1and2(), locking L1.Without the transactional code identifying L1 as a conflict, the TM system would not disallow T2 from locking L1. The system is now deadlocked. T2 cannot proceed with locking L2 as L2 has been added to T1 conflicting lock list, yet T1 cannot proceed as lock L1 is held by T2.

These deadlocks scenarios are overcome by requiring the LiT TM-lock or TX-lock protection to list all conflicting locks prior to obtaining any locks within transactions. Attempting to use locks inside of transactions without first identifying them as conflicts causes __Boost_STM__ to throw an exception informing the programmer of the missed conflicting lock and how to correct the error. Recycling the same scenario as above with conflicting locks identified at the start of the transaction avoids deadlocks. For example, thread T1 adds locks L1 and L2 to its conflicting lock list. It then executes lines 3-8 and part of line 9, locking L2 (but not unlocking it). Thread T2 executes lines 16 and part of 17, trying to lock L1, and sees T1's transaction as conflicting. Thread T2 tries to abort T1's transaction, but is disallowed as the transaction is irrevocable (see Lemma 2). T2 is therefore stalled prior to obtaining lock L1. T1 continues and executes the remainder of line 9-12, obtaining and releasing lock L1 and finally committing. Once T1's transaction has committed, T2 is allowed to resume and runs to completion.

[endsect]

[section Unrecoverable transactions to manage with I/O]

[endsect]

[endsect]

[section C++ and Library-Specific Concepts]

This section briefly discusses some of the C++ and library-specific
concepts of __Boost_STM__.

[section Native Language Compatibility]

Native Language Compatibility. Some existing STM systems require specific language extensions or compiler support for their proposed system to work. Other systems instead violate native language pragmatics by reducing or removing type-safety altogether. Yet other system's transactional functionality is significantly reliant on the preprocessor.

__Boost_STM__ is built with native language compatibility as a top priority - as such, it does not require language extensions or violate natural language semantics. Native language compatibility is a foremost concern due to C++0x set to specifically resist language extensions. While in other languages, such as Java, STM systems which require language extensions may be practical, within C++ this same approach seems unrealistic. Thus, there is a very practical need for a native language ready STM solution for C++.

[endsect]

[section Memory Management]

For unmanaged languages like C++, STM designers can build memory managers to control heap-based memory allocation and deallocation. While building a memory manager is not necessary for STM systems, performance optimizations can be achieved through such implementations. In particular, a key memory observation for STM systems is that numerous allocations and deallocations happen within transactions, irrespective of the memory design decisions. As such, __Boost_STM__ provides a builtin templatized user-configurable memory manager which generally yields 20% performance improvement over direct calls to the default C++'s new and delete.

As understood by most C++ experts, native new and delete operators in C++ are multi-threaded safe, using mutex locks to guarantee memory is retrieved and released in a safe manner for multiple contending threads. Improving the performance of direct calls to C++'s new and delete in a single-threaded application is relatively easy as a buffered free store can be created which requires no locking mechanism, thus naturally increasing performance. This same task is not quite as easy in a multi-threaded environment. __Boost_STM__ improves the native performance of C++'s operator new and delete by first implementing buffered allocations which naturally perform faster than single allocations. Secondly, performance gains are made by not relinquishing ownership of deallocated memory, making second-time memory allocations faster than first-time allocations. These two aspects enable __Boost_STM_s__ memory manager to perform faster than C++'s native new and delete operations.

__Boost_STM__ also must lock around memory allocations and deallocations, just as native C++ new and delete must, however, it can build a more problem-specific implementation that would hinder a generalized C++ new and delete if implemented on a global scale. The techniques used in __Boost_STM__ are similar to those discussed in Bulka and Mayhew's, Efficient C++, Chapter 7, Multi-threaded Memory Pooling. In C++ semantics, the performance gains within __Boost_STM_s__ memory manager can be thought of as the differences between using an std::vector's push_back() iteratively compared to using an std::vector's push_back() iteratively after calling reserve(), and then continuing to reuse the allocated space to avoid performance penalties of reallocations.

[endsect]


[section RAII]

An STM system needs a transaction interface to identify where transactions begin, end and which operations are performed within the transaction. __Boost_STM__ achieves this by implementing transactions as objects using the Resource Acquisition Is Initialization (RAII) principle.

RAII is a common concept in C++ when dealing with resources that need to be both obtained and released, like opening and closing a file. RAII uses the concept that if a resource is obtained it must be released even if the programmer fails to do so. RAII's behavior is implemented per class, usually requiring the destructor of the class to guarantee any resources gathered in the lifetime of the object be released. A primary benefit of RAII is its natively correct behavior in the event of exceptions. If an exception occurs causing an RAII class instance to destruct, due to stack unwinding, the deterministic destruction of the object is invoked. The destructor then releases any resources previously collected. This guarantees any object implementing RAII semantics will always release resources it controls, irrespective of program flow (normal or abnormal).

The __Boost_STM_s__ transaction class is based on the RAII concept for two primary reasons. First, C++ programmers implicitly understand stack based (automatic) objects and their native RAII semantics. In fact, all of C++'s Standard Template Library (STL) containers are implemented using the RAII philosophy. Second, exceptions in C++ are not required to be handled by the programmer as they are in other languages, like Java. Using RAII for transactions ensures proper and guaranteed termination of transactions regardless of program flow, a very important attribute for correct transactional behavior.

[endsect]


[section Mixin versus wrapper helpers]

__Boost_STM_s__ provides some helper classes to make transactional objects. The user should use each one on a per case, taking in account the advantages and liabilities of each one.

# mixin; transaction_object
# intrinsic wrapper: transactional_object
# extrinsic wrapper: transactional_reference_cache

Next follows the features the user should question

# Allows to use an existing class, for example std::pair class. Does the helper class allows the smart pointers to return an reference to an existing class?
    * mixin: There is no mean
    * intrinsic: the associated smart pointers to a transactional_object<std::pair> returns a std::pair reference
    * extrinsic: This is exacly the role of the extrinsec approach
# Allows to use an existing instance variable, for example a variable of type std::pair class. Does the helper class allows the smart pointers to return an reference to an existing class?
    * mixin: There is no mean
    * intrinsic: There is no mean
    * extrinsic: This is exacly the role of the extrinsec approach
# Works for class hierarchies. if D isa B, then helper<D> is a helper<B>
    * mixin: This is exactly the role of the extrinsec approach since we have added the base parameter (class B: mixin<B>{} class D: mixin<D,B>{}).
    * intrinsic: Not directly, we need to use some form of cast. clas D:B{}. intrinsic<B>* ptr=new intrinsic<D>(); ????
    * extrinsic: N/A because the helper is hidden
# Allows to avoid the forwarding problem for base classes
    * mixin: As the user defines its own class he can define the exact constructors avoiding the problem added the base parameter
    * intrinsic: the wrapper must define generic constructors having the forwarding problem.
    * extrinsic: N/A because the helper is hidden
# Allows to avoid the forwarding problem for derived classes
    * mixin: As the inheritance of the base class is done using the helper the base mixin must define generic constructors having the forwarding problem.
    * intrinsic: the wrapper must define generic constructors having the forwarding problem.
    * extrinsic: N/A because the helper is hidden
# Performs optimally.
    * mixin: optimal, only one allocation/copy
    * intrinsic: optimal, only one allocation/copy
    * extrinsic: instead of a single allocation/copy we need two, so no optimal

The following table is a compilation of the preceding analysis:

[table Comparaison with other STM systems
    [
        [[*feature]]                                            [[*Mixin]]  [[*Intrinsic Wrapper]]  [[*Extrinsic Wrapper]]
    ]
    [
        [[*existing class]]                                     [[No]]      [[*Yes]]                [[*Yes]]
    ]
    [
        [[*existing variable]]                                  [[No]]      [[No]]                  [[*Yes]]
    ]
    [
        [[*existing class hierarchy]]                           [[No]]      [[No]]                  [[*Yes]]
    ]
    [
        [[*avoid the forwarding problem for base classes]]      [[Yes]]     [[No]]                  [[*Yes]]
    ]
    [
        [[*avoid the forwarding problem for derived classes]]   [[No]]      [[No]]                  [[*Yes]]
    ]
    [
        [[*Works for class hierarchies]]                        [[*Yes]]    [[No]]                  [[*Yes]]
    ]
    [
        [[*Performs optimaly]]                                  [[*Yes]]    [[*Yes]]                [[No]]
    ]
]

[endsect]

[section Why __Boost_STM_s__ cache uses now memcpy instead of copy-constructor and assignement]

Until version 0.3 __Boost_STM_s__ used the copy-constructor to clone a new object which will be used directly by the derreed update policy and as a backup by the direct update policy. This has some drawbacks:

# Domain: Transactional object are limited to CopyConstructible objects
# Exception safety: As the user copy-constructor and assignement can throw exceptions
# Performances: Whole copy, either copy-constructor and assignement, of transactional objects could be expensive

The following sections explain deeply this issues.

[section Domain]

It seems a hard limitation to force a STM user to make all its classes CopyConstructible and Assignable.

[endsect]

[section Exception Safety]

With copy-constructor and assignement __Boost_STM__ fulfills Abrahams' basic exception safety guarantee for deferred updating, but cannot supply any exception safety guarantee for direct updating. The basic guarantee for exception safety states that if an exception is thrown, the operation may have side-effects but is in a consistent state. The basic guarantee is less strict than the strong guarantee which specifies if an exception is thrown there are no side-effects. The highest level of exception safety, above the strong guarantee, is the nothrow guarantee which disallows exceptions from being thrown entirely.

Within deferred updating, __Boost_STM__ can only afford to implement the basic guarantee because if memory is partially committed and then a user exception is thrown, no original state exists for the already committed memory. Therefore, already committed memory in a deferred updating system, must stay committed since no reverted original state can be used to revert the changes. To implement such a system would result in a substantial performance degradation to the overall system, effectively doubling memory size and copy operations. Due to these costs, a double-copy implementation is not performed and the basic guarantee for deferred updating is deemed acceptable.

Within direct updating, memory updates are done immediately on global memory, so transactions naturally achieve strong exception safety guarantees for commits. Aborts within direct updating, however, invoke copy constructors for restoration of the original global memory state. These copy constructors can throw exceptions which then can lead to a partially restored global state for aborted exceptions that are short-circuited by user-defined copy constructor exceptions. As such, no exception safety guarantee can be made for direct updating when used in C++, a downfall of the updating policy.

[endsect]

[section Performances]

Another problem with the copy is that we will need to copy the whole logical object when what we need is just the phisical part, e.g. if copy is used to clone the transactional object, each time we modify a linked list, we will copy the entire list, even if only one node is modified.

A pure transactional object is a transactional object that do not points to any non transactional object. For example, a transactional object including a std::string, is not a pure transactional object, because std::string has a pointer to a dynamically allocated memory which is not a transactional object. For these non pure transactional objects a copy will be needed. One way to limit this is to place every non pure transactional object on a separated class and add a pointer to it. So for example instead of doing

class X {
    std::string str;
    // ... other fields

};

which will make X non pure TO, we can do

class X {
    tx_ptr<std::string> str_ptr; // owned pointer which is cloned when making a copy but not by the STM system.
    // ... other fields

};

In this way X will be a pure TO poining to a non pure TO.

[endsect]

If memcpy is not portable we can consider specializing the clone and copy_state virtual functions.

The user must state explicitly the TO that are not pure by overloading the cache_clone, cache_ ... . We can also define a trait.


[endsect]


[section Move semantics]

When copying is needed we solve the problem of commit-time and abort-time exceptions by using move semantics in place of copy semantics when the class provided it. The idea of moving is new to C++ and will be available in the next version of the standard.

[endsect]

[section Parametric Polymorphism and Subtype Polymorphism]

Type
abstraction in C++ to create general purpose code can be achieved in numerous ways. Some of these ways, such as the use of C++ template classes and template functions (parametric polymorphism), as well as inheritance (subtype polymorphism), are considered practical and robust ways to build general purpose functionality while still ensuring a certain degree of type-safety is maintained. C++ templates, also known as parametric polymorphism, exhibit the same type-safety as if the general purpose code was written specifically for the templated instantiated type. Inheritance, on the other hand, reduces type-safety to some degree, but gains run-time flexibility unachievable with C++ templates alone. Other mechanisms also exist to create general purpose code, such as void pointers or preprocessor macros, but are considered unsafe and error-prone and thusly, not used in __Boost_STM__.

__Boost_STM__ uses both parametric and subtype polymorphism throughout its internal implementation and exposed interfaces. In cases where strict type-safety can be achieved, C++ templates are used. In other cases where exact type-safety cannot be achieved without reducing __Boost_STM_s__ functionality, inheritance is used. All of these factors considered, __Boost_STM__ is a research library that requires type-safety to be a foremost concern, as its usage would hampered if type-safety was relaxed in areas where it could have been retained. As such, C++ templates are used due to their retention of full type information, in cases where inheritance would have also sufficed with a slight loss of type-safety.


[endsect]



[section Language-like macro blocks]

The synchronization primitives supported in __Boost_STM_s__ programming model are mutual exclusion locks, timed locks and transactions. Mutual exclusion locks have architectural support in all modern instruction set architectures and are widely considered the most common synchronization primitive [11]. Transactions, a parallel programming abstraction by Herlihy and Moss [10], are currently implemented in software with potential hardware support in the near future [4].


[table Comparaison with other STM systems
    [
        [[*Keyword]]       [[*Behavior]]
    ]
    [
        [[*use_lock(L)]]       [[*Acquires lock L and executes critical section. Supports single operations without {} scope construction such as, use_lock(L) foo()]]
    ]
    [
        [[*use_timed_lock(MS, L)]]       [[*Acquires timed lock L and executes a critical section based on MS millisecond timer. If the timer expires without obtaining lock L, an exception is thrown. This extension allows the exception to escape the parallel construct scope. Supports single operations without {} scope construction
such as, use_timed_lock(1, L) foo()]]
    ]
    [
        [[*try_timed_lock(MS, L)]]       [[*Same as use_timed_lock(L), but exceptions are caught locally. Requires catch_lock_timeout(L) or lock_timeout]]
    ]
    [
        [[*catch_lock_timeout(E)]]       [[*Catches timed lock exception E thrown from try_timed_lock(L). Required to follow all try_timed_lock(L), unless followed by lock_timeout]]
    ]
    [
        [[*lock_timeout]]       [[*Catches and discards failed timer exception thrown from try_timed_lock(L). Required to follow all try_timed_lock(L), unless followed by catch_lock_timeout(E)]]
    ]

]

Table 1. __Boost_STM__ Mutual Exclusion Locking Parallel Constructs.

[heading Library-based Lock Implementations]

Mutual exclusion locks, or just locks, ensure a programmerspecified set of operations are limited to one thread of execution [7, 11]. Lock-guarded operations, also known as pessimistic critical sections, require that all threads obtain a single-ownership flag before executing the guarded operations. If N threads simultaneously attempt to execute the same pessimistic critical section, one thread is allowed forward progress while the remaining N ?? 1 threads are stalled. An example of three distinct types of locking is shown in Figure 1.

    1 // mutual exclusion with lock()/unlock().
    2 pthread_mutex_lock(l);
    3 int ret = foo();
    4 pthread_mutex_unlock(l);
    5 return ret;

or

    1 // mutual exclusion with automatic objects.
    2 {
    3 scoped_lock<pthread_mutex_t> lock(l);
    4 return foo(); // lock released
    5 }

or

    1 // language-like mutual exclusion.
    2 use_lock(l) return foo(); // lock released

    Figure 1. Library-based Lock Implementations.

In Figure 1, the automatic object and language-like mutual exclusion interfaces are safer than the pthread_mutex_lock() and pthread_mutex_unlock() interfaces. If an exception is thrown from foo() after pthread_mutex_lock() is called, its corresponding pthread_mutex_unlock() will not be called causing the application to deadlock. Both the automatic object and language-like implementations avoid deadlock in the event of an exception thrown from foo(). However, these implementations have notable differences in programmatic scoping and programmer error.

[heading Pitfalls in Scoping of Automatic Object Locks]

A closer examination of the automatic object and language-like approaches to locking reveal differences in potential programmerinduced error. Figure 2 demonstrates a sequential locking order example, a common solution to complex fine-grained locking implementations, in which locks must be obtained in a specific sequential order to avoid deadlocking. If the scope ({}) operators are removed from Figure 2 the behavior of both the scoped_locks and the use_locks are changed. In the case of the scoped_locks, the automatic objects will no longer be terminated after operation_C() and they will thereby retain any locks acquired upon construction until the next immediate scope is terminated. In the case of the use_locks, the locks remain locked only for operation_A() and are then released. Both locking structures are changed to behave incorrectly when the scope operators ({}) are removed, but we believe programmers are less likely to accidentally remove the scope from the use_lock idiom than the scoped_lock.

    1   // mutual exclusion with automatic objects.
    2   {
    3       scoped_lock<pthread_mutex_t> lock1(L1);
    4       scoped_lock<pthread_mutex_t> lock2(L2);
    5       scoped_lock<pthread_mutex_t> lock3(L3);
    6       operation_A();
    7       operation_B();
    8       operation_C();
    9   }

or
    1   // language-like mutual exclusion.
    2   use_lock(L1) use_lock(L2) use_lock(L3)
    3   {
    4       operation_A();
    5       operation_B();
    6       operation_C();
    7   }

    Figure 2. A Required Sequential Locking Order.


The reason why programmers are less likely to accidentally remove the scope from use_lock as opposed to scoped_lock is because the programming structure of use_lock is native to C++ in many ways. For example, the code structure shown below is found throughout C, C++ and Java:

    1   grammatical-phrase
    2   {
    3       operations ...
    4   }

A number of control structures, specifically in C++, follow this format, such as, if statements, for loops, switches, classes, structs and so forth. While the use_lock structure follows this common practice, scoped automatic objects (e.g., scoped_locks) do not. Because scoped_locks unavoidably deviate from the above common code structure, due to their automatic object basis, their scope is more likely to be accidentally removed by novice programmers as unnecessary.

The side-effect of accidental scope removal for automatic objects is that resources obtained by these objects are not released until the following scope closure is reached. In some cases, such as file closing, it may be acceptable for automatic objects to delay the release of resources. However, in other cases, such as the case with locks, it is unacceptable for automatic objects to delay the release of resources. In particular, if locks are not released when the programmer intended, the resulting behavior can temporarily or permanently stall all other threads from making forward progress. If threads are temporarily suspended from forward progress, program performance is degraded, yet if threads are permanently suspended from making forward progress, the program results in a deadlock. Both cases are unacceptable for locks because locks are used as a tool to optimize program performance and in both cases the delayed release of locks results in unoptimized performance.

[heading Library-based Transaction Implementations]

Transactions allow an unlimited number of threads to execute their optimistic critical sections. Transactions can perform their writes off to the side, ensuring global memory is preserved until the transaction's atomic operations are complete. To ensure conflicting transactions are identified and prevented, transactions perform correctness verification immediately before committing. The consistency checking performed by transactions ensures that transactions that write to or read from the same memory are restricted in their concurrent execution. The code below demonstrates three different implementations for transactions from a library-based approach where x is shared memory that must be synchronized.


    begin_transaction(t);
    tx_write(t, x) = val;
    end_transaction(t);

    transaction with begin()/end():

or

    {
        transaction t;
        t.write(x) = val;
        t.end();
    }

    transaction with automatic object:

or

    atomic { x = val; }

    language transaction:

Inspection of the above code reveals that begin_transaction() and end_transaction() are susceptible to the problem when a thrown exception can interfere with correct interface calls. As such, the begin_transaction() and end_transaction() approach can be immediately discarded from further consideration. The two remaining approaches, similar to the prior locking implementations, use automatic objects and a language-like approach. An initial observable difference between the two approaches is that the language approach has a smaller programmatic footprint than the automatic object approach. Furthermore, the automatic object approach introduces more programmatic complexity for transactional retry mechanics and composed transactional behaviors.

[heading Pitfalls in Transactional Execution of Automatic Objects]

Transactions use optimistic critical sections which generally require transactions be retried if they do not commit. As such, transactions are usually implemented as loops which re-execute until they commit. The code below illustrates the client code necessary to implement a basic retry behavior for automatic objects and language-like transactions.

    for (transaction t; !t.committed(); t.restart()) {
        try {
            t.write(x) = val;
            t.end();
        } catch (...) {}
    }

    automatic object transaction with retry

and

    atomic(t) {
        t.write(x) = val;
    } end_atom

    language-like transaction with retry

To complicate matters, some transactions must not implement a retry. Failed subtransactions often require the entire transaction be re-executed from the beginning. While the methods used to perform transactional retries vary between TM implementations, __Boost_STM__ uses an exception-based approach for all transactional interfaces. These __Boost_STM__ interfaces throw exceptions if transactions are found to be inconsistent. Therefore, parent transactions should use retry mechanics while their child transactions should not. The code above shows the differences between an automatic object and language-like implementation for parent and child transactions.



    // parent tx with automatic object:
    for (transaction t; !t.committed(); t.restart()) {
        try {
            t.write(x) -= val;
            foo();
            t.end();
        } catch (...) {}
    }

    // child tx with automatic object.
    void foo(int val) {
        transaction t;
        t.write(y) += val;
        t.end();
    }

    automatic object:

and

    // parent tx with language-like transaction.
    atomic(t) {
        t.write(x) -= val;
        foo();
    } end_atom

    // child tx with language-like transaction.
    void foo(int val) {
        atomic(t) {
            t.write(y) += val;
        } end_atom
    }

    language-like transaction:

The retry mechanics' syntactic overhead for automatic objects is nearly double that of the language-like semantics. The complexity of the additional retry code is significant and exhibits a number of locations where programmer-induced errors could be made. The key benefit of the language-like atomic syntax is that its structure is identical for parent and nested transactions and it behaves correctly when any transaction is used as a parent or child (details to follow).

While the automatic object syntax could also be created to be identical for parent and nested transactions, the impact of creating such identical behavior would result in an increase in the child transaction's code size by 266% for single instruction transactions. The resulting increased code size and complexity would increase the likelihood for programmer-induced errors. For these reasons, a number of TM researchers have been in favor of direct language integration of TM instead of API-only approaches.

[heading Disadvantages of Language Based Transactional Integration]

Unfortunately, there are a number of disadvantages to direct language-based support for transactions. To begin, transactional memory is still in the early stages of research investigation. A number of open TM questions should be answered before transactions are integrated directly into high-level languages. Some of the open questions for transactions are regarding validation and invalidation consistency checking, fairness and priority-based transactions, open and closed nesting, exception behavior within transactions, lock-based and non-blocking solutions, and hardware-software transactional communication. Furthermore, some TM problems, such as contention management strategy selection, seem more naturally placed within libraries than languages due to their continually evolving and workload-specific nature.

In light of this, direct integration of TM into a programming language today may lead to errors that are irreversible. These errors may have long-term consequences for the language. Language based integrations are also slow to emerge, even in languages that are quick to evolve, such as Java. A language-based approach to TM may take several years before it is available. Yet, the emergence of multi-core hardware is rushing programmers to develop multithreaded applications today. Without wide TM availability, the primary parallel programming construct used today is locks. Parallel programming research experts unanimously agree that finegrained locking alone leads to notoriously complex software to implement and maintain.

The culmination of the above points illustrate the need for an extensible, simplified, parallel programming model today. Our language-like approach provides such a solution for C++ that neither library-based automatic objects nor language-based parallel abstractions alone can provide.


[heading Parallel Constructs for Mutually Exclusive Locks]

In this section we describe the behavior, and give examples, of the __Boost_STM__ language-like parallel constructs for mutually exclusive locks. The __Boost_STM__ mutual exclusion locking constructs are shown in Table 1. Each of these constructs allow any type of nesting, ordering and intermixing. Examples of the __Boost_STM__ locking constructs are shown in Figure 9.

    1   // single-line sequential locking
    2   use_lock(L1) use_lock(L2) use_lock(L3) foo();
    1   // multi-line sequential locking
    2   use_lock(L1) use_lock(L2) use_lock(L3) {
    3   foo();
    4   }
    1   // multi-line sequential single 100 ms timed lock
    2   while (polling)
    3   try_timed_lock(100, L1) {
    4       use_lock(L2) use_lock(L3)
    5       {
    6           foo();
    7           polling = false;
    8       }
    9   } lock_timeout { execute_on_failed(); }

    Figure 9. Mutual Exclusion Locks with __Boost_STM__.

As demonstrated in Figure 9, a number of locking models can be implemented using a mixture of the use_lock(L), use_timed_lock(MS, L) and try_timed_lock(MS, L) parallel constructs. Each locking interface addresses a unique requirement in client code.

[heading Exception-based Timed Locks]

A notable feature of our __Boost_STM__ language-like extensions is the use of exceptions in conjunction with timed locks. It is our belief that timed locks are used primarily for polling models and generally require two distinct paths of execution. One path of execution is taken when the lock is obtained before the timeout. The other path of execution is taken when the lock is not obtained before the timeout. In light of this, exceptions thrown when timed locks are not acquired can facilitate a distinction between successful lock acquisition and failed lock acquisition. Client code can become excessively unoptimized or complex if timed sequential locking is necessary and non-throwing automatic objects are used. An example of such unoptimized timed locking is demonstrated in Figure 10.

    1   // unoptimized timed locking
    2   while (polling) {
    3       timed_lock tl1(100, L1);
    4       timed_lock tl2(100, L2);
    5       timed_lock tl3(100, L3);
    6
    7       if (tl1.has_lock() && tl2.has_lock() &&
    8           tl3.has_lock()) {
    9           foo();
    10          polling = false;
    11      }
    12      else execute_on_failed();
    13  }

    Figure 10. Unoptimized Timed Locking with Automatic Objects.

Figure 10 illustrates how non-throwing automatic objects can hamper performance if incorrectly implemented and demonstrates an unoptimized implementation of timed locks. Delaying lock acquisition checks until after all timed locks are constructed can result in an a substantial performance degradation if neither L1 nor L2 are acquired. This performance degradation is caused by performing additional unnecessary work after failing to acquire lock L1 and L2.

    1   // optimized timed locking
    2   while (polling) {
    3       timed_lock tl1(100, L1);
    4       if (tl1.has_lock()) {
    5           timed_lock tl2(100, L2);
    6           if (tl2.has_lock()) {
    7               timed_lock tl3(100, L3);
    8               if (tl3.has_lock()) {
    9                   foo();
    10                  polling = false;
    11              }
    12              else execute_on_failed();
    13          }
    14          else execute_on_failed();
    15      }
    16      else execute_on_failed();
    17  }

    Figure 11. Optimized Timed Locking with Automatic Objects.

In order to optimize Figure 10's timed locks, a complex level of if nesting is needed as shown in Figure 11. Figure 11 demonstrates an optimized level of timed locking, but drastically increases the complexity of the software structure. Figure 11 introduces a high level of software complexity as a trade-off for performance. Intermixing the __Boost_STM__ try_timed_lock(MS, L) and use_timed_lock(MS, L) constructs builds a software structure that is simpler than either Figure 10 or 11 while achieving the same level of performance found in Figure 11. An example of try_timed_lock(MS, L) and use_timed_lock(MS, L) is shown in Figure 12.

    1   // multi-line sequential all 100 ms timed lock
    2   while (polling)
    3       try_timed_lock(100, L1) {
    4           use_timed_lock(100, L2)
    5           use_timed_lock(100, L3)
    6           {
    7               foo();
    8               polling = false;
    9           }
    10      } lock_timeout { execute_on_failed(); }

    Figure 12. Optimized Timed Locking with __Boost_STM__.


[ heading Parallel Constructs for Transactional Memory]

In this section we describe the behavior, and give examples, of the __Boost_STM__ language-like parallel constructs for transactional memory. The __Boost_STM__ transaction-based parallel constructs are shown in Table 2. These transactional constructs enable open-ended transactional nesting behaviors that are important to composition. Examples of the __Boost_STM__ transactions are shown in Figure 13. Figure 13 demonstrates how transactions are used in various ways. In some cases transactions are single operations, such as in the inc_x() case. At other times transactions consist of

    1   void inc_x(int val)
    2   {
    3       atomic(t) { t.write(x) += val; } end_atom
    4   }
    1   void inc_y_and_z(int val)
    2   {
    3       atomic(t) {
    4           t.write(y) += val;
    5           t.write(z) += val;
    6       } end_atom
    7   }
    1   void transfer_x_to_y_z(int val)
    2   {
    3       atomic(t) {
    4           inc_x(-val);
    5           inc_y_and_z(val / 2);
    6       } end_atom
    7   }

    Figure 13. Transactions with __Boost_STM__.

multiple operations, such as inc_y_and_z(). More cases exist when transactions are made up of other transactions, such as transfer_x_to_y_z(). The last case, often referred to as composition, is an important characteristic of transactions that most (if not all) other synchronization primitives do not exhibit (more on this later).

In the simple case, when no transactional nesting occurs, the transactional retry behavior happens locally. For example, if two threads try to concurrently execute the inc_x() function of Figure 13, only one thread will succeed since both threads cannot simultaneously access and change the same shared memory location. The failing thread will have to retry its transaction. Since inc_x() is a single-level transaction, the failing thread can retry the transaction locally (i.e., restarting at the top of the atomic structure inside inc_x()).

Non-trivial cases exist when transactions may be nested and retrying a transaction locally will cause an infinite loop. These cases use composed transactions and (generally) require that a failed transaction be retried from the parent transaction 1. An example of a composed transaction that, if aborted, would require the transaction to be retried from the parent is transfer_x_to_y_z(). This transaction must be retried from the parent, rather than by either of its child transactions individually, (int_x() and inc_y_and_z()) because the values within the shared memory x, y, and z could have been altered by another interleaved transaction.

__Boost_STM__ handles the shifting of transactional retry mechanics from child to parent dynamically and automatically. As demonstrated in Section 3.2, the atomic macro makes numerous calls into the currently active transaction to determine whether its failed commit should result in a local retry or a thrown aborted_transaction exception. The correct path of execution for the transactional retry is based on the run-time state. For example, if int_x() has failed, but it is the only transaction currently being executed by a thread, then it should be retried locally. However, if int_x() has failed, but it is being executed from within transfer_x_to_y_z() then transfer_x_to_y_z() should be re-executed. The re-execution of a parent transaction is enabled by a child transaction identifying the correct behavior and then throwing an exception upward.

[heading Transaction Nesting]

While the retry behavior of nested transactions is important, the composed behavior of independently designed transactions is even more important. Transactional composition [8, 15] is the cornerstone of transactional memory. In short, TM allows independently designed transactions to be placed together under the umbrella of a single transaction. This single transaction then behaves in an atomic, consistent and isolated fashion. Furthermore, the single transaction that is composed of many individual transactions is seen as a single indivisible operation to other transactions.

As such, an important aspect of transaction nesting is the construction of a transaction without the need to specify it is nested. A similar line of thinking is the construction of a function which is then used inside of another function and so forth. In C++ these nested functions are not created in any special way that describes their use in a given nested structure. Transactions, therefore, should be programmatically constructed in a similar way.

To the best of our knowledge, __Boost_STM__ is the first C++ STM library to implement transactions under a single keyword (atomic) which behaves correctly for both nested and non-nested transactions. While other correct implementations exist at the languagelevel [24] and compiler-level [18], no other library-based solution allows the programmer the practical freedom to implement transactions under a single keyword for transactions at any nesting level.

A more realistic example of the importance of nested and nonnested transactions and a universal keyword for both, is shown in Figure 14. Here we implement some basic list operations that are useful when used independently and when used in an cooperative, nested fashion.

Figure 14 demonstrates how transactions are composed using __Boost_STM__. The goal of the code shown in Figure 14 is to transfer all of the elements from list l to list j that do not already exist in list j. The entire operation is done atomically using four core transactional operations, insert, remove, transfer, and complete_transfer. The additional transactional operation, priority_transfer, is added to demonstrate how client code can wrap a composed transaction and alter its underlying performance in relation to other transactions by modifying the transaction's priority. Wrapping transactions with priority is useful in cases where the original transaction was written in a priority-neutral manner, but now must be used in an explicitly prioritized system. More details of prioritized transactions can be found in [6, 20].


[endsect]

[endsect]


[section Comparaison with other STM systems]

[table Comparaison with other STM systems
    [
        [[*Features]]       [[*__Boost_STM__]]   [[*TL2]]
    ]
    [
        [[*Lock-free]]       [[*NO]]   [[*YES]]
    ]
    [
        [[*Lock-based]]     [[*YES]]   [[*NO]]
    ]
    [
        [[*Validation]]     [[*YES]]   [[*??]]
    ]
    [
        [[*Invalidation]]     [[*YES]]   [[*NO]]
    ]
    [
        [[*Direct-Updating]]     [[*YES]]   [[*YES]]
    ]
    [
        [[*Deferred-Updating]]     [[*YES]]   [[*YES]]
    ]
    [
        [[*Word memory granulatity]]     [[*NO]]   [[*YES]]
    ]
    [
        [[*Object memory granulatity]]     [[*NO]]   [[*YES]]
    ]
]




[endsect]

[endsect]
