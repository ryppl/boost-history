[/
  (C) Copyright 2009 Justin E. Gottchlich.
  (C) Copyright 2009 Vicente J. Botet Escriba
 /
 / Distributed under the Boost Software License, Version 1.0. (See accompanying
 / file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)
 /]

[section:intro Introduction]

[heading Transactional Memory]

Transactional memory is a modern type of concurrency control that uses transactions as its synchronization mechanism. A transaction is a finite sequence of operations that are executed in an atomic, isolated and consistent manner. The atomicity, isolation and consistency (ACI) of transaction's are derived from the ACID principle in the database community. TM does not exhibit the D (durability) of ACID because unlike database transactions, TM transactions are not saved to permanent storage (e.g., hard drives).

Transactions are executed speculatively (optimistically) and are checked for consistency at various points in the transaction's lifetime. Programmers specify the starting and ending points of a transaction. All of the operations between those points make up the transaction's execution body. Transactions are commonly represented using the atomic structure shown in the figure below.

    1   atomic
    2   {
    3       ++x;
    4       --y;
    5   }

    Simple Transaction Using the atomic Keyword

Once a transaction has started it either commits or aborts. A transaction's operations are only seen once the transaction has committed, providing the illusion that all of the operations occurred at a single instance in time. The instructions of a committed transaction are viewed as if they occurred as an indivisible event, not as a set of operations executed serially. The operations of an aborted transaction are never seen by other threads, even if such operations were executed within a transaction and then rolled back.

In the case of the above example, if the transaction was committed both operations `++x` and `--y` would be made visible to other threads at the same instance in time. If the transaction the above example was aborted, neither operation (`++x` and `--y`) would appear to have occurred even if the local transaction executed one or both operations.

TM offers three distinct advantages over other parallel programming abstractions.

# TM is simple; transactions, the synchronization mechanism of TM, are easier to program than other synchronization mechanisms because they move shared memory management into the underlying TM subsystem, removing its complexity from the programmer's view. Moreover, TM exposes a simple programmer interface, reducing (or in some cases, removing) the potential for deadlock, livelock and priority inversion.

# TM is scalable; it achieves increased computational throughput when compared to other parallel programming abstractions by allowing multiple threads to speculatively execute the same critical section. When concurrently executing threads do not exhibit shared data conflicts, they are guaranteed to make forward progress.

# TM is modular; transactions can be nested to any depth and function as a single unit. This behavior allows application programmers to extend atomic library algorithms into atomic domain-specific algorithms without requiring the application programmers to understand the implementation details of the library algorithm.

For these reasons, transactions are considered an important synchronization mechanism and TM is viewed as an important type of concurrency control. The remainder of this section presents TM from a viewpoint of (1) simplicity, (2) scalability and (3) modularity.

[heading Simplicity]

Synchronization problems, such as deadlocks, livelocks and priority inversion are common in software systems using mutual exclusion. TM avoids many of these problems by providing a synchronization mechanism that does not expose any of its implementation details to the programmer. The only interfaces the programmer needs to use for TM is as follows:

* begin_tx() - the signaled start of the transaction.
* read(loc) - reads the specified memory location, storing its location in the transaction's read set and returning its current value.
* write(loc, val) - writes the specified memory location to the supplied val, storing its location in the transaction's write set.
* end_tx() - the signaled end of the transaction. end_tx() returns true if the transaction commits, otherwise it returns false.

The above interfaces allow the programmer to create a transaction (using begin_tx()), specify its memory operations (using read() and write()) and terminate (using end_tx()()). Moreover, none of the interfaces specify details of the TM subsystem's implementation. This leaves the TM system's implementation disjoint from the interfaces it supplies, a key characteristic for TM's simplicity.

All TM implementations use some combination of the above interfaces. TMs implemented within compilers tend to implicitly annotate transactional read() and write() operations, whereas those implemented within software libraries tend to require the programmer explicitly state which operations are transactional reads and writes. An example of a transaction using the above interfaces alongside an actual STM library implementation is shown in Figure 3.

    1   // TM interfaces            // __Boost_STM__
    2   do {                        atomic(t)
    3       begin_tx();             {
    4       write(x, read(x)+1);        ++t.write(x);
    5       write(y, read(y)-1);        --t.write(y);
    6   } while (end_tx());         } before_retry {}

    Figure 3. Transaction Using (1) Explicit TM Interfaces and (2) __Boost_STM__.

Figure 3 implements the same transaction as shown in Figure 2, except all transactional memory accesses, including the transaction's retry behavior (e.g., its loop), are demonstrated from a simple TM interface perspective and an actual library implementation (__Boost_STM__). While most TM systems handle some portion of these interface calls implicitly, as is shown in the __Boost_STM__ transaction, it is important to note that even when all operations are made visible to the end programmer, transactions are still devoid of many concurrency problems, such as data races and deadlocks (explained below), that plague other types of concurrency control.

For example, as long as the programmer properly annotates the access to the shared variables x and y as shown in Figure 3, it is impossible for race conditions or deadlocks to occur. Furthermore, the programmer does not need any program-specific knowledge to use shared data; he or she simply uses the TM interfaces supplied by the system and the resulting behavior is guaranteed to be consistent. This is explained in greater detail in Section 3.1.

Other types of concurrency control, such as mutual exclusion, cannot achieve the same interface simplicity, because part of their implementation is associated with, or exposed through, their interface. To demonstrate this, consider the fine-grained locking example of Figure 1 as shown below.

    1   // fine-grained locking
    2   lock(mutexX);
    3   lock(mutexY);
    4   ++x;
    5   --y;
    6   unlock(mutexX);
    7   unlock(mutexY);

There is no universal interface that can be used to properly access the shared data protected by the mutual exclusion in the above fine-grained locking example. Instead, the programmer must be aware that mutexX and mutexY protect shared data x and y and, therefore, the locks must be obtained before accessing the shared data. In short, the programmer is responsible for knowing not only that mutual exclusion is used, but also how it is used (e.g., which locks protect which shared variables). In this case, mutexX must be obtained before mutexY. If another section of code implements the following, a deadlock scenario will eventually occur.

    1   // fine-grained locking
    2   lock(mutexY);
    3   lock(mutexX); // deadlock here
    4   --y;
    5   ++x;
    6   unlock(mutexY);
    7   unlock(mutexX);

[heading Understanding Concurrency Hazards]

Informally, a concurrency hazard is a condition existing in a set of operations that, if executed with a specific concurrent interleaving, results in one or many unwanted sideeffects. Most errors in parallel systems, such as deadlocks and priority inversion, are the specific execution of concurrency hazards resulting in the unwanted side-effect(s) they contain. If the concurrency hazards are eliminated, the parallel system errors contained within the concurrency hazards are also eliminated. Unfortunately, detecting existing concurrency hazards is non-trivial and therefore eliminating them is also non-trivial.

Mutual exclusion exhibits more concurrency hazards than TM because its implementation details (i.e., its locks) must be exposed and used by the end programmer. While the locks used to enforce mutual exclusion by themselves are not concurrency hazards, their use can lead to a number of hazards. As such, using locks leads to concurrency hazards.

Because the mutual exclusion locking details are exposed to the programmer and because the programmer must maintain a universal and informal contract to use these locks, concurrency hazards can arise due to the number of possible misuses that can be introduced by the programmer. In particular, if the programmer accidentally deviates from the informal locking contract, he or she may inadvertently introduce a concurrency hazard that can cause the program to deadlock, invert priority or lead to inconsistent data.

In contrast, TM has no universal or informal contract between shared data that the end programmer needs to understand and follow as is required in mutual exclusion. Due to this, TM can hide its implementation details which results in reduced concurrency hazards. In particular, each transaction tracks the memory it uses in its read and write sets. When a transaction begins its commit phase, it verifies its state is consistent and commits its changes. If a transaction finds its state is inconsistent, it discards its changes and restarts. All of this can be achieved using the basic TM interfaces shown in Section 3 without exposing any implementation details. In order to use TM, the end programmer only needs to know how to correctly create a transaction. Once the transaction is executed, regardless of how it is executed, it results in a program state that is guaranteed to be consistent.

Fundamentally, TM exhibits less concurrency hazards than mutual exclusion because its implementation details are divorced from its interface and can therefore be hidden within its subsystem. Any number of implementations can be used in a TM subsystem using only the basic TM interfaces shown in Section 3. The same is not true for mutual exclusion. Mutual exclusion, regardless of how it is implemented, exposes details of its implementation to the programmer. As demonstrated in Section 5, mutual exclusion does not provide software modularity specifically because extending an existing module requires an understanding and extension of that module's implementation. When such locking implementations are hidden inside of software libraries, extending these modules can range from difficult to impossible.

[heading Testing: Race Conditions and Interleavings]

A race condition is a common concurrency hazard that exists in parallel or distributed software. As with all concurrency hazards, race conditions rely on a specific interleaving of concurrent execution to cause their unwanted side-effect. In this section we demonstrate that race conditions do not exist in TM and therefore, software testing is greatly simplified because all possible interleavings do not need to be tested to ensure correct system behavior. In order to demonstrate that race conditions are absent from TM, we must first show that they are present in other types of concurrency control.

    1   // Thread T1 // Thread T
    2   lock(L2);
    3   lock(L1);
    4   ...
    5   unlock(L1);
    6   unlock(L2);
    7   lock(L1);
    8   lock(L2);
    9   ...

    Figure 4. Mutual Exclusion Race Condition.

Consider the race condition present in the mutual exclusion example shown in Figure 4. The race condition present in the example results in a deadlock if thread T1 executes line 7 followed by thread T2 executing line 2. However, if the program executes the lines in order (e.g., line 1, then line 2, then line 3, etc.), the system will execute properly. The fundamental problem in Figure 4 is that it contains a concurrency hazard; in particular, it contains a race condition. To further complicate matters, the race condition can only be observed in two of many possible concurrent executions. Those two executions are: T1 executes line 7 followed by T2 executing line 2 or T2 executes line 2 followed by T1 executing line 7. All other possible concurrent interleavings of threads T1 and T2 avoid the deadlock race condition. More specifically, as long as T1 executes lines 7-8 atomically or T2 executes line 2-3 atomically, all remaining concurrent interleavings are free of the deadlock race condition.

Because it is unlikely that the deadlock race condition will occur, the programmer may never observe it, no matter how many times the program is tested. Only exhaustive testing, which tests all possible concurrent interleavings, is guaranteed to identify the presence of the deadlock. Regrettably, exhaustive testing is an unrealistic solution for most programs due to the time it would take to execute all possible concurrent interleavings of the program.

An alternative to exhaustive testing is for programmers to use types of concurrency control that are devoid of certain concurrency hazards. For example, if mutual exclusion did not emit the race condition concurrency hazard, it would be impossible for a program using it to deadlock. Therefore, exhaustive testing would not be necessary. While this scenario is hypothetical, it illustrates our larger argument: in order to avoid common parallel problems in a practical fashion, programmers may need to only use types of concurrency control that are devoid of certain concurrency hazards. By doing this, the program using the specific type of concurrency control will be guaranteed to be free of certain common parallel problems.

TMs are required to be devoid of race conditions within their implementations because they must enforce the ACI (atomic, consistent and isolated) principles. Transactions must execute as atomic and isolated and, therefore, TMs are not capable of supporting concurrent interleavings between multiple transactions as that would violate the atomic and isolated principles of ACI. Due to this, programs only using TM are guaranteed to be free of deadlocks (i.e., deadlockfreedom). Moreover, because TM implementations can guarantee freedom of race condition concurrency hazards, programmers only need to verify their transactional code is correct in a sequential (non-parallel) manner. Once the sequential execution of the transactional code has been verified, no more testing is required as the TM system is required to behave in a consistent manner for all serial orders.

[heading Development: Mutual Exclusion and TM]

The development of fine-grained locking is notoriously difficult. Designing such software is equally as hard. The difficulty in developing and designing fine-grained locking systems is rooted in conflicting heuristics. A primary goal of software design is to identify the most simplistic software solution that exists for a particular problem. A primary goal of fine-grained locking is the most efficient concurrent implementation of a software system. The goals of software design and fine-grained locking are conflicting because the most efficient fine-grained locking solution usually requires some of the most complex software design implementations to achieve such performance.

TM achieves scalability by using optimistic concurrency that is implemented within its subsystem (see Section 4). Since the TM subsystem is the efficiency throttle for TM, which is unexposed to the programmer, the software architecture and design never needs to be complicated (nor can it be) in order to achieve increased parallelism when using transactions. As will be demonstrated in the following section, transactions run efficiently using the interfaces shown in this section and are never complicated in order to achieve improved performance, as is commonly found in fine-grained mutual exclusion implementations.

[heading  Scalability]

In this section we analyze the scalability of TM compared to mutual exclusion. We measure scalability by two metrics: consistency and performance. A concurrency control type has consistent scalability if it guarantees correct behavior for an arbitrarily large number of concurrently executing processes.4 Performance scalability is measured by the maximum number of consistent processes supported by a concurrency control type while executing concurrently.

[heading  Pessimistic and Optimistic Critical Sections]

Critical sections can be pessimistic or optimistic. Pessimistic critical sections limit their critical section execution to a single thread. Locks are an example of a synchronization mechanism that use pessimistic critical sections. Optimistic critical sections allow unlimited concurrent threaded execution. Transactions are an example of a synchronization mechanism that use optimistic critical sections.

[heading Truly Optimistic Critical Sections]

Truly optimistic critical sections are those critical sections which allow multiple conflicting threads to simultaneously execute the same critical section. A deferred update (or lazy acquire) TM system supports truly optimistic critical section. A direct update (or eager acquire) TM system does not support truly optimistic critical sections. More details on deferred and direct update TM systems are presented in the subsequent sections.

Truly optimistic critical sections are important because they allow simultaneous conflicting critical section execution, as opposed to disallowing such behavior. It is important to allow conflicting critical section execution because prematurely preventing concurrently executing threads pessimistically degrades performance. To demonstrate this, consider two transactions, called T1 and T2, executing the same critical section. Transaction T1 starts first and tentatively writes to memory locationM. Transaction T2 then starts and tries to write to memory locationM. In a truly optimistic TM system, T2 would be allowed to tentatively write to location M while T1 is also writing to M. This behavior then allows T2 to commit before T1 in the event T2 completes before T1.

In comparison, if the TM system is not truly optimistic, once T1 writes to M, T2 must stall until T1 completes. This pessimistically degrades the performance of the system by prematurely deciding that T1's transactional execution should have higher priority than T2's.

    1   // global variables
    2   int g1 = 0; int g2 = 0;
    3
    4   void set1(int val) { atomic { g1 = val; } }
    5   void set2(int val) { atomic { g2 = val; } }
    6   int get1() { atomic { return g1; } }
    7   int get2() { atomic { return g2; } }

    Figure 5. Truly Optimistic Concurrency Diagram.

Furthermore, and perhaps more importantly, truly optimistic critical sections allow readers and writers of the same memory location to execute concurrently. This behavior is important because in many cases, both the readers and writers of the same memory can commit with consistent views of memory.

An example of this is shown in Figure 5. As demonstrated in Figure 5 thread 1 and thread 2, which we'll refer to as T1 and T2 respectively, operate on the same memory locations (g1 and g2). Because the TM system supports optimistic concurrency, T2 is allowed to execute concurrently alongside T1 even though their memory accesses conflict. However, in this scenario, because T2 completes its workload before T1, both transactions are allowed to commit. T2 captures the state of g1=0,g2=0 while T1 sets the state of g1=1,g2=1. As the example addresses, both g1=0,g2=0 and g1=1,g2=1 are legal states.

[heading Direct and Deferred Update]

Updating is the process of committing transactional writes to global memory and is performed in either a direct or deferred manner. Figure 6 presents a step-by-step analysis of direct and deferred updating.

Deferred update creates a local copy of global memory, performs modifications to the local copy, and then writes those changes to global memory if the transaction commits. If the transaction aborts, no additional work is done. Direct update makes an original backup copy of global memory and then writes directly to global memory. If the transaction commits, the transaction does nothing. If the transaction aborts, the transaction restores global memory with its backup copy. Some TM systems favor direct update due to its natural optimization of commits (BSTM, McRTSTM and LogTM). However, other TM systems favor deferred update due to its support for truly optimistic critical sections (__Boost_STM__ and RingSTM).

Direct update enables greater TM throughput when aborts are relatively low because it optimizes the common commit case. Deferred update enables greater TM throughput when

# aborts are relatively high or
# short running transactions (e.g., those that complete quickly) are executed alongside long running transactions (e.g., those that do not complete quickly) because long running transactions do not stall shorter running ones as they would in direct update systems, and therefore the fastest transactions can commit first.

It is important to note that deferred update supports truly optimistic critical sections without special effort, while direct update does not. Truly optimistic critical sections enable the speculative execution of transactions that arrive after a memory location has already been tentatively written to by another transaction. This allows the first transaction, of potentially many competing transactions, to complete its commit, whether it be the later arriving transaction or the earlier arriving writer. This scenario is not possible with direct update without special effort.

[heading  Scalability: Mutual Exclusion and Transactional Memory]

The scalability of mutual exclusion is limited to pessimistic concurrency. By definition, mutual exclusion's critical sections must be pessimistic, otherwise they would not be isolated to a single thread (i.e., they would not be mutually exclusive). TM, however, is generally implemented using optimistic concurrency, but it can enforce pessimistic concurrency amongst transactions if that behavior is required for certain conditions. In certain cases, TMs becomemore strict and execute pessimistically to enable inevitable or irrevocable transactions. Such transactions have significant importance for handling operations that, once started, must complete (e.g., I/O operations).

Since TM can execute optimistically and pessimistically, it is clear that whatever benefits pessimistic concurrency has can be acquired by TM. However, since mutual exclusion can only execute pessimistically, the advantages found in optimistic concurrency can never be obtained by mutual exclusion.

When one first analyzes pessimistic and optimistic concurrency, it may seem that the only benefit optimistic concurrency has over pessimistic concurrency is that multiple critical sections, which conflict on the memory they access, can execute concurrently. The simultaneous execution of such conflicting critical sections allows the execution speed of such critical sections to guide the system in deciding which execution should be allowed to commit and which should be aborted. In particular, the first process to complete the critical section can be allowed to abort the other process of the system. The same scenario cannot be achieved by pessimistic critical sections and is demonstrated in Section 4.1.1.

A counterargument to this scenario is that such optimistic concurrency only allows one critical section to commit, while one must be aborted. Because mutual exclusion only allows one conflicting critical section execution at a time, and because mutual exclusion does not support failure atomicity (i.e., rollbacking of the critical section), mutual exclusion's pessimistic behavior is superior in terms of energy and efficiency. Mutual exclusion, unlike TM, suffers no wasted work because conflicting critical sections are limited to a single thread of execution, reducing the energy it uses. Furthermore, because mutual exclusion does not require original data to copied, as needed for TM's direct or deferred update, it executes faster.

While there is merit to this counterargument, an important scenario is not captured by it: truly optimistic critical sections can support multiple reader / single write executions which, if executed so the readers commit before the writer, all critical sections will succeed. This scenario is impossible to achieve using pessimistic critical sections. Although mutual exclusion can use read/write locking, as soon as a writer thread begins execution on a conflicting critical section, all readers must be stalled. TM's truly optimistic concurrency does not suffer from this overly pessimistic limitation of throughput and is therefore capable of producing an immeasurable amount of concurrent throughput under such conditions.

From a theoretical perspective, given L memory locations and P processes, mutual exclusion can support the consistent concurrent execution of P*L number of readers or L writers. TM can support the consistent concurrent execution of P*L number of readers and L writers. Using the above variables, the mathematical expression of the performance scalability of mutual exclusion (S(ME)) is:

    S(ME) = (P*L) + L

Using the same variables, the mathematical expression of the performance scalability of transactional memory is:

    S(TM) = (P * L) + L

As should be clear from the above equations, mutual exclusion cannot achieve the same performance scalability of TM. This is because TM supports truly optimistic concurrency and mutual exclusion is confined to pessimistic concurrency. While other examples exist that demonstrate optimistic concurrency can increase throughput via contention management, the above equations capture the indisputable mathematical limitations in mutual exclusion's performance scalability.

[heading  Modularity]

Software modularity is an important aspect of software that is necessary for its reuse. Formally, software is modular if it can be composed in a new system without altering its internal implementation. Informally, software is modular if it can be used, in its entirety, through its interface.

By making software modular, it can be freely used in an unlimited number of software systems. Without software modularity, software can only be used in the original system where it was written. Clearly, without software modularity, software cannot be reused. Because most software developments are based on extensive library use, software reuse is an integral part of software development. As such, limiting software reuse, would result in severely hampered development capabilities and overall development time. For these reasons, software modularity is vital for any software paradigm to be practical. Software paradigms that do not support software modularity are, in short, impractical.

[heading Mutual Exclusion and Software Modularity]

In this section, we show that mutual exclusion, regardless of its implementation, fails to deliver software modularity. We demonstrate this through a running example started in Figure 7 which implements inc(), mult() and get(); these functions use lock G to respectively implement an increment, multiply and get operations for the shared data.

    1   void inc(int v) {
    2       lock(G); g += v; unlock(G);
    3   }
    4
    5   void mult(int v) {
    6       lock(G); g *= v; unlock(G);
    7   }
    8
    9   int get() {
    10      lock(G); int v = g; unlock(G);
    11      return v;
    12  }

    Figure 7. Mutual Exclusion for Increment, Multiply and Get of Shared Variable.

Now suppose a programmer wants to increment and multiply by some values within the same atomic operation. The initial implementation may look like the following.

    1   inc(a);
    2   mult(-b);

An unwanted side-effect of such an implementation is the exposure of the intermediate state of g between inc() and mult(). A second thread performing a get() may read an inconsistent value of g; the value of g between inc() and mult(). This is demonstrated in the timing diagram of Figure 8 .

    Figure 8. Example of Exposed State of Mutual Exclusion.

If the programmer needs the inc() and mult() operations to be executed together, without an intermediate state being revealed, he or she could make lock G reentrant. Reentrant locks are locks that can be obtained multiple times by a single thread without deadlocking. If G is made reentrant, the following code could be used to make inc(a) and mult(-b) atomic. A basic implementation of a reentrant lock is to associate a counter with its lock and increment the counter each time the lock() interface is called and to decrement the counter each time the unlock() interface is called. The reentrant lock is only truly locked when a call to lock() is made when its associated counter is 0. Likewise, the reentrant lock is only truly unlocked when a call to unlock() is made when its associated counter is 1.

    1   lock(G);
    2   inc(a);
    3   mult(-b);
    4   unlock(G);

If the above code uses reentrant locks, it will achieve the programmer's intended atomicity for inc() and mult(), isolating the state between inc() and mult(), which disallows the unwanted side-effect shown in Figure 8. While the atomicity of the operations is achieved, it is only achieved by exposing the implementation details of inc() and mult(). In particular, if the programmer had not known that lock G was used within inc() and mult(), making an atomic operation of inc() and mult() would be impossible.

An external atomic grouping of operations is impossible using embedded mutual exclusion without exposing the implementation details because the heart of mutual exclusion is based on named variables which the programmer specifies to guard their critical sections. Because these variables are named, they cannot be abstracted away and any programmer wishing to reuse the mutually exclusive code must be able to access and extend the implementation details.

    1   void inc(int v) { atomic { g += v; } }
    2
    3   void mult(int v) { atomic { g *= v; } }
    4
    5   int get() { atomic { return g; } }

    Figure 9. TM of Increment, Multiply and Get of Shared Variable.


[heading Summary of Mutual Exclusion Modularity]

As we presented at the beginning of this section, software modularity can be informally understood as a component's ability to be used entirely from its interface. Therefore, components that cannot be used entirely from their interface, components that must expose their implementation details to be extended, are not modular. As such, the paradigm of mutual exclusion does not support software modularity.

[heading Transactional Memory and Software Modularity]

Transactional memory works in a fundamentally different manner than mutual exclusion, with regard to its interface and implementation. To begin, as demonstrated in Section 3, TMs do not generally expose any of their implementation details to client code. In fact, in many TMs, client code is more versatile if it knows and assumes nothing about the active implementation of the TM. By abstracting away details of TM implementation, a TM subsystem can adapt its behavior to the most efficient configuration for the program's current workload, much like the algorithms used for efficient operation of processes controlled by operating systems. TM uses such abstractions to optimize the performance of concurrent programs using various consistency checking methods, conflict detection times, updating policies, and contention management schemes.

[heading  Achieving TM Software Modularity]

TM achieves software modularity by allowing transactions to nest. With transactional nesting, individual transactions can be wrapped inside of other transactions which call the methods where they reside, resulting in a transaction composed of both the parent and child transaction. Furthermore, this is achieved without altering or understanding the child transaction's implementation. To best demonstrate transactional nesting, we reuse the prior mutual exclusion example shown in Figure 7 and implement it using transactions as shown in Figure 9.

As before, the programmer's goal is to implement a combination of inc() and mult() executed in an atomic fashion. The basic, and incorrect implementation is demonstrated below:

    1   inc(a);
    2   mult(-b);

Even with transactions, this approach fails because the transactions within inc() and mult() begin and end inside their respective functions. However, to make the above operations atomic, the programmer need only make the following modification shown in Figure 10.

    1   atomic { // atomic {
    2       inc(a); // atomic { g += a; }
    3       mult(-b); // atomic { g *= -b; }
    4   } // }

    Figure 10. Modularity: Transaction of Increment and Multiply.

In effect, the TM system subsumes the transactions that are nested inside of the inc() and mult() operations. 6 The left side of Figure 10 shows the actual code of the transaction, while the right side shows the child transactions that are subsumed by the parent transaction.

Because transactions are isolated and atomic, the resulting state of g, from operations inc() and mult(), is invisible to outside observers until the transaction is committed. As such, outside threads cannot view any intermediate state constructed by partial transaction execution. The result of such isolated behavior is the guaranteed consistent concurrent execution of interleaved accesses to shared memory from in-flight transactions. This is demonstrated in Figure 11; let g=0 and assume deferred update is the active updating policy, as explained in Section 4.2.

    Figure 11. Example of Isolated and Consistent State of TM.

As shown in Figure 11, multiple concurrently executing threads can read and write to the same shared memory in a consistent and isolated fashion when using TM. In the example, thread T2 performs x = get() after T1 has already executed inc(a). However, since T1 has not yet committed its transaction, T2's view of shared data g is consistent (g=0). When T2 begins the commit phase of its transaction, the TM subsystem verifies that shared data g has not been updated since it initially read it. Since no other transaction has updated shared data g, T2's transaction is permitted to commit. Thread T1 then continues with its mult() operation and then enters its commit phase. The TM subsystem also verifies the consistency of T1's transaction before it is allowed to commit. Again, since no one transaction has updated shared data g between its reads and writes to it, T1's transaction is permitted to commit.

The above analysis demonstrates that software modularity can be achieved in TM through transactional nesting (Figure 10). In this case, the specific software modularity achieved is extension to an existing critical section. Critical section extension was also possible with mutual exclusion, as demonstrated in Section 5.1, but only through exposing the details behind the mutual exclusion implementation. Due to this, mutual exclusion fails to deliver a practical level of software modularity.

[heading  Summary of Transactional Memory Modularity]

TM supports software modularity by allowing transactions to nest, to any depth, while logically grouping the shared data accesses within the transactions into an atomic, consistent and isolated (ACI) operation. Transactional nesting is natural to the programmer because nested transactions behave in the same manner as unnested transactions. TM's ACI support ensures transactions will behave in a correct manner regardless of if the transaction is used by itself or subsumed into a larger transaction.


[heading C++ library language-like solution]

Research in parallel programming has recently seen a flurry of attention. Among the active research is a push for high-level languages to offer native support for parallel programming primitives. The next version of C++ will incorporate library support for threads, while numerous researchers are exploring ways to extend C++ to support transactional memory (TM).

A strength of C++ is its support for automatic objects. Rather than requiring that parallel primitives be added directly to the language, automatic objects in C++ can be used to implement much of their necessary infrastructure. The automatic object approach is natural from a language perspective, provides full algorithmic control to the end programmer, and demonstrates C++'s linguistic elegance. The disadvantage of this approach is its added programmatic overhead. Using only automatic objects, certain programming errors, such as accidental scope removal and incorrectly programmed transactional retry behavior, can arise.

In light of this, there are unique trade-offs between language based and library-based parallel primitives. Language-based solutions minimize syntactic clutter which reduce programmer related errors, but are seemingly irreversible and, if incorrect, can have crippling effects upon the language. Library-based solutions increase programmer control and flexibility, but place substantial pressure on the programmer to avoid minute programming errors. A good compromise is a solution that behaves like a language extension, but is implemented within a library. By implementing parallel primitives within a library that uses language-like interfaces, programmer pressure is reduced, implementation updates are seamless, and full programmer control is achieved through library extensibility.

__Boost_STM__ present such a language-like solution for C++ using generic library coupled with a deliberate use of the preprocessor. The culmination of these components facilitate a simple, yet powerful, parallel programming interface in C++.




[endsect]